{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAJ3xV5IvM62"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# README.md\n",
        "\n",
        "# High-Dimensional Matrix-Variate Diffusion Index Models\n",
        "\n",
        "<!-- PROJECT SHIELDS -->\n",
        "[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n",
        "[![Python Version](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://www.python.org/downloads/)\n",
        "[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n",
        "[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)\n",
        "[![Type Checking: mypy](https://img.shields.io/badge/type_checking-mypy-blue)](http://mypy-lang.org/)\n",
        "[![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=flat&logo=pandas&logoColor=white)](https://pandas.pydata.org/)\n",
        "[![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=flat&logo=numpy&logoColor=white)](https://numpy.org/)\n",
        "[![SciPy](https://img.shields.io/badge/SciPy-%23025596?style=flat&logo=scipy&logoColor=white)](https://scipy.org/)\n",
        "[![Statsmodels](https://img.shields.io/badge/Statsmodels-150458.svg?style=flat&logo=python&logoColor=white)](https://www.statsmodels.org/stable/index.html)\n",
        "[![Scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=flat&logo=scikit-learn&logoColor=white)](https://scikit-learn.org/)\n",
        "[![Jupyter](https://img.shields.io/badge/Jupyter-%23F37626.svg?style=flat&logo=Jupyter&logoColor=white)](https://jupyter.org/)\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-2508.04259-b31b1b.svg)](https://arxiv.org/abs/2508.04259)\n",
        "[![Research](https://img.shields.io/badge/Research-Macroeconomic%20Forecasting-green)](https://github.com/chirindaopensource/high_dimensional_matrix_variate_diffusion_index_models)\n",
        "[![Discipline](https://img.shields.io/badge/Discipline-Econometrics-blue)](https://github.com/chirindaopensource/high_dimensional_matrix_variate_diffusion_index_models)\n",
        "[![Methodology](https://img.shields.io/badge/Methodology-Factor%20Models-orange)](https://github.com/chirindaopensource/high_dimensional_matrix_variate_diffusion_index_models)\n",
        "[![Year](https://img.shields.io/badge/Year-2025-purple)](https://github.com/chirindaopensource/high_dimensional_matrix_variate_diffusion_index_models)\n",
        "\n",
        "**Repository:** `https://github.com/chirindaopensource/high_dimensional_matrix_variate_diffusion_index_models`\n",
        "\n",
        "**Owner:** 2025 Craig Chirinda (Open Source Projects)\n",
        "\n",
        "This repository contains an **independent**, professional-grade Python implementation of the research methodology from the 2025 paper entitled **\"High-Dimensional Matrix-Variate Diffusion Index Models for Time Series Forecasting\"** by:\n",
        "\n",
        "*   Zhiren Ma\n",
        "*   Qian Zhao\n",
        "*   Riquan Zhang\n",
        "*   Zhaoxing Gao\n",
        "\n",
        "The project provides a complete, end-to-end computational framework for forecasting a scalar time series using a high-dimensional, matrix-valued panel of predictors. It moves beyond traditional vectorized factor models by preserving the intrinsic row-column structure of the data, offering a more powerful and nuanced approach to dimension reduction in modern data-rich environments. The goal is to provide a transparent, robust, and computationally efficient toolkit for researchers and practitioners to replicate, validate, and extend the paper's findings.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "- [Introduction](#introduction)\n",
        "- [Theoretical Background](#theoretical-background)\n",
        "- [Features](#features)\n",
        "- [Methodology Implemented](#methodology-implemented)\n",
        "- [Core Components (Notebook Structure)](#core-components-notebook-structure)\n",
        "- [Key Callable: run_complete_study](#key-callable-run_complete_study)\n",
        "- [Prerequisites](#prerequisites)\n",
        "- [Installation](#installation)\n",
        "- [Input Data Structure](#input-data-structure)\n",
        "- [Usage](#usage)\n",
        "- [Output Structure](#output-structure)\n",
        "- [Project Structure](#project-structure)\n",
        "- [Customization](#customization)\n",
        "- [Contributing](#contributing)\n",
        "- [License](#license)\n",
        "- [Citation](#citation)\n",
        "- [Acknowledgments](#acknowledgments)\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This project provides a Python implementation of the methodologies presented in the 2025 paper \"High-Dimensional Matrix-Variate Diffusion Index Models for Time Series Forecasting.\" The core of this repository is the iPython Notebook `high_dimensional_matrix_variate_diffusion_index_models_draft.ipynb`, which contains a comprehensive suite of functions to replicate the paper's findings, from initial data validation and cleansing to the final generation of performance tables, diagnostic plots, and a full reproducibility report.\n",
        "\n",
        "Traditional diffusion index models require vectorizing predictor panels, which can destroy valuable structural information (e.g., the relationship between different economic indicators for a single country). This project implements a matrix-variate approach that preserves this structure, potentially leading to more powerful factors and more accurate forecasts.\n",
        "\n",
        "This codebase enables users to:\n",
        "-   Rigorously validate and prepare complex panel datasets, ensuring stationarity and preventing data leakage in a forecasting context.\n",
        "-   Extract low-dimensional latent factor matrices from a high-dimensional data tensor using the flexible α-PCA methodology.\n",
        "-   Estimate a bilinear forecasting model using a numerically stable Iterative Least Squares (ILS) algorithm.\n",
        "-   Apply a novel supervised screening technique to refine the predictor set and improve forecast accuracy.\n",
        "-   Conduct a full-scale Monte Carlo simulation to validate the statistical properties of the estimators.\n",
        "-   Perform a comprehensive empirical study, including benchmark comparisons and robustness checks.\n",
        "-   Automatically generate all key tables and figures from the paper for direct comparison and validation.\n",
        "\n",
        "## Theoretical Background\n",
        "\n",
        "The implemented methods are grounded in modern high-dimensional econometrics, extending classical factor model theory to matrix- and tensor-valued time series.\n",
        "\n",
        "**1. The Matrix-Variate Diffusion Index Model:**\n",
        "The core model assumes that a high-dimensional predictor matrix $X_t \\in \\mathbb{R}^{p \\times q}$ and a future scalar outcome $y_{t+h}$ are driven by a common low-dimensional latent factor matrix $F_t \\in \\mathbb{R}^{k \\times r}$.\n",
        "-   **Observation Equation:** $X_t = R F_t C' + E_t$\n",
        "-   **Forecasting Equation:** $y_{t+h} = \\alpha' F_t \\beta + e_{t+h}$\n",
        "\n",
        "**2. α-Principal Component Analysis (α-PCA):**\n",
        "Unlike standard PCA which only considers the covariance matrix (second moments), α-PCA constructs aggregation matrices that are a weighted average of both first and second moments of the data. This allows the factor extraction to be sensitive to both the mean structure and the variance structure of the predictors. The key constructs are the moment aggregation matrices:\n",
        "$$\n",
        "\\widehat{\\boldsymbol{M}}_R = \\frac{1}{pq} \\left[ (1+\\alpha) \\overline{\\boldsymbol{X}} \\overline{\\boldsymbol{X}}^\\prime + \\frac{1}{T} \\sum_{t=1}^T (\\boldsymbol{X}_t - \\overline{\\boldsymbol{X}}) (\\boldsymbol{X}_t - \\overline{\\boldsymbol{X}})^\\prime \\right]\n",
        "$$\n",
        "The loading matrices $R$ and $C$ are derived from the eigendecomposition of $\\widehat{\\boldsymbol{M}}_R$ and its column-wise equivalent $\\widehat{\\boldsymbol{M}}_C$.\n",
        "\n",
        "**3. Supervised Screening:**\n",
        "To improve the signal-to-noise ratio, the paper proposes a supervised pre-processing step. It computes the correlation of each individual predictor series $x_{ij,t}$ with the target $y_t$. Rows (e.g., countries) and columns (e.g., indicators) with low average absolute correlation are removed before the α-PCA is applied, focusing the dimension reduction on the most relevant parts of the data.\n",
        "\n",
        "## Features\n",
        "\n",
        "The provided iPython Notebook (`high_dimensional_matrix_variate_diffusion_index_models_draft.ipynb`) implements the full research pipeline, including:\n",
        "\n",
        "-   **Data Pipeline:** A robust, leak-free validation and preparation module that performs stationarity testing, transformation, and centralization appropriate for forecasting.\n",
        "-   **High-Performance Analytics:** Elite-grade, vectorized implementations of the α-PCA and ILS algorithms using advanced NumPy and SciPy features.\n",
        "-   **Statistical Rigor:** A complete suite of benchmark models (AR, Vec-OLS, Vec-Lasso) and a robust Diebold-Mariano test with small-sample corrections for fair and accurate model comparison.\n",
        "-   **Automated Orchestration:** A master function that runs the entire end-to-end workflow, including the empirical study, simulations, and robustness checks, with a single call.\n",
        "-   **Comprehensive Reporting:** Automated generation of publication-quality summary tables (replicating Tables 1, 2, 4, 5 from the paper), diagnostic plots, and a full reproducibility report.\n",
        "-   **Full Research Lifecycle:** The codebase covers the entire research process from data ingestion to final output generation, providing a complete and transparent replication package.\n",
        "\n",
        "## Methodology Implemented\n",
        "\n",
        "The core analytical steps directly implement the methodology from the paper:\n",
        "\n",
        "1.  **Data Validation and Preparation (Tasks 1-2):** The pipeline ingests the raw panel data, performs structural and quality checks, and applies a leak-free stationarity and centralization protocol.\n",
        "2.  **α-PCA Factor Extraction (Tasks 3-6):** It computes sample statistics, constructs the moment aggregation matrices, performs eigendecomposition to find the loadings, and projects the data to recover the latent factor matrices.\n",
        "3.  **LSE Parameter Estimation (Tasks 7-8):** It prepares the training data and uses a numerically stable Iterative Least Squares algorithm to estimate the forecasting parameters $\\alpha$ and $\\beta$.\n",
        "4.  **Supervised Screening (Tasks 9-10):** It computes training-data-only correlations, applies thresholds to filter the data, and prepares a refined data tensor.\n",
        "5.  **Out-of-Sample Forecasting and Evaluation (Tasks 12-14):** It generates forecasts on unseen data and evaluates them using MSFE and the Diebold-Mariano test.\n",
        "6.  **Simulation Study (Tasks 16-17):** It implements the full Monte Carlo simulation framework to generate synthetic data and validate the estimators' statistical properties.\n",
        "7.  **Orchestration and Reporting (Tasks 18-20):** Master functions orchestrate the empirical study, robustness checks, and the generation of all final tables and reports.\n",
        "\n",
        "## Core Components (Notebook Structure)\n",
        "\n",
        "The `high_dimensional_matrix_variate_diffusion_index_models_draft.ipynb` notebook is structured as a logical pipeline with modular functions for each task, from Task 1 (Data Validation) to Task 20 (Results Compilation).\n",
        "\n",
        "## Key Callable: run_complete_study\n",
        "\n",
        "The central function in this project is `run_complete_study`. It orchestrates the entire analytical workflow from raw data to a final, comprehensive report object.\n",
        "\n",
        "```python\n",
        "def run_complete_study(\n",
        "    country_data: Dict[str, pd.DataFrame],\n",
        "    y_series: pd.Series,\n",
        "    study_manifest: Dict[str, Any],\n",
        "    run_empirical_study: bool = True,\n",
        "    run_simulation_study: bool = True,\n",
        "    generate_reports: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Executes the entire research pipeline from data to final report.\n",
        "    \"\"\"\n",
        "    # ... (implementation is in the notebook)\n",
        "```\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "-   Python 3.9+\n",
        "-   Core dependencies: `pandas`, `numpy`, `scipy`, `statsmodels`, `scikit-learn`, `matplotlib`, `joblib`, `tqdm`.\n",
        "\n",
        "## Installation\n",
        "\n",
        "1.  **Clone the repository:**\n",
        "    ```sh\n",
        "    git clone https://github.com/chirindaopensource/high_dimensional_matrix_variate_diffusion_index_models.git\n",
        "    cd high_dimensional_matrix_variate_diffusion_index_models\n",
        "    ```\n",
        "\n",
        "2.  **Create and activate a virtual environment (recommended):**\n",
        "    ```sh\n",
        "    python -m venv venv\n",
        "    source venv/bin/activate  # On Windows, use `venv\\Scripts\\activate`\n",
        "    ```\n",
        "\n",
        "3.  **Install Python dependencies:**\n",
        "    ```sh\n",
        "    pip install pandas numpy scipy statsmodels scikit-learn matplotlib joblib tqdm\n",
        "    ```\n",
        "\n",
        "## Input Data Structure\n",
        "\n",
        "The pipeline requires two primary data inputs passed to the `run_complete_study` function:\n",
        "\n",
        "1.  **`country_data`**: A Python dictionary where keys are string identifiers for the row entities (e.g., countries) and values are `pandas.DataFrame`s. Each DataFrame must have a `DatetimeIndex` and identical column names representing the predictor variables.\n",
        "2.  **`y_series`**: A `pandas.Series` containing the scalar target variable, with a `DatetimeIndex` that is identical to those in the `country_data` DataFrames.\n",
        "3.  **`study_manifest`**: A nested Python dictionary that controls all parameters of the analysis. A fully specified example is provided in the notebook.\n",
        "\n",
        "## Usage\n",
        "\n",
        "The `high_dimensional_matrix_variate_diffusion_index_models_draft.ipynb` notebook provides a complete, step-by-step guide. The core workflow is:\n",
        "\n",
        "1.  **Prepare Inputs:** Load your panel data into the required dictionary and Series formats. Define the `study_manifest` dictionary.\n",
        "2.  **Execute Pipeline:** Call the master orchestrator function:\n",
        "    ```python\n",
        "    final_results = run_complete_study(\n",
        "        country_data=my_raw_country_data,\n",
        "        y_series=my_raw_y_series,\n",
        "        study_manifest=my_study_manifest,\n",
        "        run_empirical_study=True,\n",
        "        run_simulation_study=False, # Optional: very time-consuming\n",
        "        generate_reports=True\n",
        "    )\n",
        "    ```\n",
        "3.  **Inspect Outputs:** Programmatically access any result from the returned `final_results` dictionary. For example, to view the main results table for the unscreened model:\n",
        "    ```python\n",
        "    table4_panel_a = final_results['reports']['Table 4']['Panel A']\n",
        "    # In a Jupyter Notebook, this will render the styled table\n",
        "    display(table4_panel_a)\n",
        "    ```\n",
        "\n",
        "## Output Structure\n",
        "\n",
        "The `run_complete_study` function returns a single, comprehensive dictionary with the following top-level keys:\n",
        "\n",
        "-   `empirical_study`: A deeply nested dictionary containing all raw numerical results from the empirical analysis, including performance DataFrames for the main model (screened and unscreened), benchmark results, and significance tests.\n",
        "-   `simulation_study`: A dictionary containing the raw `pd.DataFrame` from the Monte Carlo simulation (if run).\n",
        "-   `reports`: A dictionary containing all generated outputs, including styled `pd.DataFrame` objects for each table, `matplotlib` figure objects for plots, and the final reproducibility report.\n",
        "\n",
        "## Project Structure\n",
        "\n",
        "```\n",
        "high_dimensional_matrix_variate_diffusion_index_models/\n",
        "│\n",
        "├── high_dimensional_matrix_variate_diffusion_index_models_draft.ipynb  # Main implementation notebook   \n",
        "├── requirements.txt                                                      # Python package dependencies\n",
        "├── LICENSE                                                               # MIT license file\n",
        "└── README.md                                                             # This documentation file\n",
        "```\n",
        "\n",
        "## Customization\n",
        "\n",
        "The pipeline is highly customizable via the master `study_config` dictionary. Users can easily modify:\n",
        "-   The `alpha_grid` and `factor_dimensions_grid` for the empirical study.\n",
        "-   The `train_test_split_config` to change the out-of-sample period.\n",
        "-   All parameters for the Monte Carlo simulations (`p`, `q`, `T`, DGPs, etc.).\n",
        "-   The `screening_thresholds` for the supervised refinement step.\n",
        "\n",
        "## Contributing\n",
        "\n",
        "Contributions are welcome. Please fork the repository, create a feature branch, and submit a pull request with a clear description of your changes. Adherence to PEP 8, type hinting, and comprehensive docstrings is required.\n",
        "\n",
        "## License\n",
        "\n",
        "This project is licensed under the MIT License. See the `LICENSE` file for details.\n",
        "\n",
        "## Citation\n",
        "\n",
        "If you use this code or the methodology in your research, please cite the original paper:\n",
        "\n",
        "```bibtex\n",
        "@article{ma2025high,\n",
        "  title={High-Dimensional Matrix-Variate Diffusion Index Models for Time Series Forecasting},\n",
        "  author={Ma, Zhiren and Zhao, Qian and Zhang, Riquan and Gao, Zhaoxing},\n",
        "  journal={arXiv preprint arXiv:2508.04259},\n",
        "  year={2025}\n",
        "}\n",
        "```\n",
        "\n",
        "For the implementation itself, you may cite this repository:\n",
        "```\n",
        "Chirinda, C. (2025). A Python Implementation of \"High-Dimensional Matrix-Variate Diffusion Index Models for Time Series Forecasting\".\n",
        "GitHub repository: https://github.com/chirindaopensource/high_dimensional_matrix_variate_diffusion_index_models\n",
        "```\n",
        "\n",
        "## Acknowledgments\n",
        "\n",
        "-   Credit to Zhiren Ma, Qian Zhao, Riquan Zhang, and Zhaoxing Gao for their clear and insightful research.\n",
        "-   Thanks to the developers of the scientific Python ecosystem (`numpy`, `pandas`, `scipy`, `statsmodels`, `scikit-learn`) that makes this work possible.\n",
        "\n",
        "--\n",
        "\n",
        "*This README was generated based on the structure and content of `high_dimensional_matrix_variate_diffusion_index_models_draft.ipynb` and follows best practices for research software documentation.*"
      ],
      "metadata": {
        "id": "zWPNMW2veZqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paper\n",
        "\n",
        "Title: \"*High-Dimensional Matrix-Variate Diffusion Index Models for Time Series Forecasting*\"\n",
        "\n",
        "Authors: Zhiren Ma, Qian Zhao, Riquan Zhang, Zhaoxing Gao\n",
        "\n",
        "E-Journal Submission Date: 6 August 2025\n",
        "\n",
        "Link: https://arxiv.org/abs/2508.04259\n",
        "\n",
        "Abstract:\n",
        "\n",
        "This paper proposes a novel diffusion-index model for forecasting when predictors are high-dimensional matrix-valued time series. We apply an alpha-PCA method to extract low-dimensional matrix factors and build a bilinear regression linking future outcomes to these factors, estimated via iterative least squares. To handle weak factor structures, we introduce a supervised screening step to select informative rows and columns. Theoretical properties, including consistency and asymptotic normality, are established. Simulations and real data show that our method significantly improves forecast accuracy, with the screening procedure providing additional gains over standard benchmarks in out-of-sample mean squared forecast error.\n"
      ],
      "metadata": {
        "id": "09daHRzLvX18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "Here is a breakdown of the paper \"High-Dimensional Matrix-Variate Diffusion Index Models for Time Series Forecasting\" by Ma, Zhao, Zhang, and Gao.\n",
        "\n",
        "--\n",
        "\n",
        "### **Overall Summary**\n",
        "\n",
        "The authors propose a novel framework for forecasting a single time series (e.g., GDP growth) using a large panel of predictors that have a natural matrix structure (e.g., multiple economic indicators for multiple countries). Traditional methods either cannot handle such high-dimensional data or require \"vectorizing\" the matrix, which destroys its inherent row-column structure. This paper's core contribution is a **Matrix-Variate Diffusion Index (MV-DI)** model that preserves this structure, extracts a small number of latent *matrix* factors, and uses them for forecasting. They enhance this with a clever supervised screening step and provide rigorous theoretical guarantees and strong empirical validation.\n",
        "\n",
        "--\n",
        "\n",
        "### **Step-by-Step Breakdown**\n",
        "\n",
        "#### **Step 1: The Core Problem and Proposed Model**\n",
        "\n",
        "The paper addresses the problem of forecasting a scalar time series, $y_{t+h}$, using a high-dimensional $p \\times q$ matrix of predictors, $X_t$.\n",
        "\n",
        "The central model is formulated in Equation (2) as a two-part system:\n",
        "\n",
        "1.  **Factor Model for Predictors:** $X_t = R F_t C' + E_t$\n",
        "2.  **Forecasting Equation:** $y_{t+h} = \\alpha' F_t \\beta + e_{t+h}$\n",
        "\n",
        "Let's break down these components:\n",
        "*   $X_t$: The large, observable $p \\times q$ predictor matrix at time $t$.\n",
        "*   $F_t$: The unobserved, low-dimensional $k \\times r$ **latent matrix factor** (where $k \\ll p$ and $r \\ll q$). This is the \"diffusion index\" in matrix form, capturing the core dynamics of the entire predictor set.\n",
        "*   $R$ and $C$: These are the $p \\times k$ and $q \\times r$ **loading matrices** that map the low-dimensional factor back to the high-dimensional predictor space.\n",
        "*   $E_t$ and $e_{t+h}$: These are noise terms.\n",
        "*   $\\alpha$ and $\\beta$: These are the $k \\times 1$ and $r \\times 1$ **loading vectors** that define how the latent matrix factor $F_t$ predicts the future outcome $y_{t+h}$ through a bilinear relationship.\n",
        "\n",
        "This model is powerful because it reduces the dimensionality from $p \\times q$ predictors to a much smaller $k \\times r$ matrix factor, avoiding the curse of dimensionality while preserving the intrinsic row-column relationships.\n",
        "\n",
        "#### **Step 2: The Two-Stage Estimation Procedure**\n",
        "\n",
        "The authors propose a two-stage procedure to estimate the model's parameters.\n",
        "\n",
        "**Stage 1: Latent Factor Extraction via α-PCA**\n",
        "Since the factors $F_t$ are latent, they must first be estimated from the observed data $X_t$. The authors use a recently developed method called **α-PCA** (from Chen and Fan, 2023).\n",
        "\n",
        "*   **What is α-PCA?** Unlike standard PCA which only considers the covariance structure (second moment) of the data, α-PCA constructs two matrices, $M_R$ and $M_C$, that are a weighted average of the data's second moment and its cross-product matrix ($X'X$), which relates to the first moment. The hyperparameter $\\alpha$ controls this balance.\n",
        "*   **How it works:** The loading matrices $\\hat{R}$ and $\\hat{C}$ are estimated as the top eigenvectors of $M_R$ and $M_C$, respectively.\n",
        "*   **Factor Recovery:** With the estimated loadings, the latent factor matrix is recovered as $\\hat{F}_t = \\frac{1}{pq} \\hat{R}' X_t \\hat{C}$.\n",
        "\n",
        "**Stage 2: Forecasting Parameter Estimation via Iterative Least Squares (LSE)**\n",
        "Once the factor estimates $\\hat{F}_t$ are obtained, the forecasting equation becomes $y_{t+h} \\approx \\alpha' \\hat{F}_t \\beta$. This is a bilinear regression problem, not a standard linear one. The authors use an **Iterative Least Squares** procedure (also known as Alternating Least Squares):\n",
        "\n",
        "1.  Initialize $\\beta$ (e.g., with a random vector).\n",
        "2.  **Holding $\\beta$ fixed**, the equation becomes linear in $\\alpha$. Solve for $\\hat{\\alpha}$ using ordinary least squares (OLS).\n",
        "3.  **Holding the new $\\hat{\\alpha}$ fixed**, the equation becomes linear in $\\beta$. Solve for $\\hat{\\beta}$ using OLS.\n",
        "4.  Repeat steps 2 and 3 until the estimates for $\\alpha$ and $\\beta$ converge.\n",
        "\n",
        "#### **Step 3: The Novel Refinement - Supervised Screening**\n",
        "\n",
        "This is a key practical innovation. The α-PCA in Stage 1 is **unsupervised**; it extracts factors from $X_t$ without any knowledge of the target variable $y_t$. This means it might extract factors that are good at explaining $X_t$ but irrelevant for predicting $y_t$.\n",
        "\n",
        "To fix this, the authors introduce a **supervised screening** pre-processing step (Algorithm 1):\n",
        "\n",
        "1.  **Correlate:** For every element $x_{ij,t}$ in the predictor matrix, calculate its correlation with the target series $y_t$.\n",
        "2.  **Aggregate:** For each row $i$ and each column $j$, calculate the *average* of these correlations. This gives a measure of how informative that entire row (e.g., a country) or column (e.g., an economic indicator) is for the forecast.\n",
        "3.  **Filter:** Set a threshold. Remove any rows or columns whose average correlation is below this threshold.\n",
        "4.  **Proceed:** Apply the two-stage estimation procedure (α-PCA + LSE) to this new, smaller, more informative predictor matrix $\\tilde{X}_t$.\n",
        "\n",
        "This simple step intelligently uses information from the target variable to filter out noise *before* dimension reduction, leading to more relevant factors and better forecasts.\n",
        "\n",
        "#### **Step 4: Theoretical Guarantees**\n",
        "\n",
        "A major part of the paper is dedicated to establishing the statistical validity of their estimators. Under standard assumptions for high-dimensional time series (mixing conditions, properties of noise), they prove:\n",
        "\n",
        "*   **Consistency:** As the dimensions ($p, q$) and the time series length ($T$) grow, their estimators for the loadings ($\\hat{R}, \\hat{C}, \\hat{\\alpha}, \\hat{\\beta}$) and the factors ($\\hat{F}_t$) converge to their true values (up to an unidentifiable rotation, which is standard in factor models).\n",
        "*   **Asymptotic Normality:** The estimators for the forecasting parameters, $\\hat{\\alpha}$ and $\\hat{\\beta}$, are asymptotically normally distributed. This is a crucial result, as it allows for the construction of confidence intervals and hypothesis testing, making the model useful for statistical inference, not just point forecasting.\n",
        "\n",
        "#### **Step 5: Empirical Validation**\n",
        "\n",
        "The authors rigorously test their model using both simulated and real-world data.\n",
        "\n",
        "*   **Simulation Study:** They generate data from known models to verify their theory. The results confirm that:\n",
        "    *   Estimation error decreases as data dimensions and length increase, validating the consistency results.\n",
        "    *   The distribution of the estimators matches a normal distribution for large samples, validating the asymptotic normality.\n",
        "    *   Crucially, the **supervised screening step dramatically improves forecast accuracy** (reducing Mean Squared Forecast Error, or MSFE) when the original data contains irrelevant noise, with observed error reductions of up to 60.7%.\n",
        "\n",
        "*   **Real-World Application:** They apply their model to a real dataset of 10 quarterly macroeconomic indicators for 14 OECD countries (a $14 \\times 10$ matrix) to forecast aggregate OECD GDP growth.\n",
        "    *   **Benchmark Comparison:** Their proposed **α-PCA-LSE model significantly outperforms** standard benchmarks, including a vectorized model with Lasso regularization and a simple autoregressive (AR) model.\n",
        "    *   **Screening Effectiveness:** Applying the supervised screening step to the real data **further reduces the forecasting error**, demonstrating that the refinement is not just a theoretical curiosity but a practically valuable tool. The best-performing model is the one that combines the core methodology with the screening refinement.\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "This paper makes a strong contribution by developing a complete and coherent framework for a very relevant modern problem. They have:\n",
        "1.  Extended the classical diffusion index model to the matrix-variate setting.\n",
        "2.  Combined state-of-the-art statistical tools (α-PCA, Iterative LSE) into a novel estimation pipeline.\n",
        "3.  Introduced an intuitive and highly effective supervised screening method to boost performance.\n",
        "4.  Provided the necessary theoretical foundations to ensure the statistical reliability of their method.\n",
        "\n",
        "The work is methodologically sound and empirically convincing. The supervised screening step is particularly elegant in its simplicity and effectiveness, offering a clear lesson on the power of incorporating domain-specific information (in this case, the relevance to the forecast target) into otherwise unsupervised learning techniques. This is a high-quality paper that should be of great interest to researchers in financial econometrics, macro-forecasting, and high-dimensional statistics."
      ],
      "metadata": {
        "id": "tEoxwq97bOmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Essential Modules"
      ],
      "metadata": {
        "id": "AcuOH9dQVHF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# =============================================================================\n",
        "#\n",
        "#  High-Dimensional Matrix-Variate Diffusion Index Models for Time Series Forecasting\n",
        "#\n",
        "#  This module provides a complete, professional-grade, and end-to-end\n",
        "#  implementation of the analytical framework presented in \"High-Dimensional\n",
        "#  Matrix-Variate Diffusion Index Models for Time Series Forecasting\" by Ma,\n",
        "#  Zhao, Zhang, and Gao (2025). It delivers a robust system for forecasting a\n",
        "#  scalar target variable using a high-dimensional panel of matrix-valued\n",
        "#  predictor data, with a focus on methodological rigor and reproducibility.\n",
        "#\n",
        "#  Core Methodological Components:\n",
        "#  • α-PCA for latent matrix factor extraction from high-dimensional tensors.\n",
        "#  • Iterative Least Squares (ILS) for estimating bilinear forecasting models.\n",
        "#  • Supervised screening for predictor refinement based on target correlation.\n",
        "#  • A full suite of benchmark models (AR, Vectorized OLS, Vectorized Lasso).\n",
        "#  • Robust out-of-sample evaluation using the Diebold-Mariano test.\n",
        "#  • A comprehensive Monte Carlo framework for validating estimator properties.\n",
        "#\n",
        "#  Technical Implementation Features:\n",
        "#  • Leak-free time series data preparation (stationarity and centralization).\n",
        "#  • Numerically stable algorithms for eigendecomposition and linear systems.\n",
        "#  • Efficient, vectorized tensor operations using `numpy.einsum`.\n",
        "#  • A modular, multi-stage pipeline with rigorous input validation.\n",
        "#  • A complete suite of robustness checks (sensitivity, CV, stability).\n",
        "#  • Publication-quality reporting and diagnostic visualization tools.\n",
        "#\n",
        "#  Paper Reference:\n",
        "#  Ma, Z., Zhao, Q., Zhang, R., & Gao, Z. (2025). High-Dimensional Matrix-Variate\n",
        "#  Diffusion Index Models for Time Series Forecasting. arXiv preprint\n",
        "#  arXiv:2508.04259.\n",
        "#  https://arxiv.org/abs/2508.04259\n",
        "#\n",
        "#  Author: CS Chirinda\n",
        "#  License: MIT\n",
        "#  Version: 1.0.0\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "# =============================================================================\n",
        "# STANDARD LIBRARIES\n",
        "# =============================================================================\n",
        "import copy\n",
        "import datetime\n",
        "import json\n",
        "import math\n",
        "import platform\n",
        "import sys\n",
        "import warnings\n",
        "from itertools import product\n",
        "from typing import Any, Dict, List, Optional, Set, Tuple, Union, Callable\n",
        "\n",
        "# =============================================================================\n",
        "# THIRD-PARTY LIBRARIES\n",
        "# =============================================================================\n",
        "\n",
        "# Core numerical and data manipulation libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Scientific and statistical computing\n",
        "import scipy.linalg\n",
        "import scipy.stats\n",
        "from scipy.stats import t\n",
        "\n",
        "# Machine learning and econometrics\n",
        "import statsmodels\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "from statsmodels.tsa.stattools import acovf\n",
        "\n",
        "# Parallel processing and progress monitoring\n",
        "import joblib\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Plotting and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "rgHI_ffXVL1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation"
      ],
      "metadata": {
        "id": "lpnc2KPqVOcL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Draft 1\n",
        "\n",
        "### Discussion of the Inputs, Processes and Outputs (IPO) Of Key Callables\n",
        "\n",
        "\n",
        "### **Explication of All Implemented Callables**\n",
        "\n",
        "#### **Task 1: `validate_input_data`**\n",
        "\n",
        "*   **Inputs:** Raw `country_data` (Dict of DataFrames), raw `y_series` (Series), and the `study_manifest` (Dict).\n",
        "*   **Processes:**\n",
        "    1.  Performs a series of rigorous checks on the inputs.\n",
        "    2.  Verifies the structure, keys, and value types of the `country_data` dictionary.\n",
        "    3.  Validates the column names, dtypes, and temporal index of every DataFrame and the `y_series`, ensuring perfect alignment and quarterly frequency.\n",
        "    4.  Assesses data quality by scanning for NaNs, infinities, constant series, and significant outliers.\n",
        "    5.  Checks the `study_manifest` for the presence and validity of critical parameters.\n",
        "*   **Outputs:** A tuple containing a master boolean `is_valid` flag and a detailed `validation_report` dictionary.\n",
        "*   **Transformation:** This function is a validator, not a transformer. It inspects data and returns a structured report on its integrity without altering the data itself.\n",
        "*   **Role in Research Pipeline:** This function serves as the **Gatekeeper** for the entire pipeline. While not based on a specific equation, it enforces the implicit assumptions of data quality and structural consistency required for all subsequent mathematical operations to be valid. It is the implementation of **methodological rigor** at the data ingestion stage.\n",
        "\n",
        "#### **Task 2: `prepare_forecasting_data`**\n",
        "\n",
        "*   **Inputs:** Raw `country_data`, raw `y_series`, the `study_manifest`, and the `training_size`.\n",
        "*   **Processes:**\n",
        "    1.  Applies stationarity-inducing transformations (logarithms, first/second differencing) to all 141 time series based on sequential Augmented Dickey-Fuller tests.\n",
        "    2.  Calculates the mean of each transformed series using **only the training data portion**.\n",
        "    3.  Centralizes the entire transformed series (both train and test portions) by subtracting the corresponding **training mean**, thus preventing data leakage.\n",
        "    4.  Aligns all 141 fully prepared series to find a common, non-missing time window.\n",
        "    5.  Splits the aligned data into final, dense `numpy` tensors for training and testing.\n",
        "*   **Outputs:** A dictionary containing the leak-free `X_train`, `y_train`, `X_test`, `y_test` tensors, the final `DatetimeIndex`, and a detailed transformation log.\n",
        "*   **Transformation:** It transforms raw, potentially non-stationary and misaligned data into clean, stationary, centralized, and perfectly aligned training and testing sets ready for modeling.\n",
        "*   **Role in Research Pipeline:** This function implements the **Data Preparation and Leakage Prevention** protocol. It is the practical application of the \"mixing conditions\" mentioned in **Assumption 1** of the paper, ensuring the time series are stationary and suitable for the model's theoretical framework. Its most critical role is to uphold the integrity of the out-of-sample evaluation by strictly separating training and testing information.\n",
        "\n",
        "#### **Task 3: `compute_sample_statistics`**\n",
        "\n",
        "*   **Inputs:** A single `(T, p, q)` predictor tensor (e.g., `X_train`).\n",
        "*   **Processes:**\n",
        "    1.  Calculates the sample mean matrix by averaging the input tensor along its time dimension (axis 0).\n",
        "    2.  Calculates the deviation tensor by subtracting the computed sample mean matrix from each time-slice of the input tensor.\n",
        "*   **Outputs:** A tuple containing the `(p, q)` sample mean matrix and the `(T, p, q)` deviation tensor.\n",
        "*   **Transformation:** It transforms a time series of matrices into its first-order summary statistics: its central tendency ($\\overline{\\boldsymbol{X}}$) and its variation around that tendency ($\\boldsymbol{X}_t - \\overline{\\boldsymbol{X}}$).\n",
        "*   **Role in Research Pipeline:** This function computes the **Fundamental Building Blocks for α-PCA**. It directly calculates the terms $\\overline{\\boldsymbol{X}}$ and $(\\boldsymbol{X}_t - \\overline{\\boldsymbol{X}})$ that are required in the construction of the moment aggregation matrices in **Equations (3) and (4)**.\n",
        "\n",
        "#### **Task 4: `construct_moment_aggregation_matrices`**\n",
        "\n",
        "*   **Inputs:** The `(p, q)` sample mean matrix, the `(T, p, q)` deviation tensor, and the scalar hyperparameter `alpha`.\n",
        "*   **Processes:**\n",
        "    1.  Calculates the first-moment components ($(1+\\alpha) \\overline{\\boldsymbol{X}} \\overline{\\boldsymbol{X}}^\\prime$ and $(1+\\alpha) \\overline{\\boldsymbol{X}}^\\prime \\overline{\\boldsymbol{X}}$).\n",
        "    2.  Calculates the second-moment components by summing the outer products of the deviation matrices over time.\n",
        "    3.  Combines these components and scales them by $\\frac{1}{pq}$.\n",
        "    4.  Enforces perfect numerical symmetry on the final matrices.\n",
        "*   **Outputs:** A tuple containing the `(p, p)` row aggregation matrix $\\widehat{\\boldsymbol{M}}_R$ and the `(q, q)` column aggregation matrix $\\widehat{\\boldsymbol{M}}_C$.\n",
        "*   **Transformation:** It transforms the time-series summary statistics into two static, square matrices that aggregate the first and second moment information of the entire dataset, weighted by `alpha`.\n",
        "*   **Role in Research Pipeline:** This is the direct and precise implementation of the **α-PCA Moment Aggregation** step, as defined in **Equations (3) and (4)** of the paper:\n",
        "    $$ \\widehat{\\boldsymbol{M}}_R = \\frac{1}{pq} \\left[ (1+\\alpha) \\overline{\\boldsymbol{X}} \\overline{\\boldsymbol{X}}^\\prime + \\frac{1}{T} \\sum_{t=1}^T (\\boldsymbol{X}_t - \\overline{\\boldsymbol{X}}) (\\boldsymbol{X}_t - \\overline{\\boldsymbol{X}})^\\prime \\right] $$\n",
        "    $$ \\widehat{\\boldsymbol{M}}_C = \\frac{1}{pq} \\left[ (1+\\alpha) \\overline{\\boldsymbol{X}}^\\prime \\overline{\\boldsymbol{X}} + \\frac{1}{T} \\sum_{t=1}^T (\\boldsymbol{X}_t - \\overline{\\boldsymbol{X}})^\\prime (\\boldsymbol{X}_t - \\overline{\\boldsymbol{X}}) \\right] $$\n",
        "\n",
        "#### **Task 5: `extract_loadings_and_dimensions`**\n",
        "\n",
        "*   **Inputs:** The moment matrices $\\widehat{\\boldsymbol{M}}_R$ and $\\widehat{\\boldsymbol{M}}_C$, data dimensions `p` and `q`, max factor dimensions `k_max` and `r_max`, and an optional `fixed_kr` tuple.\n",
        "*   **Processes:**\n",
        "    1.  Performs a numerically stable eigendecomposition of $\\widehat{\\boldsymbol{M}}_R$ and $\\widehat{\\boldsymbol{M}}_C$.\n",
        "    2.  Sorts the eigenvalues and eigenvectors in descending order and applies a deterministic sign convention.\n",
        "    3.  If `fixed_kr` is not provided, it estimates the number of factors `k` and `r` using the eigenvalue ratio test.\n",
        "    4.  If `fixed_kr` is provided, it bypasses estimation and uses the fixed values.\n",
        "    5.  Constructs the loading matrices $\\widehat{\\boldsymbol{R}}$ and $\\widehat{\\boldsymbol{C}}$ by taking the top `k` and `r` scaled eigenvectors.\n",
        "    6.  Performs a final validation to ensure the loading matrices satisfy their orthogonality constraints.\n",
        "*   **Outputs:** A dictionary containing the estimated/fixed dimensions (`k_hat`, `r_hat`), the loading matrices (`R_hat`, `C_hat`), and the full spectrum of eigenvalues.\n",
        "*   **Transformation:** It transforms the moment aggregation matrices into the low-dimensional loading matrices that define the factor space.\n",
        "*   **Role in Research Pipeline:** This function implements the **Spectral Analysis and Dimension Reduction** core of the α-PCA method. It is the practical application of the procedure described in **Section 2.1** and the dimension estimation method from **Section 2.3**, which is based on the eigenvalue ratio test:\n",
        "    $$ \\widehat{k} = \\underset{1 \\leq j \\leq k_{\\max}}{\\operatorname{argmax}} \\frac{\\widehat{\\lambda}_{R,j}}{\\widehat{\\lambda}_{R,j+1}} $$\n",
        "\n",
        "#### **Task 6: `estimate_factor_matrices`**\n",
        "\n",
        "*   **Inputs:** A `(T, p, q)` data tensor, the `(p, k)` loading matrix `R_hat`, and the `(q, r)` loading matrix `C_hat`.\n",
        "*   **Processes:**\n",
        "    1.  For each time slice `t`, it projects the data matrix $\\boldsymbol{X}_t$ onto the estimated factor space using the loading matrices.\n",
        "    2.  Optionally, it reconstructs the data from the estimated factors and calculates the mean squared reconstruction error.\n",
        "*   **Outputs:** A dictionary containing the `(T, k, r)` latent factor tensor `F_hat_tensor` and, optionally, the reconstruction error.\n",
        "*   **Transformation:** It transforms the high-dimensional `(T, p, q)` observed data into the low-dimensional `(T, k, r)` latent factor representation.\n",
        "*   **Role in Research Pipeline:** This function implements the **Factor Recovery** step. It is the direct implementation of the equation for $\\hat{F}_t$ presented in **Section 2.1**:\n",
        "    $$ \\widehat{\\boldsymbol{F}}_t = \\frac{1}{pq} \\widehat{\\boldsymbol{R}}^\\prime \\boldsymbol{X}_t \\widehat{\\boldsymbol{C}} $$\n",
        "\n",
        "#### **Task 7: `setup_lse_training_data`**\n",
        "\n",
        "*   **Inputs:** The `(T, k, r)` factor tensor, the `(T,)` target vector, `training_size`, `forecast_horizon`, and an optional `random_seed`.\n",
        "*   **Processes:**\n",
        "    1.  Initializes the `alpha` and `beta` parameter vectors by sampling from a standard normal distribution, ensuring reproducibility via the random seed.\n",
        "    2.  Normalizes the initial `alpha` vector to have a unit L2 norm, satisfying a key identification constraint.\n",
        "    3.  Slices the factor tensor and target vector to create perfectly aligned training sets, ensuring that predictor `F_t` is matched with target `y_{t+h}`.\n",
        "*   **Outputs:** A dictionary containing the `F_train` tensor, the `y_train_target` vector, and the initialized `alpha_init` and `beta_init` vectors.\n",
        "*   **Transformation:** It transforms the full factor and target series into the specific, aligned data structures and initial parameter guesses required to start the iterative optimization.\n",
        "*   **Role in Research Pipeline:** This function is the **Initialization and Data Staging for the Forecasting Model**. It prepares the inputs for the Iterative Least Squares (ILS/LSE) algorithm described in **Section 2.2**.\n",
        "\n",
        "#### **Task 8: `estimate_lse_parameters`**\n",
        "\n",
        "*   **Inputs:** The `F_train` tensor, `y_train_target` vector, initial `alpha` and `beta` vectors, and convergence parameters.\n",
        "*   **Processes:**\n",
        "    1.  Enters a loop that alternates between updating `alpha` and `beta`.\n",
        "    2.  In the `alpha` update, it fixes `beta` and solves a standard OLS problem for `alpha`.\n",
        "    3.  In the `beta` update, it fixes the new `alpha` and solves a standard OLS problem for `beta`.\n",
        "    4.  It uses a numerically stable linear system solver (`scipy.linalg.solve`) with a regularization fallback for ill-conditioned systems.\n",
        "    5.  It monitors the change in the parameter vectors and terminates upon convergence or reaching the maximum number of iterations.\n",
        "*   **Outputs:** A dictionary containing the converged `alpha_hat` and `beta_hat` vectors, and convergence diagnostics.\n",
        "*   **Transformation:** It transforms the initial parameter guesses into their final, optimized least-squares estimates.\n",
        "*   **Role in Research Pipeline:** This is the direct implementation of the **Iterative Least Squares (Alternating Least Squares) Algorithm** used to estimate the forecasting equation parameters, as derived from the first-order conditions in **Equations (6) and (7)**.\n",
        "\n",
        "#### **Task 9: `compute_supervised_correlation_scores`**\n",
        "\n",
        "*   **Inputs:** The `(T_train, p, q)` training predictor tensor and the `(T_train,)` training target vector.\n",
        "*   **Processes:**\n",
        "    1.  Calculates the Pearson correlation coefficient between each of the `p*q` predictor series and the target series, using **only the training data**.\n",
        "    2.  Aggregates these pairwise correlations by computing the mean of their absolute values along each row (country) and each column (indicator).\n",
        "*   **Outputs:** A dictionary containing the `(p, q)` correlation matrix and the `(p,)` and `(q,)` Series of average row and column correlations.\n",
        "*   **Transformation:** It transforms the training data into a set of relevance scores for each predictor entity (row) and attribute (column).\n",
        "*   **Role in Research Pipeline:** This function implements the **Supervised Signal Extraction** step, which is the core of the refinement procedure described in **Section 4**. It computes the correlation matrix $\\boldsymbol{P}$ where $P_{ij} = \\text{corr}(y_t, x_{ij,t})$ and the average scores $\\bar{\\rho}_i$ and $\\bar{\\rho}_j$ that will be used for screening.\n",
        "\n",
        "#### **Task 10: `perform_supervised_screening`**\n",
        "\n",
        "*   **Inputs:** A full `(T, p, q)` data tensor, the average correlation scores for rows and columns, and the row and column thresholds.\n",
        "*   **Processes:**\n",
        "    1.  Identifies the set of row and column indices that meet or exceed the specified correlation thresholds.\n",
        "    2.  Uses these indices to slice the input data tensor, creating a new, smaller tensor.\n",
        "*   **Outputs:** A dictionary containing the refined `(T, \\tilde{p}, \\tilde{q})` tensor and the lists of retained row and column names.\n",
        "*   **Transformation:** It transforms a large data tensor into a smaller, more relevant data tensor by filtering out uninformative rows and columns.\n",
        "*   **Role in Research Pipeline:** This function implements the **Filtering Algorithm** of the supervised screening procedure from **Section 4**. It applies the thresholds to the scores computed in the previous task to construct the refined observation matrix $\\widetilde{\\boldsymbol{X}}_t$.\n",
        "\n",
        "#### **Task 11: `run_apca_pipeline`**\n",
        "\n",
        "*   **Inputs:** A `(T, p, q)` data tensor, the `alpha` hyperparameter, and an optional `fixed_kr` tuple.\n",
        "*   **Processes:** It orchestrates a complete, sequential execution of Tasks 3, 4, 5, and 6. It takes a data tensor and returns the full set of α-PCA results. Its key feature is the ability to either estimate the factor dimensions `(k, r)` or use the `fixed_kr` values provided.\n",
        "*   **Outputs:** A dictionary containing all key α-PCA artifacts (`F_hat_tensor`, `R_hat`, `C_hat`, `k_hat`, `r_hat`, etc.).\n",
        "*   **Transformation:** This is a meta-function that encapsulates the entire transformation from an observed data tensor to its latent factor representation.\n",
        "*   **Role in Research Pipeline:** This is the **Master α-PCA Workflow Component**. It represents the entire methodology of **Section 2.1** as a single, reusable, and flexible function.\n",
        "\n",
        "#### **Task 12: `generate_out_of_sample_forecasts`**\n",
        "\n",
        "*   **Inputs:** The `(T_test, p, q)` test predictor tensor, the `(p, k)` and `(q, r)` loading matrices from training, the `(k,)` and `(r,)` estimated forecasting parameters, and the forecast horizon `h`.\n",
        "*   **Processes:**\n",
        "    1.  Projects the out-of-sample predictor data `X_test` into the latent factor space using the *training-derived* loading matrices.\n",
        "    2.  Applies the estimated forecasting equation to the resulting out-of-sample factors to generate predictions.\n",
        "    3.  Aligns the forecast `DatetimeIndex` correctly using the forecast horizon.\n",
        "*   **Outputs:** A `pd.Series` of out-of-sample forecasts with a correctly aligned index.\n",
        "*   **Transformation:** It transforms out-of-sample predictor data into a final, scalar forecast series.\n",
        "*   **Role in Research Pipeline:** This function implements the **Out-of-Sample Prediction** step. It is the practical application of the estimated forecasting equation $y_{t+h} = \\alpha' F_t \\beta + e_{t+h}$ on unseen data.\n",
        "\n",
        "#### **Task 13: `compute_performance_metrics`**\n",
        "\n",
        "*   **Inputs:** Two `pd.Series`, `y_true` and `y_pred`, with `DatetimeIndex`.\n",
        "*   **Processes:**\n",
        "    1.  Rigorously aligns the two series on their common index, dropping any non-overlapping points.\n",
        "    2.  Calculates the forecast error vector.\n",
        "    3.  Computes the MSFE, RMSE, and MAE from the error vector.\n",
        "*   **Outputs:** A dictionary containing the scalar metric values and the aligned DataFrame of true values, predictions, and errors.\n",
        "*   **Transformation:** It transforms two time series into a set of scalar performance scores.\n",
        "*   **Role in Research Pipeline:** This function implements the **Forecast Evaluation**, calculating the Mean Squared Forecast Error (MSFE) as defined in **Equation (9)**:\n",
        "    $$ \\text{MSFE} = \\frac{1}{T_{\\text{test}}-h} \\sum_{j=1}^{T_{\\text{test}}-h} (\\widehat{y}_{T_{\\text{train}}+j+h} - y_{T_{\\text{train}}+j+h})^2 $$\n",
        "\n",
        "#### **Task 14: `perform_diebold_mariano_test`**\n",
        "\n",
        "*   **Inputs:** Three `pd.Series` (`y_true`, `y_pred1`, `y_pred2`) and the `forecast_horizon`.\n",
        "*   **Processes:**\n",
        "    1.  Aligns the series and computes the loss differential series, $d_t = e_{1,t}^2 - e_{2,t}^2$.\n",
        "    2.  Calculates the mean of the loss differential, $\\bar{d}$.\n",
        "    3.  Estimates the HAC variance of $\\bar{d}$, correctly accounting for autocorrelation up to lag `h-1`.\n",
        "    4.  Computes the DM statistic, applies the small-sample correction, and calculates the p-value using a t-distribution.\n",
        "*   **Outputs:** A dictionary containing the DM statistic, the p-value, and a plain-language interpretation.\n",
        "*   **Transformation:** It transforms two sets of forecasts and the true values into a statistical conclusion about their relative predictive accuracy.\n",
        "*   **Role in Research Pipeline:** This function implements the **Statistical Comparison of Forecasts**, as used in the paper's empirical section (**Section 6.2**) to formally establish the superiority of the proposed model over benchmarks.\n",
        "\n",
        "#### **Task 15: `run_all_benchmarks`**\n",
        "\n",
        "*   **Inputs:** The full data tensors, `training_size`, `forecast_horizon`, and other parameters.\n",
        "*   **Processes:** It orchestrates the training and prediction for the three benchmark models (AR(1), Vectorized OLS with pseudoinverse, and Vectorized Lasso with cross-validation) on a consistent data split.\n",
        "*   **Outputs:** A dictionary of `pd.Series`, where each series contains the out-of-sample forecasts from one benchmark model.\n",
        "*   **Transformation:** It transforms the prepared data into a set of competing forecasts.\n",
        "*   **Role in Research Pipeline:** This function implements the **Benchmark Model Suite** described in **Section 6.2**, providing the necessary competing forecasts to validate the performance of the main α-PCA-LSE model.\n",
        "\n",
        "#### **Task 16: `generate_synthetic_data`**\n",
        "\n",
        "*   **Inputs:** All model dimensions (`p, q, T, k, r`), DGP method specifications, and a `random_seed`.\n",
        "*   **Processes:** It orchestrates the calls to all the component generator functions (`generate_factor_tensor`, `generate_loading_matrices`, etc.) to construct a complete, internally consistent synthetic dataset according to the model equations.\n",
        "*   **Outputs:** A dictionary containing the `X_tensor`, the `y_vector`, and a nested dictionary with all the ground-truth components.\n",
        "*   **Transformation:** It transforms a set of parameters into a full, complex, simulated dataset.\n",
        "*   **Role in Research Pipeline:** This is the implementation of the **Data Generating Processes** described in detail in **Section 5.1**, which are essential for the Monte Carlo validation of the model's theoretical properties.\n",
        "\n",
        "#### **Task 17: `run_monte_carlo_simulation`**\n",
        "\n",
        "*   **Inputs:** The `study_manifest`.\n",
        "*   **Processes:**\n",
        "    1.  Builds a complete grid of all simulation experiments.\n",
        "    2.  Uses `joblib.Parallel` to execute hundreds of replications for each experiment in parallel.\n",
        "    3.  Each replication calls the `_run_single_replication` worker, which generates data and runs the full estimation pipeline.\n",
        "    4.  The worker computes rotation-invariant error metrics and returns them along with the estimated parameters.\n",
        "    5.  The main function aggregates all results into a single, comprehensive DataFrame.\n",
        "*   **Outputs:** A `pd.DataFrame` containing the raw results of the entire simulation study.\n",
        "*   **Transformation:** It transforms a study design (the manifest) into a large-scale empirical dataset of estimator performance.\n",
        "*   **Role in Research Pipeline:** This is the **Monte Carlo Simulation Engine**, the practical implementation of the study described in **Section 5** to produce the data needed for Tables 1 and 2 and the diagnostic plots.\n",
        "\n",
        "#### **Task 18: `run_empirical_study_orchestrator`**\n",
        "\n",
        "*   **Inputs:** Raw `country_data`, `y_series`, and the `study_manifest`.\n",
        "*   **Processes:** This is the master workflow for the empirical analysis. It correctly sequences all the necessary steps: leak-free data preparation, running the main model grid search on both unscreened and screened data, running all benchmarks on both unscreened and screened data, and performing the final significance tests.\n",
        "*   **Outputs:** A comprehensive dictionary containing all results from the empirical study.\n",
        "*   **Transformation:** It transforms raw data and a study design into a complete set of empirical findings.\n",
        "*   **Role in Research Pipeline:** This is the **Master Empirical Script**, the complete and correct implementation of the entire empirical study described in **Section 6**.\n",
        "\n",
        "#### **Task 19: `run_full_robustness_analysis`**\n",
        "\n",
        "*   **Inputs:** Raw `country_data`, `y_series`, and the `study_manifest`.\n",
        "*   **Processes:** It orchestrates the execution of the three major robustness checks: parameter sensitivity, forward-chaining cross-validation, and subsample stability assessment, by repeatedly calling the main empirical study orchestrator with modified data or parameters.\n",
        "*   **Outputs:** A nested dictionary containing the detailed results from all robustness checks.\n",
        "*   **Transformation:** It transforms the main empirical study into a broader analysis of the stability and robustness of its findings.\n",
        "*   **Role in Research Pipeline:** This function implements the **Advanced Model Validation** protocols described in **Task 19**, which are essential for a professional-grade research project.\n",
        "\n",
        "#### **Task 20: Reporting Functions (`format_table_4`, `format_table_5`, etc.)**\n",
        "\n",
        "*   **Inputs:** The raw results DataFrames and dictionaries produced by the orchestrator functions.\n",
        "*   **Processes:** These functions take the raw numerical output and apply aggregation (`groupby`, `mean`, `std`), reshaping (`pivot_table`, `unstack`), and styling (`pandas.Styler`) to produce publication-quality tables. The plotting function uses `matplotlib` and `scipy` to generate diagnostic plots. The reproducibility function uses standard libraries to capture the computational environment.\n",
        "*   **Outputs:** Styled `pd.DataFrame` objects, `matplotlib` figures, and a report dictionary.\n",
        "*   **Transformation:** They transform raw, machine-readable data into formatted, human-readable outputs (tables, plots, reports).\n",
        "*   **Role in Research Pipeline:** These functions are the **Presentation Layer**, responsible for creating the final outputs that would appear in a publication, such as **Tables 1, 2, 4, 5** and the appendix figures.\n",
        "\n",
        "### Usage Example\n",
        "\n",
        "### **Example Usage of the End-to-End Research Pipeline**\n",
        "\n",
        "This example demonstrates how a researcher would use the `run_complete_study` function to replicate the findings of the paper. It covers the setup of the necessary inputs and the final call to the orchestrator.\n",
        "\n",
        "--\n",
        "\n",
        "#### **Step 1: Data Loading and Preparation**\n",
        "\n",
        "Before calling the pipeline, the user is responsible for loading the raw data into the specified formats. We will simulate this step by creating placeholder data that matches the required structure.\n",
        "\n",
        "```python\n",
        "# In a real-world scenario, this data would be loaded from CSV files, a database,\n",
        "# or an API like the OECD Data Explorer. For this example, we create synthetic\n",
        "# data that conforms to the exact input requirements of our pipeline.\n",
        "\n",
        "# Define the dimensions and time index based on the paper's empirical study.\n",
        "T = 107\n",
        "p = 14\n",
        "q = 10\n",
        "countries = ['USA', 'CAN', 'NLD', 'AUS', 'NOR', 'IRL', 'DNK', 'GBR', 'FIN', 'SWE', 'FRA', 'NZL', 'AUT', 'DEU']\n",
        "indicators = ['P:TIEC', 'P:TM', 'GDP', 'CPI:Food', 'CPI:Ener', 'CPI:Tot', 'IR:Long', 'IR:3-Mon', 'IT:Ex', 'IT:Im']\n",
        "date_index = pd.date_range(start='1993-01-01', periods=T, freq='QS-JAN')\n",
        "\n",
        "# Create the dictionary of predictor DataFrames.\n",
        "# Each DataFrame represents a country and has indicators as columns.\n",
        "country_data_raw = {}\n",
        "for country in countries:\n",
        "    # Generate random data for demonstration purposes.\n",
        "    data = np.random.randn(T, q)\n",
        "    country_data_raw[country] = pd.DataFrame(data, index=date_index, columns=indicators)\n",
        "\n",
        "# Create the target variable Series.\n",
        "y_series_raw = pd.Series(np.random.randn(T), index=date_index, name='OECD_GDPG')\n",
        "\n",
        "print(\"Step 1: Raw data loaded into the required formats.\")\n",
        "print(f\"Predictor data structure: Dict with {len(country_data_raw)} countries.\")\n",
        "print(f\"Target data structure: pd.Series with {len(y_series_raw)} observations.\")\n",
        "```\n",
        "\n",
        "--\n",
        "\n",
        "#### **Step 2: Defining the Study Manifest**\n",
        "\n",
        "The `study_manifest` is the central configuration object for the entire project. It is a nested dictionary that contains every parameter needed for the empirical study, simulations, and robustness checks. Using a single, comprehensive manifest like this is a critical best practice for ensuring reproducibility. We will use the manifest defined in the original prompt.\n",
        "\n",
        "```python\n",
        "# This is the master study manifest, which acts as the complete set of\n",
        "# instructions for the entire research pipeline. Every parameter, from\n",
        "# train/test split sizes to hyperparameter grids, is defined here.\n",
        "\n",
        "study_manifest = {\n",
        "    'empirical_study': {\n",
        "        'parameters': {\n",
        "            'train_test_split_config': {'training_size': 86, 'testing_size': 21},\n",
        "            'forecast_horizon_h': {'value': 1},\n",
        "            'alpha_grid': {'value': [-1.0, -0.5, 0.0, 0.5, 1.0]},\n",
        "            'factor_dimensions_grid': {'value': [(6, 5), (5, 5), (4, 5), (4, 4), (3, 4), (3, 3), (3, 2)]},\n",
        "            'iterative_lse_config': {'convergence_tolerance': 1e-8, 'max_iterations': 200},\n",
        "            'cross_validation_folds': {'value': 10}\n",
        "        },\n",
        "        'data_inputs': {\n",
        "            'predictor_matrices_X_all': {\n",
        "                'T_observations': T,\n",
        "                'row_index_countries': countries,\n",
        "                'column_index_indicators': indicators\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    'simulation_study': {\n",
        "        'parameters': {\n",
        "            'monte_carlo_replications': {'value': 200},\n",
        "            'observation_dimensions_grid_pq': {'value': [(5, 10), (10, 10), (20, 20)]},\n",
        "            'latent_factor_dimensions_kr': {'value': (3, 2)},\n",
        "            'time_horizon_config': {'for_table_2': {'values': [100, 200, 400, 5000]}},\n",
        "            'alpha_pca_parameter_alpha': {'value': 0.0},\n",
        "            'config_for_normality_plots': {'p': 10, 'q': 10, 'T': 400, 'factor_method': 'matrix_normal', 'noise_method': 'uncorrelated'}\n",
        "        }\n",
        "    },\n",
        "    'screening_validation': {\n",
        "        'empirical_parameters': {\n",
        "            'screening_thresholds': {'row_threshold': 0.19, 'column_threshold': 0.16}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\nStep 2: Study manifest defined.\")\n",
        "```\n",
        "\n",
        "--\n",
        "\n",
        "#### **Step 3: Executing the Master Orchestrator**\n",
        "\n",
        "With the inputs prepared, the final step is a single call to the master orchestrator function, `run_complete_study`. We can use the boolean flags to control which parts of the analysis are performed. For this example, we will run the core empirical study and generate the final reports, but skip the computationally intensive simulation and robustness checks.\n",
        "\n",
        "```python\n",
        "# This is the final execution step. A single function call triggers the\n",
        "# entire, complex research workflow.\n",
        "\n",
        "print(\"\\nStep 3: Executing the complete study pipeline...\")\n",
        "\n",
        "# We pass the raw data and the manifest to the master orchestrator.\n",
        "# We disable the simulation and robustness checks to make the example run quickly.\n",
        "# In a real research project, these would be set to True.\n",
        "final_results = run_complete_study(\n",
        "    country_data=country_data_raw,\n",
        "    y_series=y_series_raw,\n",
        "    study_manifest=study_manifest,\n",
        "    run_empirical_study=True,\n",
        "    run_simulation_study=False,  # Set to True for full replication\n",
        "    run_robustness=False,      # Set to True for full replication\n",
        "    generate_reports=True\n",
        ")\n",
        "\n",
        "print(\"\\n--- EXECUTION COMPLETE ---\")\n",
        "```\n",
        "\n",
        "--\n",
        "\n",
        "#### **Step 4: Inspecting the Results**\n",
        "\n",
        "The `final_results` object is a deeply nested dictionary containing every artifact from the study. A researcher can now programmatically access any piece of information, from the detailed performance of a single model configuration to the final, formatted tables.\n",
        "\n",
        "```python\n",
        "# The output is a structured dictionary, making it easy to access results.\n",
        "\n",
        "print(\"\\nStep 4: Inspecting the final results...\")\n",
        "\n",
        "# --- Accessing Empirical Study Results ---\n",
        "if final_results.get('empirical_study'):\n",
        "    emp_results = final_results['empirical_study']\n",
        "    \n",
        "    print(\"\\n--- Best Model Configuration ---\")\n",
        "    print(emp_results['best_model_info'])\n",
        "    \n",
        "    print(\"\\n--- Unscreened Model Performance (Top 5) ---\")\n",
        "    print(emp_results['unscreened_results'].sort_values('MSFE').head())\n",
        "    \n",
        "    print(\"\\n--- Benchmark Performance (Unscreened) ---\")\n",
        "    print(emp_results['benchmark_results_unscreened'])\n",
        "    \n",
        "    print(\"\\n--- Significance Tests (Best Model vs. Benchmarks) ---\")\n",
        "    print(emp_results['significance_tests'])\n",
        "\n",
        "# --- Accessing Generated Reports ---\n",
        "if final_results.get('reports'):\n",
        "    reports = final_results['reports']\n",
        "    \n",
        "    print(\"\\n--- Generated Table 4 (Unscreened Results) ---\")\n",
        "    # In a Jupyter environment, this would render a styled HTML table.\n",
        "    # Here, we print the underlying DataFrame.\n",
        "    display(reports['Table 4']['Panel A'])\n",
        "    display(reports['Table 4']['Panel B'])\n",
        "    \n",
        "    print(\"\\n--- Reproducibility Report Snippet ---\")\n",
        "    repro_report = reports['reproducibility_report']\n",
        "    print(f\"Python Version: {repro_report['reproducibility_report']['generation_info']['python_version']}\")\n",
        "    print(f\"Pandas Version: {repro_report['reproducibility_report']['generation_info']['library_versions']['pandas']}\")\n",
        "```\n",
        "\n",
        "This example provides a complete and professional workflow for using the entire implemented pipeline. It demonstrates how the modular, high-rigor functions are controlled by a single, well-defined manifest and invoked through a clean, powerful orchestrator interface. This is the standard to which professional quantitative research code should aspire.\n",
        "\n"
      ],
      "metadata": {
        "id": "9iuPtzWdVRlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Input Data Structure Validation\n",
        "\n",
        "def validate_input_data(\n",
        "    country_data: Dict[str, pd.DataFrame],\n",
        "    y_series: pd.Series,\n",
        "    study_manifest: Dict[str, Any]\n",
        ") -> Tuple[bool, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Performs a rigorous, multi-faceted validation of all input data structures.\n",
        "\n",
        "    This function serves as the primary gateway to the research pipeline, ensuring\n",
        "    that the provided data and parameters conform to the strict requirements of\n",
        "    the \"High-Dimensional Matrix-Variate Diffusion Index Models\" methodology.\n",
        "    It checks dictionary structure, DataFrame integrity (columns, dtypes,\n",
        "    temporal indices), data quality (NaNs, infinities, outliers), and the\n",
        "    validity of the study manifest parameters.\n",
        "\n",
        "    Args:\n",
        "        country_data (Dict[str, pd.DataFrame]):\n",
        "            A dictionary where keys are country identifiers (e.g., 'USA') and\n",
        "            values are pandas DataFrames. Each DataFrame should contain\n",
        "            identically named columns of economic indicators and share an\n",
        "            identical quarterly DatetimeIndex.\n",
        "        y_series (pd.Series):\n",
        "            A pandas Series containing the target variable, indexed with a\n",
        "            quarterly DatetimeIndex that must align perfectly with the\n",
        "            predictor DataFrames in `country_data`.\n",
        "        study_manifest (Dict[str, Any]):\n",
        "            A nested dictionary containing all non-data parameters that govern\n",
        "            the study, including configurations for the empirical study,\n",
        "            simulations, and screening validation.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[bool, Dict[str, Any]]:\n",
        "            A tuple containing:\n",
        "            - is_valid (bool): A master boolean flag that is True only if all\n",
        "              critical validation checks pass. Warnings do not set this to False.\n",
        "            - validation_report (Dict[str, Any]): A detailed, nested dictionary\n",
        "              containing the results of every validation check performed. Each\n",
        "              check has a 'status' (bool) and 'details' (list of messages).\n",
        "    \"\"\"\n",
        "    # Initialize the master validation flag and the detailed report dictionary.\n",
        "    is_valid = True\n",
        "    validation_report = {\n",
        "        'dictionary_structure': {'status': True, 'details': []},\n",
        "        'dataframe_integrity': {'status': True, 'details': []},\n",
        "        'temporal_synchronization': {'status': True, 'details': []},\n",
        "        'data_quality': {'status': True, 'details': []},\n",
        "        'manifest_validation': {'status': True, 'details': []},\n",
        "    }\n",
        "\n",
        "    # =========================================================================\n",
        "    # Task 1.1: Validate Dictionary Structure\n",
        "    # =========================================================================\n",
        "    try:\n",
        "        # Extract the required country codes from the study manifest for validation.\n",
        "        required_countries: Set[str] = set(\n",
        "            study_manifest['empirical_study']['data_inputs']\n",
        "            ['predictor_matrices_X_all']['row_index_countries']\n",
        "        )\n",
        "        # Get the set of country codes provided in the input dictionary.\n",
        "        provided_countries: Set[str] = set(country_data.keys())\n",
        "\n",
        "        # Check if the provided country codes exactly match the required ones.\n",
        "        if required_countries != provided_countries:\n",
        "            # If they don't match, the structure is invalid.\n",
        "            is_valid = False\n",
        "            validation_report['dictionary_structure']['status'] = False\n",
        "            # Identify and report missing countries.\n",
        "            missing = required_countries - provided_countries\n",
        "            if missing:\n",
        "                msg = f\"Critical Error: Missing required country keys: {sorted(list(missing))}.\"\n",
        "                validation_report['dictionary_structure']['details'].append(msg)\n",
        "            # Identify and report unexpected extra countries.\n",
        "            extra = provided_countries - required_countries\n",
        "            if extra:\n",
        "                msg = f\"Critical Error: Found unexpected country keys: {sorted(list(extra))}.\"\n",
        "                validation_report['dictionary_structure']['details'].append(msg)\n",
        "\n",
        "        # Verify that every value in the dictionary is a pandas DataFrame.\n",
        "        for country, df in country_data.items():\n",
        "            if not isinstance(df, pd.DataFrame):\n",
        "                is_valid = False\n",
        "                validation_report['dictionary_structure']['status'] = False\n",
        "                msg = f\"Critical Error: Value for key '{country}' is not a pandas DataFrame, but {type(df)}.\"\n",
        "                validation_report['dictionary_structure']['details'].append(msg)\n",
        "\n",
        "    except (KeyError, AttributeError) as e:\n",
        "        # Catch errors if the manifest is malformed or input is not a dict.\n",
        "        is_valid = False\n",
        "        validation_report['dictionary_structure']['status'] = False\n",
        "        msg = f\"Catastrophic Error: Failed to validate dictionary structure. Check manifest or input type. Details: {e}\"\n",
        "        validation_report['dictionary_structure']['details'].append(msg)\n",
        "        # Return immediately as further checks are impossible.\n",
        "        return is_valid, validation_report\n",
        "\n",
        "    # =========================================================================\n",
        "    # Task 1.2 & 1.3: Temporal Index and DataFrame Column/Dtype Validation\n",
        "    # =========================================================================\n",
        "    # Extract required columns and dimensions from the manifest.\n",
        "    required_columns: Set[str] = set(\n",
        "        study_manifest['empirical_study']['data_inputs']\n",
        "        ['predictor_matrices_X_all']['column_index_indicators']\n",
        "    )\n",
        "    required_T = study_manifest['empirical_study']['data_inputs']['predictor_matrices_X_all']['T_observations']\n",
        "\n",
        "    # Establish the first valid DataFrame's index as the reference for synchronization.\n",
        "    reference_index: pd.DatetimeIndex = None\n",
        "    if country_data:\n",
        "        first_country = next(iter(country_data))\n",
        "        reference_index = country_data[first_country].index\n",
        "\n",
        "    # --- Validate y_series first ---\n",
        "    # Check if y_series is a pandas Series.\n",
        "    if not isinstance(y_series, pd.Series):\n",
        "        is_valid = False\n",
        "        validation_report['temporal_synchronization']['status'] = False\n",
        "        msg = f\"Critical Error: y_series is not a pandas Series, but {type(y_series)}.\"\n",
        "        validation_report['temporal_synchronization']['details'].append(msg)\n",
        "    else:\n",
        "        # Check if the y_series index matches the reference index.\n",
        "        if reference_index is not None and not y_series.index.equals(reference_index):\n",
        "            is_valid = False\n",
        "            validation_report['temporal_synchronization']['status'] = False\n",
        "            msg = \"Critical Error: y_series DatetimeIndex does not match the reference predictor DataFrame index.\"\n",
        "            validation_report['temporal_synchronization']['details'].append(msg)\n",
        "\n",
        "    # --- Iterate through each country's DataFrame for detailed validation ---\n",
        "    for country, df in country_data.items():\n",
        "        # --- Column Validation ---\n",
        "        provided_columns = set(df.columns)\n",
        "        if provided_columns != required_columns:\n",
        "            is_valid = False\n",
        "            validation_report['dataframe_integrity']['status'] = False\n",
        "            missing = required_columns - provided_columns\n",
        "            extra = provided_columns - required_columns\n",
        "            msg = f\"Critical Error for '{country}': Column mismatch. Missing: {missing or 'None'}. Extra: {extra or 'None'}.\"\n",
        "            validation_report['dataframe_integrity']['details'].append(msg)\n",
        "\n",
        "        # --- Dtype and Data Quality Validation (per DataFrame) ---\n",
        "        for col in required_columns:\n",
        "            if col in df.columns:\n",
        "                # Check if the column's data type is float.\n",
        "                if not pd.api.types.is_float_dtype(df[col].dtype):\n",
        "                    # This is a warning, not a critical error, as casting is often possible.\n",
        "                    validation_report['dataframe_integrity']['status'] = False # Treat as error for rigor\n",
        "                    is_valid = False # Treat as error for rigor\n",
        "                    msg = f\"Critical Error for '{country}', column '{col}': Dtype is not float, but {df[col].dtype}.\"\n",
        "                    validation_report['dataframe_integrity']['details'].append(msg)\n",
        "\n",
        "        # --- Temporal Index Validation ---\n",
        "        # Check for index equality against the reference.\n",
        "        if not df.index.equals(reference_index):\n",
        "            is_valid = False\n",
        "            validation_report['temporal_synchronization']['status'] = False\n",
        "            msg = f\"Critical Error for '{country}': DatetimeIndex does not match the reference index.\"\n",
        "            validation_report['temporal_synchronization']['details'].append(msg)\n",
        "        # Check if the index is monotonically increasing.\n",
        "        if not df.index.is_monotonic_increasing:\n",
        "            is_valid = False\n",
        "            validation_report['temporal_synchronization']['status'] = False\n",
        "            msg = f\"Critical Error for '{country}': DatetimeIndex is not monotonically increasing.\"\n",
        "            validation_report['temporal_synchronization']['details'].append(msg)\n",
        "        # Check the number of observations.\n",
        "        if len(df) != required_T:\n",
        "            is_valid = False\n",
        "            validation_report['temporal_synchronization']['status'] = False\n",
        "            msg = f\"Critical Error for '{country}': Expected {required_T} observations, but found {len(df)}.\"\n",
        "            validation_report['temporal_synchronization']['details'].append(msg)\n",
        "        # Infer and check the frequency of the index.\n",
        "        freq = pd.infer_freq(df.index)\n",
        "        if not (freq and freq.startswith('Q')):\n",
        "            # This is a warning, as analysis might still be possible.\n",
        "            validation_report['temporal_synchronization']['status'] = False # Treat as error for rigor\n",
        "            is_valid = False # Treat as error for rigor\n",
        "            msg = f\"Critical Error for '{country}': Could not infer quarterly frequency. Inferred: {freq}.\"\n",
        "            validation_report['temporal_synchronization']['details'].append(msg)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Task 1.4: Data Quality Assessment (NaNs, Infs, Outliers, Constants)\n",
        "    # =========================================================================\n",
        "    all_series = {f\"{c}_{col}\": df[col] for c, df in country_data.items() for col in df.columns}\n",
        "    all_series[y_series.name or 'y_series'] = y_series\n",
        "\n",
        "    total_nans = 0\n",
        "    total_infs = 0\n",
        "    total_outliers = 0\n",
        "    constant_series = []\n",
        "\n",
        "    for name, series in all_series.items():\n",
        "        # Check for missing values (NaNs).\n",
        "        nans = series.isnull().sum()\n",
        "        if nans > 0:\n",
        "            total_nans += nans\n",
        "            msg = f\"Warning: Series '{name}' contains {nans} NaN value(s).\"\n",
        "            validation_report['data_quality']['details'].append(msg)\n",
        "\n",
        "        # Check for infinite values.\n",
        "        infs = np.isinf(series).sum()\n",
        "        if infs > 0:\n",
        "            total_infs += infs\n",
        "            msg = f\"Warning: Series '{name}' contains {infs} infinite value(s).\"\n",
        "            validation_report['data_quality']['details'].append(msg)\n",
        "\n",
        "        # Check for constant series (zero variance).\n",
        "        if series.std() < 1e-9:\n",
        "            is_valid = False # Constant series can break many algorithms.\n",
        "            validation_report['data_quality']['status'] = False\n",
        "            constant_series.append(name)\n",
        "            msg = f\"Critical Error: Series '{name}' is constant (zero variance).\"\n",
        "            validation_report['data_quality']['details'].append(msg)\n",
        "        else:\n",
        "            # Check for outliers using Z-score, only if not constant.\n",
        "            # Z = (x - μ) / σ\n",
        "            z_scores = np.abs((series - series.mean()) / series.std())\n",
        "            outliers = (z_scores > 5).sum()\n",
        "            if outliers > 0:\n",
        "                total_outliers += outliers\n",
        "                msg = f\"Warning: Series '{name}' contains {outliers} outlier(s) with |Z-score| > 5.\"\n",
        "                validation_report['data_quality']['details'].append(msg)\n",
        "\n",
        "    if total_nans > 0 or total_infs > 0 or total_outliers > 0:\n",
        "        # If any quality issues are found, the status is False (warning).\n",
        "        # It doesn't invalidate the run unless NaNs/Infs are not handled.\n",
        "        # For this rigorous validator, we will consider them warnings that don't flip `is_valid`.\n",
        "        # The presence of constant series, however, is a critical error.\n",
        "        pass\n",
        "\n",
        "    # =========================================================================\n",
        "    # Task 1.5: Study Manifest Validation\n",
        "    # =========================================================================\n",
        "    try:\n",
        "        # Check for the presence of top-level keys.\n",
        "        for key in ['empirical_study', 'simulation_study', 'screening_validation']:\n",
        "            if key not in study_manifest:\n",
        "                is_valid = False\n",
        "                validation_report['manifest_validation']['status'] = False\n",
        "                msg = f\"Critical Error: Manifest missing required top-level key: '{key}'.\"\n",
        "                validation_report['manifest_validation']['details'].append(msg)\n",
        "\n",
        "        # Validate specific parameter values.\n",
        "        alpha_grid = study_manifest['empirical_study']['parameters']['alpha_grid']['value']\n",
        "        if not all(isinstance(a, (int, float)) and a >= -1 for a in alpha_grid):\n",
        "            is_valid = False\n",
        "            validation_report['manifest_validation']['status'] = False\n",
        "            msg = \"Critical Error: Manifest 'alpha_grid' contains invalid values (must be numeric and >= -1).\"\n",
        "            validation_report['manifest_validation']['details'].append(msg)\n",
        "\n",
        "        # Validate convergence tolerance.\n",
        "        tol = study_manifest['empirical_study']['parameters']['iterative_lse_config']['convergence_tolerance']\n",
        "        if not (isinstance(tol, float) and tol > 0):\n",
        "            is_valid = False\n",
        "            validation_report['manifest_validation']['status'] = False\n",
        "            msg = \"Critical Error: Manifest 'convergence_tolerance' must be a positive float.\"\n",
        "            validation_report['manifest_validation']['details'].append(msg)\n",
        "\n",
        "    except (KeyError, TypeError) as e:\n",
        "        # Catch errors from a malformed manifest.\n",
        "        is_valid = False\n",
        "        validation_report['manifest_validation']['status'] = False\n",
        "        msg = f\"Catastrophic Error: Failed to validate manifest structure. Details: {e}\"\n",
        "        validation_report['manifest_validation']['details'].append(msg)\n",
        "\n",
        "    # Final check on all statuses to determine the master `is_valid` flag.\n",
        "    is_valid = all(\n",
        "        validation_report[key]['status'] for key in validation_report\n",
        "    )\n",
        "\n",
        "    # Return the final validation status and the detailed report.\n",
        "    return is_valid, validation_report\n"
      ],
      "metadata": {
        "id": "q-tzj2q9VTyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Data Cleansing and Stationarity Preparation\n",
        "\n",
        "# =============================================================================\n",
        "# Helper Function: _perform_adf_test (Task 2.1)\n",
        "# =============================================================================\n",
        "\n",
        "def _perform_adf_test(\n",
        "    series: pd.Series,\n",
        "    significance_level: float = 0.05\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Performs the Augmented Dickey-Fuller (ADF) test on a single time series.\n",
        "\n",
        "    This is a low-level helper function that encapsulates the ADF test logic,\n",
        "    including handling of potential errors and formatting the output in a\n",
        "    structured manner.\n",
        "\n",
        "    Args:\n",
        "        series (pd.Series): The time series to be tested for a unit root.\n",
        "        significance_level (float): The p-value threshold to determine stationarity.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing the test results:\n",
        "            - 'is_stationary' (bool): True if the p-value is below the\n",
        "              significance level.\n",
        "            - 'p_value' (float): The p-value from the ADF test.\n",
        "            - 'adf_statistic' (float): The test statistic.\n",
        "            - 'lags_used' (int): The number of lags used in the regression.\n",
        "            - 'critical_values' (Dict): The critical values for the test at\n",
        "              different confidence levels.\n",
        "            - 'error' (str or None): An error message if the test failed.\n",
        "    \"\"\"\n",
        "    # Create a clean version of the series by dropping missing values.\n",
        "    clean_series = series.dropna()\n",
        "\n",
        "    # The ADF test requires a minimum number of observations.\n",
        "    if len(clean_series) < 15:\n",
        "        return {\n",
        "            'is_stationary': False,\n",
        "            'p_value': None,\n",
        "            'adf_statistic': None,\n",
        "            'lags_used': None,\n",
        "            'critical_values': None,\n",
        "            'error': 'Insufficient data for ADF test after dropping NaNs.'\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        # Perform the ADF test using statsmodels.\n",
        "        # H0: The series has a unit root (is non-stationary).\n",
        "        # regression='c': Include only a constant (intercept) in the regression.\n",
        "        # autolag='AIC': Automatically select the number of lags using the\n",
        "        #                Akaike Information Criterion.\n",
        "        adf_result = adfuller(\n",
        "            clean_series,\n",
        "            regression='c',\n",
        "            autolag='AIC'\n",
        "        )\n",
        "\n",
        "        # Extract results into a structured dictionary.\n",
        "        p_value = adf_result[1]\n",
        "        is_stationary = p_value < significance_level\n",
        "\n",
        "        return {\n",
        "            'is_stationary': is_stationary,\n",
        "            'p_value': p_value,\n",
        "            'adf_statistic': adf_result[0],\n",
        "            'lags_used': adf_result[2],\n",
        "            'critical_values': adf_result[4],\n",
        "            'error': None\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        # Catch any unexpected errors during the test execution.\n",
        "        return {\n",
        "            'is_stationary': False,\n",
        "            'p_value': None,\n",
        "            'adf_statistic': None,\n",
        "            'lags_used': None,\n",
        "            'critical_values': None,\n",
        "            'error': f\"ADF test failed with exception: {e}\"\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# Helper Function: _make_series_stationary (Task 2.2 & 2.3)\n",
        "# =============================================================================\n",
        "\n",
        "def _make_series_stationary(\n",
        "    original_series: pd.Series,\n",
        "    series_name: str\n",
        ") -> Tuple[pd.Series, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Applies transformations to a single time series to achieve stationarity.\n",
        "\n",
        "    This function implements a sequential \"test-transform-retest\" protocol.\n",
        "    It applies the minimum necessary transformations (log, differencing) to\n",
        "    make a series stationary based on the ADF test. It concludes by\n",
        "    centralizing (de-meaning) the final stationary series.\n",
        "\n",
        "    Args:\n",
        "        original_series (pd.Series): The raw time series to process.\n",
        "        series_name (str): The identifier for the series, used for logging.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.Series, pd.DataFrame]:\n",
        "            - transformed_series (pd.Series): The final stationary and\n",
        "              centralized series. It may contain leading NaNs.\n",
        "            - transformation_log (pd.DataFrame): A log detailing each\n",
        "              transformation step and its outcome.\n",
        "    \"\"\"\n",
        "    # Initialize the series to be transformed and the log.\n",
        "    current_series = original_series.copy()\n",
        "    log_entries = []\n",
        "\n",
        "    # --- Initial Stationarity Check ---\n",
        "    adf_initial = _perform_adf_test(current_series)\n",
        "    log_entries.append({\n",
        "        'series_name': series_name,\n",
        "        'step': 'Initial Check',\n",
        "        'transformation': 'None',\n",
        "        'p_value': adf_initial['p_value'],\n",
        "        'is_stationary': adf_initial['is_stationary']\n",
        "    })\n",
        "\n",
        "    # If the series is already stationary, proceed directly to centralization.\n",
        "    if not adf_initial['is_stationary']:\n",
        "        # --- Transformation Step 1: Log Transform (if applicable) ---\n",
        "        # Check if all values are positive before attempting log transform.\n",
        "        if (current_series.dropna() > 0).all():\n",
        "            current_series = np.log(current_series)\n",
        "            adf_after_log = _perform_adf_test(current_series)\n",
        "            log_entries.append({\n",
        "                'series_name': series_name,\n",
        "                'step': 'Log Transform',\n",
        "                'transformation': 'log(x)',\n",
        "                'p_value': adf_after_log['p_value'],\n",
        "                'is_stationary': adf_after_log['is_stationary']\n",
        "            })\n",
        "            # If stationary after log, break the transformation loop.\n",
        "            if adf_after_log['is_stationary']:\n",
        "                pass # Will proceed to centralization\n",
        "            else:\n",
        "                # --- Transformation Step 2: First Differencing ---\n",
        "                # Equation: Δx_t = x_t - x_{t-1}\n",
        "                current_series = current_series.diff()\n",
        "                adf_after_diff1 = _perform_adf_test(current_series)\n",
        "                log_entries.append({\n",
        "                    'series_name': series_name,\n",
        "                    'step': 'First Difference',\n",
        "                    'transformation': 'diff(1)',\n",
        "                    'p_value': adf_after_diff1['p_value'],\n",
        "                    'is_stationary': adf_after_diff1['is_stationary']\n",
        "                })\n",
        "                if not adf_after_diff1['is_stationary']:\n",
        "                    # --- Transformation Step 3: Second Differencing ---\n",
        "                    # Equation: Δ²x_t = Δx_t - Δx_{t-1}\n",
        "                    current_series = current_series.diff()\n",
        "                    adf_after_diff2 = _perform_adf_test(current_series)\n",
        "                    log_entries.append({\n",
        "                        'series_name': series_name,\n",
        "                        'step': 'Second Difference',\n",
        "                        'transformation': 'diff(2)',\n",
        "                        'p_value': adf_after_diff2['p_value'],\n",
        "                        'is_stationary': adf_after_diff2['is_stationary']\n",
        "                    })\n",
        "        else: # If not all positive, skip log and go to differencing.\n",
        "            # --- Transformation Step 2 (No Log): First Differencing ---\n",
        "            current_series = current_series.diff()\n",
        "            adf_after_diff1 = _perform_adf_test(current_series)\n",
        "            log_entries.append({\n",
        "                'series_name': series_name,\n",
        "                'step': 'First Difference',\n",
        "                'transformation': 'diff(1)',\n",
        "                'p_value': adf_after_diff1['p_value'],\n",
        "                'is_stationary': adf_after_diff1['is_stationary']\n",
        "            })\n",
        "            if not adf_after_diff1['is_stationary']:\n",
        "                # --- Transformation Step 3 (No Log): Second Differencing ---\n",
        "                current_series = current_series.diff()\n",
        "                adf_after_diff2 = _perform_adf_test(current_series)\n",
        "                log_entries.append({\n",
        "                    'series_name': series_name,\n",
        "                    'step': 'Second Difference',\n",
        "                    'transformation': 'diff(2)',\n",
        "                    'p_value': adf_after_diff2['p_value'],\n",
        "                    'is_stationary': adf_after_diff2['is_stationary']\n",
        "                })\n",
        "\n",
        "    # --- Final Step: Centralization (De-meaning) ---\n",
        "    # Equation: x_centered = x - mean(x)\n",
        "    series_mean = current_series.mean()\n",
        "    centralized_series = current_series - series_mean\n",
        "    log_entries.append({\n",
        "        'series_name': series_name,\n",
        "        'step': 'Centralization',\n",
        "        'transformation': f'x - {series_mean:.4f}',\n",
        "        'p_value': None,\n",
        "        'is_stationary': None\n",
        "    })\n",
        "\n",
        "    # Create the final log DataFrame.\n",
        "    transformation_log = pd.DataFrame(log_entries)\n",
        "\n",
        "    # Final check for persistent non-stationarity.\n",
        "    final_adf = _perform_adf_test(centralized_series)\n",
        "    if not final_adf['is_stationary']:\n",
        "        warnings.warn(\n",
        "            f\"Series '{series_name}' remains non-stationary after all \"\n",
        "            f\"transformations (p-value: {final_adf['p_value']:.4f}). \"\n",
        "            \"Manual inspection is required.\",\n",
        "            UserWarning\n",
        "        )\n",
        "\n",
        "    return centralized_series, transformation_log\n",
        "\n",
        "# =============================================================================\n",
        "# Main Orchestrator Function (Task 2.4)\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "def prepare_forecasting_data(\n",
        "    country_data: Dict[str, pd.DataFrame],\n",
        "    y_series: pd.Series,\n",
        "    study_manifest: Dict[str, Any],\n",
        "    training_size: int\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Prepares stationary, centralized, and aligned data for a forecasting task.\n",
        "\n",
        "    This function implements a rigorous, leak-free data preparation pipeline:\n",
        "    1.  Applies stationarity-inducing transformations (log, diff) to each raw series.\n",
        "    2.  Calculates centralization parameters (mean) using ONLY the training portion\n",
        "        of the transformed data.\n",
        "    3.  Applies these training-derived parameters to centralize both the training\n",
        "        and testing portions of the data.\n",
        "    4.  Aligns all 141 processed series to find a common, valid time window.\n",
        "    5.  Constructs and returns the final train/test splits as numpy tensors.\n",
        "\n",
        "    This process is critically designed to prevent any data leakage from the\n",
        "    test set into the training set.\n",
        "\n",
        "    Args:\n",
        "        country_data (Dict[str, pd.DataFrame]): Raw country predictor data.\n",
        "        y_series (pd.Series): Raw target variable series.\n",
        "        study_manifest (Dict[str, Any]): The master configuration dictionary.\n",
        "        training_size (int): The number of observations in the training set.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing the prepared data:\n",
        "            - 'X_train' (np.ndarray): (T_train_new, p, q) training tensor.\n",
        "            - 'y_train' (np.ndarray): (T_train_new,) training target vector.\n",
        "            - 'X_test' (np.ndarray): (T_test_new, p, q) testing tensor.\n",
        "            - 'y_test' (np.ndarray): (T_test_new,) testing target vector.\n",
        "            - 'final_index' (pd.DatetimeIndex): The common aligned index.\n",
        "            - 'prep_log' (pd.DataFrame): A log of all transformations.\n",
        "    \"\"\"\n",
        "    # --- Helper function for leak-free stationarity and centralization ---\n",
        "    def _process_single_series(series, name, train_len):\n",
        "        current_series = series.copy()\n",
        "        log = []\n",
        "\n",
        "        # Step 1: Stationarity transformations (leakage-free)\n",
        "        adf_initial = _perform_adf_test(current_series)\n",
        "        is_stationary = adf_initial['is_stationary']\n",
        "        log.append({'series': name, 'transform': 'None', 'p_value': adf_initial['p_value']})\n",
        "\n",
        "        if not is_stationary and (current_series.dropna() > 0).all():\n",
        "            current_series = np.log(current_series)\n",
        "            adf_log = _perform_adf_test(current_series)\n",
        "            is_stationary = adf_log['is_stationary']\n",
        "            log.append({'series': name, 'transform': 'log', 'p_value': adf_log['p_value']})\n",
        "\n",
        "        if not is_stationary:\n",
        "            current_series = current_series.diff()\n",
        "            adf_d1 = _perform_adf_test(current_series)\n",
        "            is_stationary = adf_d1['is_stationary']\n",
        "            log.append({'series': name, 'transform': 'diff(1)', 'p_value': adf_d1['p_value']})\n",
        "\n",
        "        if not is_stationary:\n",
        "            current_series = current_series.diff()\n",
        "            adf_d2 = _perform_adf_test(current_series)\n",
        "            log.append({'series': name, 'transform': 'diff(2)', 'p_value': adf_d2['p_value']})\n",
        "\n",
        "        # Step 2: Calculate mean using ONLY the training part of the transformed series\n",
        "        train_mean = current_series.iloc[:train_len].mean()\n",
        "\n",
        "        # Step 3: Centralize the ENTIRE series using the training mean\n",
        "        centralized_series = current_series - train_mean\n",
        "        log.append({'series': name, 'transform': f'center(mean={train_mean:.4f})', 'p_value': None})\n",
        "\n",
        "        return centralized_series, pd.DataFrame(log)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Main Orchestration\n",
        "    # =========================================================================\n",
        "    # Get ordered lists of countries and indicators for consistent matrix structure.\n",
        "    p_countries = sorted(study_manifest['empirical_study']['data_inputs']['predictor_matrices_X_all']['row_index_countries'])\n",
        "    q_indicators = sorted(study_manifest['empirical_study']['data_inputs']['predictor_matrices_X_all']['column_index_indicators'])\n",
        "\n",
        "    processed_series_dict = {}\n",
        "    all_logs = []\n",
        "\n",
        "    # --- Process all 140 predictor series ---\n",
        "    for country in p_countries:\n",
        "        for indicator in q_indicators:\n",
        "            series_name = f\"{country}_{indicator}\"\n",
        "            processed, log = _process_single_series(country_data[country][indicator], series_name, training_size)\n",
        "            processed_series_dict[series_name] = processed\n",
        "            all_logs.append(log)\n",
        "\n",
        "    # --- Process the target series ---\n",
        "    y_name = y_series.name or 'target_y'\n",
        "    processed_y, y_log = _process_single_series(y_series, y_name, training_size)\n",
        "    all_logs.append(y_log)\n",
        "\n",
        "    # --- Step 4: Final Assembly and Alignment ---\n",
        "    # Combine all processed series into one DataFrame.\n",
        "    full_processed_df = pd.DataFrame(processed_series_dict)\n",
        "    full_processed_df[y_name] = processed_y\n",
        "\n",
        "    # Drop all rows with NaNs to find the common, valid time window.\n",
        "    aligned_df = full_processed_df.dropna()\n",
        "    final_index = aligned_df.index\n",
        "\n",
        "    # Identify the split point in the new, aligned index.\n",
        "    # The first test observation is the first one with an index greater than\n",
        "    # the last training index from the original series.\n",
        "    original_train_end_date = y_series.index[training_size - 1]\n",
        "    split_idx = aligned_df.index.searchsorted(original_train_end_date, side='right')\n",
        "\n",
        "    # --- Step 5: Construct Final Train/Test Tensors ---\n",
        "    # Split the aligned DataFrame into train and test sets.\n",
        "    train_df = aligned_df.iloc[:split_idx]\n",
        "    test_df = aligned_df.iloc[split_idx:]\n",
        "\n",
        "    # Extract target vectors.\n",
        "    y_train = train_df[y_name].to_numpy()\n",
        "    y_test = test_df[y_name].to_numpy()\n",
        "\n",
        "    # Construct the 3D predictor tensors.\n",
        "    T_train_new, p, q = len(train_df), len(p_countries), len(q_indicators)\n",
        "    T_test_new = len(test_df)\n",
        "    X_train = np.zeros((T_train_new, p, q))\n",
        "    X_test = np.zeros((T_test_new, p, q))\n",
        "\n",
        "    for i, country in enumerate(p_countries):\n",
        "        for j, indicator in enumerate(q_indicators):\n",
        "            series_name = f\"{country}_{indicator}\"\n",
        "            X_train[:, i, j] = train_df[series_name].to_numpy()\n",
        "            X_test[:, i, j] = test_df[series_name].to_numpy()\n",
        "\n",
        "    return {\n",
        "        'X_train': X_train, 'y_train': y_train,\n",
        "        'X_test': X_test, 'y_test': y_test,\n",
        "        'final_index': final_index, 'split_idx': split_idx,\n",
        "        'prep_log': pd.concat(all_logs, ignore_index=True)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "JOR8I69cYGtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: Sample Statistics Computation\n",
        "\n",
        "def compute_sample_statistics(\n",
        "    X_tensor: np.ndarray\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Computes first-order sample statistics for the matrix-variate time series.\n",
        "\n",
        "    This function takes the 3D tensor of stationary, centralized predictor\n",
        "    data and computes two fundamental quantities required for the α-PCA\n",
        "    methodology:\n",
        "    1. The sample mean matrix, averaged over the time dimension.\n",
        "    2. The tensor of deviation matrices, representing the deviation of each\n",
        "       time-slice from the sample mean matrix.\n",
        "\n",
        "    Args:\n",
        "        X_tensor (np.ndarray):\n",
        "            A 3D numpy array of shape (T, p, q) containing the prepared\n",
        "            predictor data from Task 2. T is the number of time periods,\n",
        "            p is the number of row entities (e.g., countries), and q is the\n",
        "            number of column entities (e.g., indicators). The data within\n",
        "            this tensor is expected to be stationary and centralized.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray]:\n",
        "            A tuple containing:\n",
        "            - sample_mean_matrix (np.ndarray): A 2D array of shape (p, q),\n",
        "              representing the sample mean matrix, X_bar.\n",
        "            - deviation_tensor (np.ndarray): A 3D array of shape (T, p, q),\n",
        "              representing the sequence of deviation matrices, X_t - X_bar.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the input `X_tensor` is not a 3D numpy array.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    # Ensure the input is a 3D numpy array.\n",
        "    if not isinstance(X_tensor, np.ndarray) or X_tensor.ndim != 3:\n",
        "        raise ValueError(\n",
        "            f\"Input `X_tensor` must be a 3D numpy array. \"\n",
        "            f\"Received type {type(X_tensor)} with {X_tensor.ndim} dimensions.\"\n",
        "        )\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 3.1: Sample Mean Matrix Calculation\n",
        "    # =========================================================================\n",
        "    # Equation: \\overline{X} = (1/T) * Σ_{t=1 to T} X_t\n",
        "    # This computes the mean of the array elements along the time axis (axis=0).\n",
        "    # We use np.float64 to ensure high precision in the calculation.\n",
        "    sample_mean_matrix = np.mean(X_tensor, axis=0, dtype=np.float64)\n",
        "\n",
        "    # --- Internal Consistency Check ---\n",
        "    # Since the input tensor from Task 2 is already centralized, its sample\n",
        "    # mean should be a matrix of zeros within a small numerical tolerance.\n",
        "    # This serves as a powerful validation of the previous processing step.\n",
        "    if not np.allclose(sample_mean_matrix, 0, atol=1e-9):\n",
        "        # This warning indicates a potential issue in the centralization step.\n",
        "        warnings.warn(\n",
        "            \"The sample mean of the input tensor is not close to zero. \"\n",
        "            \"Ensure the data passed to this function has been properly \"\n",
        "            \"centralized as per Task 2.\",\n",
        "            UserWarning\n",
        "        )\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 3.2: Deviation Matrices Construction\n",
        "    # =========================================================================\n",
        "    # Equation: X_t^{(dev)} = X_t - \\overline{X}\n",
        "    # We use numpy's broadcasting to efficiently subtract the (p, q) mean matrix\n",
        "    # from each of the T slices of the (T, p, q) tensor.\n",
        "    deviation_tensor = X_tensor - sample_mean_matrix\n",
        "\n",
        "    # --- Final Validation ---\n",
        "    # The mean of the deviation_tensor must be numerically zero. This confirms\n",
        "    # the correctness of the subtraction operation.\n",
        "    # This check is slightly redundant given the one above but provides a\n",
        "    # direct verification of the output of this specific function.\n",
        "    if not np.allclose(np.mean(deviation_tensor, axis=0), 0, atol=1e-9):\n",
        "        # This would indicate a failure in the numpy broadcasting/subtraction.\n",
        "        raise RuntimeError(\n",
        "            \"Internal consistency check failed: The mean of the calculated \"\n",
        "            \"deviation tensor is not zero. This indicates a potential \"\n",
        "            \"numerical issue.\"\n",
        "        )\n",
        "\n",
        "    # Return the computed statistics.\n",
        "    return sample_mean_matrix, deviation_tensor\n"
      ],
      "metadata": {
        "id": "a2lLdgUDZQEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4: Moment Aggregation Matrix Construction\n",
        "\n",
        "def construct_moment_aggregation_matrices(\n",
        "    sample_mean_matrix: np.ndarray,\n",
        "    deviation_tensor: np.ndarray,\n",
        "    alpha: float\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Constructs the row and column moment aggregation matrices (M_R, M_C).\n",
        "\n",
        "    This function is the computational core of the α-PCA method. It builds the\n",
        "    two symmetric matrices whose spectral properties reveal the latent factor\n",
        "    structure. These matrices are a weighted average of the first moment\n",
        "    (from the sample mean) and second moment (from the temporal deviations)\n",
        "    of the predictor data.\n",
        "\n",
        "    Args:\n",
        "        sample_mean_matrix (np.ndarray):\n",
        "            The (p, q) sample mean matrix X_bar, from Task 3.\n",
        "        deviation_tensor (np.ndarray):\n",
        "            The (T, p, q) tensor of deviation matrices X_t - X_bar, from Task 3.\n",
        "        alpha (float):\n",
        "            The hyperparameter that balances the contribution of the first and\n",
        "            second moments. Must be >= -1.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray]:\n",
        "            A tuple containing:\n",
        "            - M_R (np.ndarray): The (p, p) symmetric row aggregation matrix.\n",
        "            - M_C (np.ndarray): The (q, q) symmetric column aggregation matrix.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If input dimensions are inconsistent or `alpha` is invalid.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    # Validate the dimensions of the input arrays.\n",
        "    if deviation_tensor.ndim != 3:\n",
        "        raise ValueError(\"`deviation_tensor` must be a 3D array.\")\n",
        "    if sample_mean_matrix.ndim != 2:\n",
        "        raise ValueError(\"`sample_mean_matrix` must be a 2D array.\")\n",
        "    if deviation_tensor.shape[1:] != sample_mean_matrix.shape:\n",
        "        raise ValueError(\n",
        "            \"The (p, q) dimensions of `deviation_tensor` and \"\n",
        "            \"`sample_mean_matrix` must match.\"\n",
        "        )\n",
        "    # Validate the alpha hyperparameter.\n",
        "    if not isinstance(alpha, (int, float)) or alpha < -1.0:\n",
        "        raise ValueError(f\"`alpha` must be a numeric value >= -1.0, but got {alpha}.\")\n",
        "\n",
        "    # Extract dimensions for clarity and calculations.\n",
        "    T, p, q = deviation_tensor.shape\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 4.1: Row Aggregation Matrix (M_R) Construction\n",
        "    # =========================================================================\n",
        "    # Equation: M_R = (1/pq) * [ (1+α) * X̄X̄' + (1/T) * Σ(X_t_dev * X_t_dev') ]\n",
        "\n",
        "    # --- Component 1: First Moment Contribution ---\n",
        "    # This term captures the structure of the time-averaged data.\n",
        "    # (1 + alpha) * (p, q) @ (q, p) -> (p, p)\n",
        "    first_moment_R = (1 + alpha) * (sample_mean_matrix @ sample_mean_matrix.T)\n",
        "\n",
        "    # --- Component 2: Second Moment Contribution ---\n",
        "    # This term captures the average covariance structure across time.\n",
        "    # We use np.einsum for a highly efficient and memory-safe computation\n",
        "    # of the sum of outer products over the time dimension.\n",
        "    # 'tpi,tqi->pq' means: for each time t, take the p-th row vector (t,p,:)\n",
        "    # and the q-th row vector (t,q,:), compute their dot product, and sum\n",
        "    # over the indicator dimension i. The result is a (p,p) matrix.\n",
        "    # This is equivalent to Σ_t (X_t_dev @ X_t_dev.T)\n",
        "    second_moment_R = np.einsum(\n",
        "        'tpi,tqi->pq', deviation_tensor, deviation_tensor\n",
        "    ) / T\n",
        "\n",
        "    # --- Combine and Scale ---\n",
        "    # Add the two components.\n",
        "    M_R_unscaled = first_moment_R + second_moment_R\n",
        "    # Scale the final matrix by 1 / (p * q).\n",
        "    M_R = M_R_unscaled / (p * q)\n",
        "\n",
        "    # --- Enforce Symmetry ---\n",
        "    # Due to floating point inaccuracies, M_R might be minutely asymmetric.\n",
        "    # We enforce perfect symmetry, which is a requirement for `scipy.linalg.eigh`.\n",
        "    M_R = (M_R + M_R.T) / 2.0\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 4.2: Column Aggregation Matrix (M_C) Construction\n",
        "    # =========================================================================\n",
        "    # Equation: M_C = (1/pq) * [ (1+α) * X̄'X̄ + (1/T) * Σ(X_t_dev' * X_t_dev) ]\n",
        "\n",
        "    # --- Component 1: First Moment Contribution ---\n",
        "    # (1 + alpha) * (q, p) @ (p, q) -> (q, q)\n",
        "    first_moment_C = (1 + alpha) * (sample_mean_matrix.T @ sample_mean_matrix)\n",
        "\n",
        "    # --- Component 2: Second Moment Contribution ---\n",
        "    # 'tip,tiq->pq' means: for each time t, take the p-th column vector (t,:,p)\n",
        "    # and the q-th column vector (t,:,q), compute their dot product, and sum\n",
        "    # over the country dimension i. The result is a (q,q) matrix.\n",
        "    # This is equivalent to Σ_t (X_t_dev.T @ X_t_dev)\n",
        "    second_moment_C = np.einsum(\n",
        "        'tip,tiq->pq', deviation_tensor, deviation_tensor\n",
        "    ) / T\n",
        "\n",
        "    # --- Combine and Scale ---\n",
        "    # Add the two components.\n",
        "    M_C_unscaled = first_moment_C + second_moment_C\n",
        "    # Scale the final matrix by 1 / (p * q).\n",
        "    M_C = M_C_unscaled / (p * q)\n",
        "\n",
        "    # --- Enforce Symmetry ---\n",
        "    # Enforce perfect symmetry for the same reasons as M_R.\n",
        "    M_C = (M_C + M_C.T) / 2.0\n",
        "\n",
        "    # Return the final, symmetric aggregation matrices.\n",
        "    return M_R, M_C\n"
      ],
      "metadata": {
        "id": "5tmMrP8BZ1yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 5: Eigendecomposition and Loading Matrix Extraction\n",
        "\n",
        "# =============================================================================\n",
        "# Helper Function: _get_sorted_eigensystem (Task 5.1 & 5.2)\n",
        "# =============================================================================\n",
        "\n",
        "def _get_sorted_eigensystem(\n",
        "    symmetric_matrix: np.ndarray\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Computes and sorts the eigensystem of a symmetric matrix.\n",
        "\n",
        "    This function uses `scipy.linalg.eigh` for numerically stable\n",
        "    eigendecomposition, sorts the eigenvalues in descending order, and applies\n",
        "    a deterministic sign convention to the eigenvectors for reproducibility.\n",
        "\n",
        "    Args:\n",
        "        symmetric_matrix (np.ndarray): A square, symmetric matrix.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray]:\n",
        "            - sorted_eigenvalues (np.ndarray): 1D array of eigenvalues, sorted\n",
        "              in descending order.\n",
        "            - sorted_eigenvectors (np.ndarray): 2D array where columns are\n",
        "              eigenvectors corresponding to the sorted eigenvalues.\n",
        "    \"\"\"\n",
        "    # Use scipy.linalg.eigh for stable decomposition of symmetric matrices.\n",
        "    # It guarantees real eigenvalues and is generally faster than np.linalg.eig.\n",
        "    eigenvalues, eigenvectors = scipy.linalg.eigh(symmetric_matrix)\n",
        "\n",
        "    # Sort eigenvalues in descending order and get the sorting indices.\n",
        "    sort_indices = np.argsort(eigenvalues)[::-1]\n",
        "\n",
        "    # Apply the same sorting to both eigenvalues and eigenvectors.\n",
        "    sorted_eigenvalues = eigenvalues[sort_indices]\n",
        "    sorted_eigenvectors = eigenvectors[:, sort_indices]\n",
        "\n",
        "    # --- Enforce a deterministic sign convention for eigenvectors ---\n",
        "    # The sign of an eigenvector is arbitrary. To ensure reproducibility,\n",
        "    # we force the element with the largest absolute value in each eigenvector\n",
        "    # to be positive.\n",
        "    for i in range(sorted_eigenvectors.shape[1]):\n",
        "        # Find the index of the element with the maximum absolute value.\n",
        "        max_abs_val_idx = np.argmax(np.abs(sorted_eigenvectors[:, i]))\n",
        "        # If that element is negative, flip the sign of the entire eigenvector.\n",
        "        if sorted_eigenvectors[max_abs_val_idx, i] < 0:\n",
        "            sorted_eigenvectors[:, i] *= -1\n",
        "\n",
        "    return sorted_eigenvalues, sorted_eigenvectors\n",
        "\n",
        "# =============================================================================\n",
        "# Helper Function: _estimate_dimension_by_ratio (Task 5.3)\n",
        "# =============================================================================\n",
        "\n",
        "def _estimate_dimension_by_ratio(\n",
        "    eigenvalues: np.ndarray,\n",
        "    max_dimension: int\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Estimates the number of factors using the eigenvalue ratio test.\n",
        "\n",
        "    Implements the method from Lam and Yao (2012) as cited in the paper.\n",
        "    k_hat = argmax_{j} (lambda_j / lambda_{j+1})\n",
        "\n",
        "    Args:\n",
        "        eigenvalues (np.ndarray): A 1D array of eigenvalues, sorted descending.\n",
        "        max_dimension (int): The maximum number of factors to consider (k_max or r_max).\n",
        "\n",
        "    Returns:\n",
        "        int: The estimated number of factors (k_hat or r_hat).\n",
        "    \"\"\"\n",
        "    # Ensure max_dimension is valid.\n",
        "    if max_dimension >= len(eigenvalues):\n",
        "        raise ValueError(\n",
        "            \"max_dimension must be less than the number of eigenvalues.\"\n",
        "        )\n",
        "\n",
        "    # To prevent division by zero or near-zero, add a small epsilon.\n",
        "    epsilon = 1e-12\n",
        "\n",
        "    # Calculate the ratio of adjacent eigenvalues.\n",
        "    # We only consider ratios up to the specified max_dimension.\n",
        "    # Equation: ratio_j = λ_j / λ_{j+1}\n",
        "    ratios = eigenvalues[:max_dimension] / (eigenvalues[1:max_dimension + 1] + epsilon)\n",
        "\n",
        "    # Find the index of the maximum ratio.\n",
        "    # The estimated dimension is the index + 1.\n",
        "    # Equation: k_hat = argmax_{1 <= j <= k_max} ratio_j\n",
        "    estimated_dim = np.argmax(ratios) + 1\n",
        "\n",
        "    return int(estimated_dim)\n",
        "\n",
        "# =============================================================================\n",
        "# Main Orchestrator Function (Task 5.4 & 5.5)\n",
        "# =============================================================================\n",
        "\n",
        "def extract_loadings_and_dimensions(\n",
        "    M_R: np.ndarray,\n",
        "    M_C: np.ndarray,\n",
        "    p: int,\n",
        "    q: int,\n",
        "    k_max: int,\n",
        "    r_max: int,\n",
        "    fixed_kr: Optional[Tuple[int, int]] = None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Performs eigendecomposition and extracts loading matrices and dimensions.\n",
        "\n",
        "    This function is a flexible core component of the α-PCA pipeline. It can\n",
        "    either estimate the number of factors (k, r) using the eigenvalue ratio\n",
        "    test or accept a fixed, pre-specified number of factors.\n",
        "\n",
        "    Args:\n",
        "        M_R, M_C (np.ndarray): The row and column moment aggregation matrices.\n",
        "        p, q (int): The dimensions of the original data matrix.\n",
        "        k_max, r_max (int): The maximum number of factors to consider for estimation.\n",
        "        fixed_kr (Optional[Tuple[int, int]]): If provided as a tuple (k, r),\n",
        "            these dimensions will be used directly, bypassing estimation.\n",
        "            Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing the estimated dimensions\n",
        "                        (k_hat, r_hat), loading matrices (R_hat, C_hat), and\n",
        "                        the sorted eigenvalues.\n",
        "    \"\"\"\n",
        "    # --- Eigendecomposition ---\n",
        "    eigvals_R, eigvecs_R = _get_sorted_eigensystem(M_R)\n",
        "    eigvals_C, eigvecs_C = _get_sorted_eigensystem(M_C)\n",
        "\n",
        "    # --- Factor Dimension Selection ---\n",
        "    if fixed_kr is not None:\n",
        "        # If dimensions are fixed, use them directly after validation.\n",
        "        k_hat, r_hat = fixed_kr\n",
        "        if not (0 < k_hat <= p and 0 < r_hat <= q):\n",
        "            raise ValueError(f\"Fixed dimensions ({k_hat}, {r_hat}) are invalid for data of shape ({p}, {q}).\")\n",
        "    else:\n",
        "        # If dimensions are not fixed, estimate them using the ratio test.\n",
        "        k_hat = _estimate_dimension_by_ratio(eigvals_R, k_max)\n",
        "        r_hat = _estimate_dimension_by_ratio(eigvals_C, r_max)\n",
        "\n",
        "    # --- Loading Matrix Construction ---\n",
        "    R_hat = np.sqrt(p) * eigvecs_R[:, :k_hat]\n",
        "    C_hat = np.sqrt(q) * eigvecs_C[:, :r_hat]\n",
        "\n",
        "    # --- Orthogonality Verification ---\n",
        "    identity_k = np.eye(k_hat)\n",
        "    if not np.allclose((1 / p) * (R_hat.T @ R_hat), identity_k, atol=1e-9):\n",
        "        raise RuntimeError(\"Orthogonality check for R_hat failed.\")\n",
        "    identity_r = np.eye(r_hat)\n",
        "    if not np.allclose((1 / q) * (C_hat.T @ C_hat), identity_r, atol=1e-9):\n",
        "        raise RuntimeError(\"Orthogonality check for C_hat failed.\")\n",
        "\n",
        "    return {\n",
        "        'k_hat': k_hat, 'r_hat': r_hat, 'R_hat': R_hat, 'C_hat': C_hat,\n",
        "        'eigenvalues_R': eigvals_R, 'eigenvalues_C': eigvals_C\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "PyKtIw_dak4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 6: Factor Matrix Estimation\n",
        "\n",
        "def estimate_factor_matrices(\n",
        "    X_tensor: np.ndarray,\n",
        "    R_hat: np.ndarray,\n",
        "    C_hat: np.ndarray,\n",
        "    perform_validation: bool = False\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Estimates the latent factor matrices and optionally validates the reconstruction.\n",
        "\n",
        "    This function projects the high-dimensional predictor data onto the low-\n",
        "    dimensional space spanned by the estimated loading matrices to recover the\n",
        "    sequence of latent factor matrices. It can also perform a validation step\n",
        "    by reconstructing the original data from the factors and calculating the\n",
        "    reconstruction error, which measures the information lost during dimension\n",
        "    reduction.\n",
        "\n",
        "    Args:\n",
        "        X_tensor (np.ndarray):\n",
        "            The (T, p, q) tensor of prepared predictor data.\n",
        "        R_hat (np.ndarray):\n",
        "            The (p, k) row loading matrix from Task 5.\n",
        "        C_hat (np.ndarray):\n",
        "            The (q, r) column loading matrix from Task 5.\n",
        "        perform_validation (bool):\n",
        "            If True, the function will compute the reconstructed data tensor\n",
        "            and calculate the mean squared reconstruction error. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing:\n",
        "            - 'F_hat_tensor' (np.ndarray): The estimated (T, k, r) latent\n",
        "              factor tensor.\n",
        "            - 'mean_squared_recon_error' (float, optional): The MSRE, returned\n",
        "              only if `perform_validation` is True.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If input matrix dimensions are inconsistent.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    # Rigorously check for dimensional consistency between all inputs.\n",
        "    if X_tensor.ndim != 3 or R_hat.ndim != 2 or C_hat.ndim != 2:\n",
        "        raise ValueError(\"Inputs must be 3D (X_tensor) and 2D (R_hat, C_hat).\")\n",
        "\n",
        "    T, p, q = X_tensor.shape\n",
        "    p_r, k = R_hat.shape\n",
        "    q_c, r = C_hat.shape\n",
        "\n",
        "    if p != p_r:\n",
        "        raise ValueError(f\"Dimension 'p' mismatch: X_tensor has {p} but R_hat has {p_r}.\")\n",
        "    if q != q_c:\n",
        "        raise ValueError(f\"Dimension 'q' mismatch: X_tensor has {q} but C_hat has {q_c}.\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 6.1: Factor Matrix Recovery\n",
        "    # =========================================================================\n",
        "    # Equation: F_hat_t = (1/pq) * R_hat' @ X_t @ C_hat\n",
        "    # We use np.einsum for a single, highly optimized tensor contraction.\n",
        "    # 'kp,tij,jq->tkq':\n",
        "    #   - R_hat' has shape (k, p) -> indices kp\n",
        "    #   - X_tensor has shape (T, p, q) -> indices tij\n",
        "    #   - C_hat has shape (q, r) -> indices jq (transposed in formula)\n",
        "    # The repeated indices p and j are summed over, resulting in a tensor\n",
        "    # with shape (t, k, q). This is incorrect.\n",
        "    # The correct einsum path for R_hat.T @ X_t @ C_hat is:\n",
        "    # 'ki,tij,jl->tkl'\n",
        "    #   - R_hat.T is (k, p) -> ki\n",
        "    #   - X_tensor is (T, p, q) -> tij\n",
        "    #   - C_hat is (q, r) -> jl\n",
        "    # Sum over i and j, leaving t, k, l. Result is (T, k, r).\n",
        "    F_hat_tensor = np.einsum(\n",
        "        'ki,tij,jl->tkl', R_hat.T, X_tensor, C_hat\n",
        "    ) / (p * q)\n",
        "\n",
        "    # Initialize the results dictionary with the primary output.\n",
        "    results = {'F_hat_tensor': F_hat_tensor}\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 6.2: Reconstruction Validation (Optional)\n",
        "    # =========================================================================\n",
        "    if perform_validation:\n",
        "        # Equation: X_hat_t = R_hat @ F_hat_t @ C_hat'\n",
        "        # The einsum path for this reconstruction is:\n",
        "        # 'ik,tkl,jl->tij'\n",
        "        #   - R_hat is (p, k) -> ik\n",
        "        #   - F_hat_tensor is (T, k, r) -> tkl\n",
        "        #   - C_hat.T is (r, q) -> jl\n",
        "        # Sum over k and l, leaving t, i, j. Result is (T, p, q).\n",
        "        X_hat_tensor = np.einsum(\n",
        "            'ik,tkl,jl->tij', R_hat, F_hat_tensor, C_hat.T\n",
        "        )\n",
        "\n",
        "        # Calculate the Mean Squared Reconstruction Error (MSRE).\n",
        "        # MSRE = (1 / (T*p*q)) * Σ_t ||X_t - X_hat_t||_F^2\n",
        "        # The squared Frobenius norm is the sum of squared element-wise differences.\n",
        "        squared_error = np.sum((X_tensor - X_hat_tensor) ** 2)\n",
        "        mean_squared_recon_error = squared_error / (T * p * q)\n",
        "\n",
        "        # Add the validation metric to the results dictionary.\n",
        "        results['mean_squared_recon_error'] = mean_squared_recon_error\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "Xm8QhnERbZ3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 7: LSE Initialization and Setup\n",
        "\n",
        "def setup_lse_training_data(\n",
        "    F_hat_tensor: np.ndarray,\n",
        "    y_vector: np.ndarray,\n",
        "    training_size: int,\n",
        "    forecast_horizon: int,\n",
        "    random_seed: Optional[int] = None\n",
        ") -> Dict[str, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Initializes parameters and prepares aligned training data for LSE.\n",
        "\n",
        "    This function performs two critical setup steps for the Iterative Least\n",
        "    Squares (ILS/LSE) algorithm:\n",
        "    1.  Initializes the forecasting loading vectors (alpha, beta) with\n",
        "        reproducible random values, applying normalization for identification.\n",
        "    2.  Constructs the training dataset by correctly slicing the factor tensor\n",
        "        and target vector according to the specified forecast horizon, ensuring\n",
        "        perfect alignment and preventing look-ahead bias.\n",
        "\n",
        "    Args:\n",
        "        F_hat_tensor (np.ndarray):\n",
        "            The (T, k, r) tensor of estimated latent factors from Task 6.\n",
        "        y_vector (np.ndarray):\n",
        "            The (T,) vector of the prepared target variable.\n",
        "        training_size (int):\n",
        "            The number of observations to include in the training set (T_train).\n",
        "        forecast_horizon (int):\n",
        "            The forecast horizon, h.\n",
        "        random_seed (Optional[int]):\n",
        "            A seed for the random number generator to ensure reproducible\n",
        "            parameter initialization. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, np.ndarray]: A dictionary containing the setup artifacts:\n",
        "            - 'F_train' (np.ndarray): The (T_train-h, k, r) tensor of factors\n",
        "              for training.\n",
        "            - 'y_train_target' (np.ndarray): The (T_train-h,) vector of\n",
        "              corresponding target values.\n",
        "            - 'alpha_init' (np.ndarray): The (k,) initial alpha vector.\n",
        "            - 'beta_init' (np.ndarray): The (r,) initial beta vector.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If training size or forecast horizon are invalid.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    if F_hat_tensor.ndim != 3:\n",
        "        raise ValueError(\"`F_hat_tensor` must be a 3D array.\")\n",
        "    if y_vector.ndim != 1:\n",
        "        raise ValueError(\"`y_vector` must be a 1D array.\")\n",
        "    if F_hat_tensor.shape[0] != y_vector.shape[0]:\n",
        "        raise ValueError(\"Time dimension T must be consistent for factors and target.\")\n",
        "    if not training_size > forecast_horizon:\n",
        "        raise ValueError(\n",
        "            f\"Training size ({training_size}) must be greater than the \"\n",
        "            f\"forecast horizon ({forecast_horizon}).\"\n",
        "        )\n",
        "    if training_size > F_hat_tensor.shape[0]:\n",
        "        raise ValueError(\n",
        "            f\"Training size ({training_size}) cannot exceed the total number \"\n",
        "            f\"of observations ({F_hat_tensor.shape[0]}).\"\n",
        "        )\n",
        "\n",
        "    # Extract dimensions for clarity.\n",
        "    T, k, r = F_hat_tensor.shape\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 7.1: Parameter Initialization\n",
        "    # =========================================================================\n",
        "    # Initialize a random number generator for reproducibility.\n",
        "    rng = np.random.default_rng(random_seed)\n",
        "\n",
        "    # Sample initial alpha from a standard multivariate normal distribution.\n",
        "    # Equation: α_hat^(0) ~ N(0, I_k)\n",
        "    alpha_init = rng.multivariate_normal(np.zeros(k), np.eye(k))\n",
        "\n",
        "    # Normalize alpha_init to have a unit L2 norm for model identification.\n",
        "    # Equation: α_hat^(0) <- α_hat^(0) / ||α_hat^(0)||_2\n",
        "    alpha_norm = np.linalg.norm(alpha_init)\n",
        "    # Add a safeguard against division by a near-zero norm.\n",
        "    if alpha_norm < 1e-12:\n",
        "        raise RuntimeError(\n",
        "            \"Initial alpha vector has a near-zero norm, causing normalization \"\n",
        "            \"to fail. This is a rare numerical anomaly; try a different seed.\"\n",
        "        )\n",
        "    alpha_init /= alpha_norm\n",
        "\n",
        "    # Sample initial beta from a standard multivariate normal distribution.\n",
        "    # Equation: β_hat^(0) ~ N(0, I_r)\n",
        "    beta_init = rng.multivariate_normal(np.zeros(r), np.eye(r))\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 7.2: Training Data Preparation and Alignment\n",
        "    # =========================================================================\n",
        "    # To predict y_{t+h} using F_t, we need to align the datasets.\n",
        "    # The training predictors F_train will run from t=0 to t=T_train-h-1.\n",
        "    # The training targets y_train_target will run from t=h to t=T_train-1.\n",
        "\n",
        "    # Define the slicing indices.\n",
        "    predictor_end_idx = training_size - forecast_horizon\n",
        "    target_start_idx = forecast_horizon\n",
        "    target_end_idx = training_size\n",
        "\n",
        "    # Slice the factor tensor to get the training predictors.\n",
        "    F_train = F_hat_tensor[0:predictor_end_idx, :, :]\n",
        "\n",
        "    # Slice the target vector to get the corresponding aligned targets.\n",
        "    y_train_target = y_vector[target_start_idx:target_end_idx]\n",
        "\n",
        "    # --- Final Alignment Validation ---\n",
        "    # The number of observations in the predictor and target training sets\n",
        "    # must be identical.\n",
        "    if F_train.shape[0] != y_train_target.shape[0]:\n",
        "        # This error should not be reachable if the logic is correct,\n",
        "        # but serves as a critical safeguard.\n",
        "        raise RuntimeError(\n",
        "            \"Internal error: Sliced training predictors and targets have \"\n",
        "            \"mismatched lengths. Check slicing logic.\"\n",
        "        )\n",
        "\n",
        "    # Compile and return the setup artifacts in a structured dictionary.\n",
        "    setup_artifacts = {\n",
        "        'F_train': F_train,\n",
        "        'y_train_target': y_train_target,\n",
        "        'alpha_init': alpha_init,\n",
        "        'beta_init': beta_init,\n",
        "    }\n",
        "\n",
        "    return setup_artifacts\n"
      ],
      "metadata": {
        "id": "KD44raXycD90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 8: Alternating Least Squares Implementation\n",
        "\n",
        "# =============================================================================\n",
        "# Helper Function: _solve_regularized_linear_system\n",
        "# =============================================================================\n",
        "\n",
        "def _solve_regularized_linear_system(\n",
        "    A: np.ndarray,\n",
        "    b: np.ndarray,\n",
        "    cond_threshold: float = 1e12,\n",
        "    reg_lambda: float = 1e-8\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Solves the linear system Ax = b with a regularization fallback.\n",
        "\n",
        "    This helper uses the numerically stable `scipy.linalg.solve`. If the\n",
        "    condition number of matrix A is too high, it applies Tikhonov (Ridge)\n",
        "    regularization by adding a small identity matrix to A before solving.\n",
        "\n",
        "    Args:\n",
        "        A (np.ndarray): The square matrix of the linear system.\n",
        "        b (np.ndarray): The vector of the linear system.\n",
        "        cond_threshold (float): The condition number above which to regularize.\n",
        "        reg_lambda (float): The small regularization parameter (lambda).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The solution vector x.\n",
        "    \"\"\"\n",
        "    # Check the condition number of the matrix A.\n",
        "    if np.linalg.cond(A) > cond_threshold:\n",
        "        # If ill-conditioned, apply regularization: A_reg = A + λI\n",
        "        A_reg = A + reg_lambda * np.eye(A.shape[0])\n",
        "        # Solve the regularized system.\n",
        "        x = scipy.linalg.solve(A_reg, b)\n",
        "    else:\n",
        "        # If well-conditioned, solve the standard system.\n",
        "        x = scipy.linalg.solve(A, b)\n",
        "    return x\n",
        "\n",
        "# =============================================================================\n",
        "# Main Orchestrator Function\n",
        "# =============================================================================\n",
        "\n",
        "def estimate_lse_parameters(\n",
        "    F_train: np.ndarray,\n",
        "    y_train_target: np.ndarray,\n",
        "    alpha_init: np.ndarray,\n",
        "    beta_init: np.ndarray,\n",
        "    max_iterations: int,\n",
        "    convergence_tolerance: float\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Estimates forecasting parameters alpha and beta via Iterative Least Squares.\n",
        "\n",
        "    This function implements the alternating least squares algorithm to solve\n",
        "    the bilinear regression problem. It iteratively updates alpha and beta\n",
        "    until the change in parameters falls below a tolerance threshold or the\n",
        "    maximum number of iterations is reached.\n",
        "\n",
        "    Args:\n",
        "        F_train (np.ndarray):\n",
        "            The (T_train-h, k, r) tensor of factors for training.\n",
        "        y_train_target (np.ndarray):\n",
        "            The (T_train-h,) vector of corresponding target values.\n",
        "        alpha_init (np.ndarray): The (k,) initial alpha vector.\n",
        "        beta_init (np.ndarray): The (r,) initial beta vector.\n",
        "        max_iterations (int): The maximum number of iterations to perform.\n",
        "        convergence_tolerance (float): The tolerance for the convergence criterion.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing the estimation results:\n",
        "            - 'alpha_hat' (np.ndarray): The final estimated (k,) alpha vector.\n",
        "            - 'beta_hat' (np.ndarray): The final estimated (r,) beta vector.\n",
        "            - 'converged' (bool): True if the algorithm converged within the\n",
        "              specified tolerance.\n",
        "            - 'iterations' (int): The number of iterations performed.\n",
        "            - 'convergence_history' (list): A log of the parameter change\n",
        "              at each iteration.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Initialization\n",
        "    # =========================================================================\n",
        "    # Set the initial parameter estimates.\n",
        "    alpha_current = alpha_init.copy()\n",
        "    beta_current = beta_init.copy()\n",
        "\n",
        "    # Initialize containers for convergence tracking.\n",
        "    convergence_history = []\n",
        "    converged = False\n",
        "\n",
        "    # =========================================================================\n",
        "    # Iterative Update Loop (Task 8.1, 8.2, 8.3)\n",
        "    # =========================================================================\n",
        "    for i in range(max_iterations):\n",
        "        # Store the parameter values from the start of the iteration.\n",
        "        alpha_previous = alpha_current.copy()\n",
        "        beta_previous = beta_current.copy()\n",
        "\n",
        "        # --- α-Update Step ---\n",
        "        # For a fixed beta, the problem is OLS: y = (F_t * beta)' * alpha\n",
        "        # We need to solve A * alpha = b, where:\n",
        "        # A = Σ [ (F_t * beta) * (F_t * beta)' ]\n",
        "        # b = Σ [ y_{t+h} * (F_t * beta) ]\n",
        "\n",
        "        # Efficiently compute the new predictors Z_alpha = F_train @ beta\n",
        "        # 'tkr,r->tk': for each t, (k,r) @ (r,) -> (k,)\n",
        "        Z_alpha = np.einsum('tkr,r->tk', F_train, beta_current)\n",
        "\n",
        "        # Compute the matrix A = Z_alpha' @ Z_alpha\n",
        "        # 'tk,tl->kl': sum over t of outer products of (k,) vectors\n",
        "        A_matrix = np.einsum('tk,tl->kl', Z_alpha, Z_alpha)\n",
        "\n",
        "        # Compute the vector b = Z_alpha' @ y\n",
        "        # 'tk,t->k': sum over t of (k,) vectors scaled by y\n",
        "        b_vector_alpha = np.einsum('tk,t->k', Z_alpha, y_train_target)\n",
        "\n",
        "        # Solve the linear system for the new alpha.\n",
        "        alpha_current = _solve_regularized_linear_system(A_matrix, b_vector_alpha)\n",
        "\n",
        "        # --- β-Update Step ---\n",
        "        # For a fixed alpha, the problem is OLS: y = (alpha' * F_t) * beta\n",
        "        # We need to solve B * beta = d, where:\n",
        "        # B = Σ [ (F_t' * alpha) * (F_t' * alpha)' ]\n",
        "        # d = Σ [ y_{t+h} * (F_t' * alpha) ]\n",
        "\n",
        "        # Efficiently compute the new predictors Z_beta = F_train.T @ alpha\n",
        "        # 'k,tkr->tr': for each t, (k,) @ (k,r) -> (r,)\n",
        "        Z_beta = np.einsum('k,tkr->tr', alpha_current, F_train)\n",
        "\n",
        "        # Compute the matrix B = Z_beta' @ Z_beta\n",
        "        # 'tr,ts->rs': sum over t of outer products of (r,) vectors\n",
        "        B_matrix = np.einsum('tr,ts->rs', Z_beta, Z_beta)\n",
        "\n",
        "        # Compute the vector d = Z_beta' @ y\n",
        "        # 'tr,t->r': sum over t of (r,) vectors scaled by y\n",
        "        d_vector_beta = np.einsum('tr,t->r', Z_beta, y_train_target)\n",
        "\n",
        "        # Solve the linear system for the new beta.\n",
        "        beta_current = _solve_regularized_linear_system(B_matrix, d_vector_beta)\n",
        "\n",
        "        # --- Convergence Monitoring ---\n",
        "        # Calculate the change in parameters from the previous iteration.\n",
        "        # Equation: Conv = ||α_new - α_old||_2 + ||β_new - β_old||_2\n",
        "        alpha_change = np.linalg.norm(alpha_current - alpha_previous)\n",
        "        beta_change = np.linalg.norm(beta_current - beta_previous)\n",
        "        total_change = alpha_change + beta_change\n",
        "        convergence_history.append(total_change)\n",
        "\n",
        "        # Check if the change is below the tolerance threshold.\n",
        "        if total_change < convergence_tolerance:\n",
        "            converged = True\n",
        "            # If converged, exit the loop.\n",
        "            break\n",
        "\n",
        "    # After the loop, check if convergence was not achieved.\n",
        "    if not converged:\n",
        "        warnings.warn(\n",
        "            f\"LSE algorithm did not converge within {max_iterations} \"\n",
        "            f\"iterations. The final parameter change was {total_change:.2e}. \"\n",
        "            \"Results may be unstable.\",\n",
        "            UserWarning\n",
        "        )\n",
        "\n",
        "    # Compile and return the final results.\n",
        "    results = {\n",
        "        'alpha_hat': alpha_current,\n",
        "        'beta_hat': beta_current,\n",
        "        'converged': converged,\n",
        "        'iterations': i + 1,\n",
        "        'convergence_history': convergence_history\n",
        "    }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "YMzUjZtqcwmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 9: Correlation Analysis Framework\n",
        "\n",
        "def compute_supervised_correlation_scores(\n",
        "    X_train_tensor: np.ndarray,\n",
        "    y_train_vector: np.ndarray,\n",
        "    country_names: List[str],\n",
        "    indicator_names: List[str]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Computes correlation scores for screening using ONLY training data.\n",
        "\n",
        "    This function implements the analysis for supervised screening in a\n",
        "    methodologically sound manner for forecasting, preventing data leakage. It\n",
        "    calculates the Pearson correlation between each predictor and the target\n",
        "    variable using exclusively the training dataset. These training-derived\n",
        "    scores are then used to generate rules for feature selection.\n",
        "\n",
        "    Args:\n",
        "        X_train_tensor (np.ndarray):\n",
        "            The (T_train, p, q) tensor of prepared training predictors.\n",
        "        y_train_vector (np.ndarray):\n",
        "            The (T_train,) vector of the prepared training target variable.\n",
        "        country_names (List[str]):\n",
        "            An ordered list of p country names.\n",
        "        indicator_names (List[str]):\n",
        "            An ordered list of q indicator names.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing the correlation analysis:\n",
        "            - 'correlation_matrix' (pd.DataFrame): A (p, q) DataFrame of\n",
        "              pairwise correlation coefficients derived from training data.\n",
        "            - 'row_avg_correlations' (pd.Series): A Series of length p with\n",
        "              the average absolute correlation for each country.\n",
        "            - 'col_avg_correlations' (pd.Series): A Series of length q with\n",
        "              the average absolute correlation for each indicator.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If input dimensions are inconsistent.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    # Verify that the input tensors have the expected dimensionality.\n",
        "    if not (X_train_tensor.ndim == 3 and y_train_vector.ndim == 1):\n",
        "        raise ValueError(\"Inputs must be a 3D X_train_tensor and 1D y_train_vector.\")\n",
        "\n",
        "    # Unpack dimensions and validate consistency.\n",
        "    T_train, p, q = X_train_tensor.shape\n",
        "    if T_train != len(y_train_vector):\n",
        "        raise ValueError(\"Time dimension T_train must match for inputs.\")\n",
        "    if p != len(country_names) or q != len(indicator_names):\n",
        "        raise ValueError(\"Dimensions p and q must match lengths of name lists.\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 1: Pairwise Correlation Computation on Training Data\n",
        "    # =========================================================================\n",
        "    # Reshape the (T_train, p, q) tensor into a (T_train, p*q) matrix.\n",
        "    # This vectorization enables efficient, parallel computation of all correlations.\n",
        "    X_train_flat = X_train_tensor.reshape(T_train, p * q, order='F')\n",
        "\n",
        "    # Center the training data. This is a step in the standard correlation formula.\n",
        "    # Note: The input data from `prepare_forecasting_data` is already centered\n",
        "    # using the training mean, so this step is technically redundant but serves\n",
        "    # as a robust safeguard if the function is used with uncentered data.\n",
        "    X_train_centered = X_train_flat - np.mean(X_train_flat, axis=0)\n",
        "    y_train_centered = y_train_vector - np.mean(y_train_vector)\n",
        "\n",
        "    # Calculate the standard deviation of each predictor series and the target.\n",
        "    # A small epsilon is added to the denominator to prevent division by zero\n",
        "    # in the case of a constant series (which should have been handled earlier).\n",
        "    epsilon = 1e-12\n",
        "    std_X_train = np.std(X_train_flat, axis=0) + epsilon\n",
        "    std_y_train = np.std(y_train_vector) + epsilon\n",
        "\n",
        "    # Compute the covariance vector using a single matrix-vector product.\n",
        "    # This is the numerator of the Pearson correlation formula.\n",
        "    cov_vector = (1 / (T_train - 1)) * (X_train_centered.T @ y_train_centered)\n",
        "\n",
        "    # Compute the final Pearson correlation coefficients.\n",
        "    # Equation: ρ = cov(x, y) / (σ_x * σ_y)\n",
        "    correlation_vector = cov_vector / (std_X_train * std_y_train)\n",
        "\n",
        "    # Reshape the (p*q,) vector of correlations back into a (p, q) matrix.\n",
        "    correlation_matrix_np = correlation_vector.reshape(p, q, order='F')\n",
        "\n",
        "    # Convert the numpy matrix to a labeled pandas DataFrame for interpretability.\n",
        "    correlation_matrix = pd.DataFrame(\n",
        "        correlation_matrix_np,\n",
        "        index=country_names,\n",
        "        columns=indicator_names\n",
        "    )\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 2: Average Correlation Computation\n",
        "    # =========================================================================\n",
        "    # Take the absolute value of the correlation matrix to treat positive and\n",
        "    # negative correlations as equally informative.\n",
        "    abs_correlation_matrix = np.abs(correlation_matrix_np)\n",
        "\n",
        "    # Calculate the average absolute correlation for each row (country).\n",
        "    # Equation: ρ_bar_i = (1/q) * Σ_j |ρ_{ij}|\n",
        "    row_avg_corrs_np = np.mean(abs_correlation_matrix, axis=1)\n",
        "\n",
        "    # Calculate the average absolute correlation for each column (indicator).\n",
        "    # Equation: ρ_bar_j = (1/p) * Σ_i |ρ_{ij}|\n",
        "    col_avg_corrs_np = np.mean(abs_correlation_matrix, axis=0)\n",
        "\n",
        "    # Convert the numpy arrays to labeled pandas Series.\n",
        "    row_avg_correlations = pd.Series(row_avg_corrs_np, index=country_names)\n",
        "    col_avg_correlations = pd.Series(col_avg_corrs_np, index=indicator_names)\n",
        "\n",
        "    # Compile and return the final results.\n",
        "    results = {\n",
        "        'correlation_matrix': correlation_matrix,\n",
        "        'row_avg_correlations': row_avg_correlations,\n",
        "        'col_avg_correlations': col_avg_correlations,\n",
        "    }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "6LwgaRNadc-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 10: Screening Implementation\n",
        "\n",
        "def perform_supervised_screening(\n",
        "    X_tensor: np.ndarray,\n",
        "    country_names: List[str],\n",
        "    indicator_names: List[str],\n",
        "    row_avg_correlations: pd.Series,\n",
        "    col_avg_correlations: pd.Series,\n",
        "    row_threshold: float,\n",
        "    col_threshold: float\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Filters the predictor tensor based on supervised correlation scores.\n",
        "\n",
        "    This function implements the supervised screening procedure described in the\n",
        "    paper. It uses pre-computed average correlation scores to identify and\n",
        "    retain only the most relevant rows (countries) and columns (indicators)\n",
        "    from the original high-dimensional predictor data tensor.\n",
        "\n",
        "    Args:\n",
        "        X_tensor (np.ndarray):\n",
        "            The original (T, p, q) tensor of prepared predictor data.\n",
        "        country_names (List[str]):\n",
        "            The ordered list of p country names for the original tensor.\n",
        "        indicator_names (List[str]):\n",
        "            The ordered list of q indicator names for the original tensor.\n",
        "        row_avg_correlations (pd.Series):\n",
        "            A Series of length p with average absolute correlation scores for\n",
        "            each country, indexed by country name.\n",
        "        col_avg_correlations (pd.Series):\n",
        "            A Series of length q with average absolute correlation scores for\n",
        "            each indicator, indexed by indicator name.\n",
        "        row_threshold (float):\n",
        "            The correlation threshold for retaining a row (country).\n",
        "        col_threshold (float):\n",
        "            The correlation threshold for retaining a column (indicator).\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing the screened results:\n",
        "            - 'X_tilde_tensor' (np.ndarray): The refined (T, p_tilde, q_tilde)\n",
        "              predictor tensor.\n",
        "            - 'retained_countries' (List[str]): The ordered list of p_tilde\n",
        "              retained country names.\n",
        "            - 'retained_indicators' (List[str]): The ordered list of q_tilde\n",
        "              retained indicator names.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If screening results in an empty dataset.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    if not (isinstance(row_avg_correlations, pd.Series) and\n",
        "            isinstance(col_avg_correlations, pd.Series)):\n",
        "        raise TypeError(\"Correlation scores must be pandas Series.\")\n",
        "    if set(country_names) != set(row_avg_correlations.index):\n",
        "        raise ValueError(\"Country names must match the index of row correlations.\")\n",
        "    if set(indicator_names) != set(col_avg_correlations.index):\n",
        "        raise ValueError(\"Indicator names must match the index of col correlations.\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 10.1: Threshold-Based Filtering\n",
        "    # =========================================================================\n",
        "    # Identify rows (countries) to retain based on the threshold.\n",
        "    # A country is kept if its average absolute correlation is >= the threshold.\n",
        "    retained_countries_mask = row_avg_correlations >= row_threshold\n",
        "    retained_countries = row_avg_correlations[retained_countries_mask].index.tolist()\n",
        "\n",
        "    # Identify columns (indicators) to retain based on the threshold.\n",
        "    retained_indicators_mask = col_avg_correlations >= col_threshold\n",
        "    retained_indicators = col_avg_correlations[retained_indicators_mask].index.tolist()\n",
        "\n",
        "    # --- Validation of Filtering Outcome ---\n",
        "    # Check if the filtering process removed all rows or columns.\n",
        "    if not retained_countries:\n",
        "        raise ValueError(\n",
        "            f\"Screening with row_threshold={row_threshold} removed all countries. \"\n",
        "            \"Consider a lower threshold.\"\n",
        "        )\n",
        "    if not retained_indicators:\n",
        "        raise ValueError(\n",
        "            f\"Screening with col_threshold={col_threshold} removed all indicators. \"\n",
        "            \"Consider a lower threshold.\"\n",
        "        )\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 10.2: Refined Matrix Construction\n",
        "    # =========================================================================\n",
        "    # To slice the numpy tensor, we need the integer indices of the retained entities.\n",
        "    # Create a mapping from name to original index position.\n",
        "    country_to_idx = {name: i for i, name in enumerate(country_names)}\n",
        "    indicator_to_idx = {name: i for i, name in enumerate(indicator_names)}\n",
        "\n",
        "    # Get the integer indices for the retained rows and columns.\n",
        "    retained_row_indices = sorted([country_to_idx[name] for name in retained_countries])\n",
        "    retained_col_indices = sorted([indicator_to_idx[name] for name in retained_indicators])\n",
        "\n",
        "    # Also get the sorted lists of names for the output.\n",
        "    sorted_retained_countries = [country_names[i] for i in retained_row_indices]\n",
        "    sorted_retained_indicators = [indicator_names[i] for i in retained_col_indices]\n",
        "\n",
        "    # Use advanced numpy indexing to efficiently slice the original tensor.\n",
        "    # This selects all time steps (:) and the specific rows and columns.\n",
        "    X_tilde_tensor = X_tensor[:, retained_row_indices, :][:, :, retained_col_indices]\n",
        "\n",
        "    # --- Final Shape Validation ---\n",
        "    # Assert that the shape of the new tensor matches the number of retained entities.\n",
        "    T, p_tilde, q_tilde = X_tilde_tensor.shape\n",
        "    if p_tilde != len(sorted_retained_countries) or q_tilde != len(sorted_retained_indicators):\n",
        "        raise RuntimeError(\"Internal error: Shape of the refined tensor is inconsistent.\")\n",
        "\n",
        "    # Compile and return the final results.\n",
        "    results = {\n",
        "        'X_tilde_tensor': X_tilde_tensor,\n",
        "        'retained_countries': sorted_retained_countries,\n",
        "        'retained_indicators': sorted_retained_indicators,\n",
        "    }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "keIGAPWGeAgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 11: Re-application of α-PCA on Screened Data\n",
        "\n",
        "def run_apca_pipeline(\n",
        "    X_tensor: np.ndarray,\n",
        "    alpha: float,\n",
        "    fixed_kr: Optional[Tuple[int, int]] = None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Executes the complete α-PCA factor extraction pipeline on a given data tensor.\n",
        "\n",
        "    This function serves as a master orchestrator for Tasks 3 through 6. It\n",
        "    takes a data tensor and hyperparameters, computes all necessary statistics\n",
        "    and matrices, and returns the final factor representation and loading\n",
        "    matrices. It can operate in two modes: estimating the factor dimensions\n",
        "    or using pre-specified, fixed dimensions.\n",
        "\n",
        "    Args:\n",
        "        X_tensor (np.ndarray):\n",
        "            The (T, p, q) data tensor to be analyzed.\n",
        "        alpha (float):\n",
        "            The α-PCA hyperparameter, must be >= -1.\n",
        "        fixed_kr (Optional[Tuple[int, int]]):\n",
        "            If provided, these (k, r) dimensions are used, bypassing estimation.\n",
        "            If None, dimensions are estimated from the data. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing all key pipeline artifacts,\n",
        "                        including the factor tensor, loading matrices, and\n",
        "                        the dimensions (k_hat, r_hat) that were used.\n",
        "    \"\"\"\n",
        "    # --- Step 1 (Task 3): Sample Statistics Computation ---\n",
        "    # This step computes the mean matrix and the tensor of deviations.\n",
        "    sample_mean_matrix, deviation_tensor = compute_sample_statistics(X_tensor)\n",
        "    T, p, q = X_tensor.shape\n",
        "\n",
        "    # --- Step 2 (Task 4): Moment Aggregation Matrix Construction ---\n",
        "    # This step builds the core M_R and M_C matrices for eigendecomposition.\n",
        "    M_R, M_C = construct_moment_aggregation_matrices(\n",
        "        sample_mean_matrix, deviation_tensor, alpha\n",
        "    )\n",
        "\n",
        "    # --- Step 3 (Task 5): Eigendecomposition and Loading Matrix Extraction ---\n",
        "    # This step now flexibly handles both estimated and fixed dimensions.\n",
        "    # Define the maximum possible dimensions for the estimation case.\n",
        "    k_max = max(1, math.floor(p / 2))\n",
        "    r_max = max(1, math.floor(q / 2))\n",
        "\n",
        "    # Call the flexible, re-implemented helper function.\n",
        "    loading_results = extract_loadings_and_dimensions(\n",
        "        M_R, M_C, p, q, k_max, r_max, fixed_kr=fixed_kr\n",
        "    )\n",
        "    R_hat = loading_results['R_hat']\n",
        "    C_hat = loading_results['C_hat']\n",
        "\n",
        "    # --- Step 4 (Task 6): Factor Matrix Estimation ---\n",
        "    # This step projects the data onto the factor space defined by the loadings.\n",
        "    factor_results = estimate_factor_matrices(\n",
        "        X_tensor, R_hat, C_hat, perform_validation=False\n",
        "    )\n",
        "    F_hat_tensor = factor_results['F_hat_tensor']\n",
        "\n",
        "    # --- Final Output Compilation ---\n",
        "    # Combine all results into a single, comprehensive dictionary.\n",
        "    pipeline_results = {\n",
        "        'F_hat_tensor': F_hat_tensor,\n",
        "        'R_hat': R_hat,\n",
        "        'C_hat': C_hat,\n",
        "        'k_hat': loading_results['k_hat'],\n",
        "        'r_hat': loading_results['r_hat'],\n",
        "        'M_R': M_R,\n",
        "        'M_C': M_C,\n",
        "        'eigenvalues_R': loading_results['eigenvalues_R'],\n",
        "        'eigenvalues_C': loading_results['eigenvalues_C'],\n",
        "    }\n",
        "\n",
        "    return pipeline_results\n",
        "\n",
        "def reapply_apca_on_screened_data(\n",
        "    X_tilde_tensor: np.ndarray,\n",
        "    alpha: float\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Orchestrates the re-application of the α-PCA pipeline on screened data.\n",
        "\n",
        "    This function takes the refined data tensor from the supervised screening\n",
        "    step (Task 10) and runs it through the entire α-PCA factor extraction\n",
        "    pipeline (Tasks 3-6). It demonstrates the modularity of the implemented\n",
        "    functions by reusing them with the new, smaller data dimensions.\n",
        "\n",
        "    Args:\n",
        "        X_tilde_tensor (np.ndarray):\n",
        "            The refined (T, p_tilde, q_tilde) predictor tensor from Task 10.\n",
        "        alpha (float):\n",
        "            The α-PCA hyperparameter, must be >= -1.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]:\n",
        "            A dictionary containing all artifacts from the α-PCA pipeline,\n",
        "            now computed on the screened data. The keys are identical to the\n",
        "            output of `run_apca_pipeline`.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    if not isinstance(X_tilde_tensor, np.ndarray) or X_tilde_tensor.ndim != 3:\n",
        "        raise ValueError(\"`X_tilde_tensor` must be a 3D numpy array.\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 11.1 & 11.2: Re-application of the α-PCA Pipeline\n",
        "    # =========================================================================\n",
        "    # The core of this task is to call the master pipeline function, which\n",
        "    # encapsulates Tasks 3 through 6, with the new screened data. The\n",
        "    # `run_apca_pipeline` function will automatically handle the updated\n",
        "    # dimensions (p_tilde, q_tilde) for all internal calculations, including\n",
        "    # scaling factors and k_max/r_max determination.\n",
        "\n",
        "    print(\n",
        "        f\"Re-applying α-PCA pipeline on screened data with dimensions \"\n",
        "        f\"T={X_tilde_tensor.shape[0]}, p_tilde={X_tilde_tensor.shape[1]}, \"\n",
        "        f\"q_tilde={X_tilde_tensor.shape[2]}...\"\n",
        "    )\n",
        "\n",
        "    # Execute the pipeline.\n",
        "    screened_pipeline_results = run_apca_pipeline(\n",
        "        X_tensor=X_tilde_tensor,\n",
        "        alpha=alpha\n",
        "    )\n",
        "\n",
        "    print(\"Re-application of α-PCA pipeline on screened data complete.\")\n",
        "\n",
        "    return screened_pipeline_results\n"
      ],
      "metadata": {
        "id": "TmjzDGpHepT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 12: Out-of-Sample Forecasting\n",
        "\n",
        "def generate_out_of_sample_forecasts(\n",
        "    X_test_tensor: np.ndarray,\n",
        "    test_index: pd.DatetimeIndex,\n",
        "    R_hat: np.ndarray,\n",
        "    C_hat: np.ndarray,\n",
        "    alpha_hat: np.ndarray,\n",
        "    beta_hat: np.ndarray,\n",
        "    forecast_horizon: int\n",
        ") -> pd.Series:\n",
        "    \"\"\"\n",
        "    Generates out-of-sample forecasts using the trained factor model.\n",
        "\n",
        "    This function executes the complete out-of-sample forecasting process:\n",
        "    1.  It takes the unseen predictor data for the test period (`X_test_tensor`).\n",
        "    2.  It projects this data into the latent factor space using the loading\n",
        "        matrices (`R_hat`, `C_hat`) that were estimated *only* on the training data.\n",
        "    3.  It applies the estimated forecasting equation using the converged\n",
        "        parameters (`alpha_hat`, `beta_hat`) to the out-of-sample factors to\n",
        "        generate predictions.\n",
        "    4.  It returns the forecasts as a pandas Series with a correctly aligned\n",
        "        DatetimeIndex.\n",
        "\n",
        "    Args:\n",
        "        X_test_tensor (np.ndarray):\n",
        "            The (T_test, p, q) tensor of prepared predictor data for the test period.\n",
        "        test_index (pd.DatetimeIndex):\n",
        "            The DatetimeIndex corresponding to the time dimension of `X_test_tensor`.\n",
        "        R_hat (np.ndarray):\n",
        "            The (p, k) row loading matrix estimated from the training data.\n",
        "        C_hat (np.ndarray):\n",
        "            The (q, r) column loading matrix estimated from the training data.\n",
        "        alpha_hat (np.ndarray):\n",
        "            The final estimated (k,) alpha vector from the LSE algorithm.\n",
        "        beta_hat (np.ndarray):\n",
        "            The final estimated (r,) beta vector from the LSE algorithm.\n",
        "        forecast_horizon (int):\n",
        "            The forecast horizon, h, used to correctly align the forecast index.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series:\n",
        "            A pandas Series containing the out-of-sample forecasts, indexed by\n",
        "            the forecast target date.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If input dimensions are inconsistent.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    if X_test_tensor.shape[1] != R_hat.shape[0] or \\\n",
        "       X_test_tensor.shape[2] != C_hat.shape[0]:\n",
        "        raise ValueError(\"Dimensions of X_test_tensor and loading matrices are inconsistent.\")\n",
        "    if R_hat.shape[1] != alpha_hat.shape[0] or \\\n",
        "       C_hat.shape[1] != beta_hat.shape[0]:\n",
        "        raise ValueError(\"Dimensions of loading matrices and parameter vectors are inconsistent.\")\n",
        "    if X_test_tensor.shape[0] != len(test_index):\n",
        "        raise ValueError(\"Length of test_index must match time dimension of X_test_tensor.\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 12.1: Test Period Factor Computation\n",
        "    # =========================================================================\n",
        "    # This is a critical step: we project the out-of-sample data using the\n",
        "    # loadings estimated *only* from the training data. This prevents data leakage.\n",
        "    # We reuse the robust `estimate_factor_matrices` function for this projection.\n",
        "    test_factor_results = estimate_factor_matrices(\n",
        "        X_tensor=X_test_tensor,\n",
        "        R_hat=R_hat,\n",
        "        C_hat=C_hat,\n",
        "        perform_validation=False  # Validation is not needed for forecasting.\n",
        "    )\n",
        "    F_test_tensor = test_factor_results['F_hat_tensor']\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 12.2: Forecast Generation\n",
        "    # =========================================================================\n",
        "    # Apply the estimated forecasting equation to the out-of-sample factors.\n",
        "    # Equation: y_hat_{t+h} = alpha_hat' @ F_hat_t @ beta_hat\n",
        "    # We use np.einsum for a highly efficient, vectorized computation over the\n",
        "    # entire test set.\n",
        "    # 'k,tkr,r->t': For each time step t, this performs the bilinear form\n",
        "    #               multiplication, summing over k and r to produce a scalar.\n",
        "    y_hat_vector = np.einsum(\n",
        "        'k,tkr,r->t', alpha_hat, F_test_tensor, beta_hat\n",
        "    )\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 12.3: Forecast Storage and Organization\n",
        "    # =========================================================================\n",
        "    # The forecast generated at index `t` (from `F_test_tensor[t]`) is for\n",
        "    # the target at time `t+h`. We need to shift the index accordingly.\n",
        "    # We assume the test_index has a defined frequency.\n",
        "    try:\n",
        "        # This is the most robust way to shift a DatetimeIndex.\n",
        "        forecast_index = test_index.shift(forecast_horizon)\n",
        "    except AttributeError:\n",
        "        raise TypeError(\n",
        "            \"test_index must be a pandas DatetimeIndex with a defined frequency \"\n",
        "            \"to correctly align forecasts.\"\n",
        "        )\n",
        "\n",
        "    # Create the final pandas Series with the correctly aligned index.\n",
        "    forecast_series = pd.Series(y_hat_vector, index=forecast_index)\n",
        "    forecast_series.name = 'forecast'\n",
        "\n",
        "    return forecast_series\n"
      ],
      "metadata": {
        "id": "cF4AdJUwfdlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 13: Performance Metrics Computation\n",
        "\n",
        "def compute_performance_metrics(\n",
        "    y_true: pd.Series,\n",
        "    y_pred: pd.Series\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Computes a suite of performance metrics for out-of-sample forecasts.\n",
        "\n",
        "    This function rigorously evaluates the accuracy of forecasts by comparing\n",
        "    them against the true, realized values. It handles the critical step of\n",
        "    aligning the two time series before calculating the forecast errors and\n",
        "    then computes the Mean Squared Forecast Error (MSFE), Root Mean Squared\n",
        "    Error (RMSE), and Mean Absolute Error (MAE).\n",
        "\n",
        "    Args:\n",
        "        y_true (pd.Series):\n",
        "            A pandas Series containing the true, realized values of the target\n",
        "            variable, with a DatetimeIndex.\n",
        "        y_pred (pd.Series):\n",
        "            A pandas Series containing the model's forecasts, with a\n",
        "            DatetimeIndex.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing the performance metrics:\n",
        "            - 'metrics' (Dict[str, float]): A sub-dictionary with keys\n",
        "              'MSFE', 'RMSE', 'MAE'.\n",
        "            - 'evaluation_df' (pd.DataFrame): A DataFrame containing the\n",
        "              aligned true values, predictions, and forecast errors.\n",
        "            - 'n_observations' (int): The number of observations used for\n",
        "              evaluation after alignment.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If inputs are not pandas Series or if no overlapping\n",
        "                    data points are found for evaluation.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    if not isinstance(y_true, pd.Series) or not isinstance(y_pred, pd.Series):\n",
        "        raise TypeError(\"Inputs `y_true` and `y_pred` must be pandas Series.\")\n",
        "    if not isinstance(y_true.index, pd.DatetimeIndex) or \\\n",
        "       not isinstance(y_pred.index, pd.DatetimeIndex):\n",
        "        raise TypeError(\"Indices of `y_true` and `y_pred` must be DatetimeIndex.\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Data Alignment and Error Calculation\n",
        "    # =========================================================================\n",
        "    # Combine the true values and predictions into a single DataFrame.\n",
        "    # This allows pandas to automatically align the data based on the index.\n",
        "    evaluation_df = pd.concat([y_true.rename('y_true'), y_pred.rename('y_pred')], axis=1)\n",
        "\n",
        "    # Drop any rows with missing values in either column. This is the most\n",
        "    # robust way to ensure we are only evaluating on the intersection of\n",
        "    # available true values and forecasts.\n",
        "    evaluation_df.dropna(inplace=True)\n",
        "\n",
        "    # Check if any data remains for evaluation.\n",
        "    n_observations = len(evaluation_df)\n",
        "    if n_observations == 0:\n",
        "        raise ValueError(\n",
        "            \"No overlapping data points found between `y_true` and `y_pred`. \"\n",
        "            \"Cannot compute performance metrics.\"\n",
        "        )\n",
        "\n",
        "    # Calculate the forecast error.\n",
        "    # Equation: e_t = y_true_t - y_pred_t\n",
        "    evaluation_df['error'] = evaluation_df['y_true'] - evaluation_df['y_pred']\n",
        "    errors = evaluation_df['error'].to_numpy()\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 13.1: MSFE Calculation\n",
        "    # =========================================================================\n",
        "    # Equation: MSFE = (1/N) * Σ(e_t^2)\n",
        "    msfe = np.mean(np.square(errors))\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 13.2: Additional Metrics\n",
        "    # =========================================================================\n",
        "    # Equation: RMSE = sqrt(MSFE)\n",
        "    rmse = np.sqrt(msfe)\n",
        "\n",
        "    # Equation: MAE = (1/N) * Σ|e_t|\n",
        "    mae = np.mean(np.abs(errors))\n",
        "\n",
        "    # =========================================================================\n",
        "    # Compile and Return Results\n",
        "    # =========================================================================\n",
        "    metrics = {\n",
        "        'MSFE': msfe,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "    }\n",
        "\n",
        "    results = {\n",
        "        'metrics': metrics,\n",
        "        'evaluation_df': evaluation_df,\n",
        "        'n_observations': n_observations,\n",
        "    }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "Z13GM3cMgH4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 14: Statistical Significance Testing\n",
        "\n",
        "def perform_diebold_mariano_test(\n",
        "    y_true: pd.Series,\n",
        "    y_pred1: pd.Series,\n",
        "    y_pred2: pd.Series,\n",
        "    forecast_horizon: int,\n",
        "    loss_func: str = 'squared_error'\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Performs the Diebold-Mariano test for superior predictive accuracy.\n",
        "\n",
        "    This function compares the forecasts from two models to determine if the\n",
        "    observed difference in their accuracy is statistically significant. It\n",
        "    implements the test with a Heteroskedasticity and Autocorrelation\n",
        "    Consistent (HAC) variance estimator and the Harvey, Leybourne, and\n",
        "    Newbold (1997) small-sample correction.\n",
        "\n",
        "    The null hypothesis (H0) is that the two models have equal predictive\n",
        "    accuracy. The alternative hypothesis (H1) is that they do not. A low\n",
        "    p-value suggests that one model is significantly better than the other.\n",
        "\n",
        "    Args:\n",
        "        y_true (pd.Series):\n",
        "            The true, realized values of the target variable.\n",
        "        y_pred1 (pd.Series):\n",
        "            The forecasts from Model 1.\n",
        "        y_pred2 (pd.Series):\n",
        "            The forecasts from Model 2.\n",
        "        forecast_horizon (int):\n",
        "            The forecast horizon, h. This is crucial for the HAC estimator.\n",
        "        loss_func (str):\n",
        "            The loss function to use. Currently supports 'squared_error' (for MSFE)\n",
        "            and 'absolute_error' (for MAE). Defaults to 'squared_error'.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing the test results:\n",
        "            - 'dm_statistic' (float): The value of the Diebold-Mariano test statistic\n",
        "              (with small-sample correction).\n",
        "            - 'p_value' (float): The two-sided p-value.\n",
        "            - 'interpretation' (str): A plain-language interpretation of the result.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If inputs are invalid or no overlapping data is found.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation and Data Alignment\n",
        "    # =========================================================================\n",
        "    if not all(isinstance(s, pd.Series) for s in [y_true, y_pred1, y_pred2]):\n",
        "        raise TypeError(\"All inputs must be pandas Series.\")\n",
        "    if forecast_horizon < 1:\n",
        "        raise ValueError(\"Forecast horizon must be a positive integer.\")\n",
        "\n",
        "    # Align all three series and drop any non-overlapping points.\n",
        "    eval_df = pd.concat([\n",
        "        y_true.rename('y_true'),\n",
        "        y_pred1.rename('y_pred1'),\n",
        "        y_pred2.rename('y_pred2')\n",
        "    ], axis=1).dropna()\n",
        "\n",
        "    n_obs = len(eval_df)\n",
        "    if n_obs < 2:\n",
        "        raise ValueError(\"Not enough overlapping data points to perform the test.\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 14.1: Diebold-Mariano Test Implementation\n",
        "    # =========================================================================\n",
        "    # --- Compute Forecast Errors ---\n",
        "    e1 = eval_df['y_true'] - eval_df['y_pred1']\n",
        "    e2 = eval_df['y_true'] - eval_df['y_pred2']\n",
        "\n",
        "    # --- Compute Loss Differentials ---\n",
        "    # Equation: d_t = L(e_1t) - L(e_2t)\n",
        "    if loss_func == 'squared_error':\n",
        "        d = e1**2 - e2**2\n",
        "    elif loss_func == 'absolute_error':\n",
        "        d = np.abs(e1) - np.abs(e2)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported loss function. Use 'squared_error' or 'absolute_error'.\")\n",
        "\n",
        "    d_np = d.to_numpy()\n",
        "    d_mean = np.mean(d_np)\n",
        "\n",
        "    # --- Compute HAC Variance of the Mean Loss Differential ---\n",
        "    # Equation: Var(d_mean) = (1/N) * [γ_0 + 2 * Σ_{j=1 to h-1} γ_j]\n",
        "    # where γ_j is the j-th autocovariance of the loss differential series d.\n",
        "    # We use statsmodels' acovf to get the autocovariance function.\n",
        "    gamma = acovf(d_np, nlag=forecast_horizon - 1, fft=False)\n",
        "    var_d_mean = (gamma[0] + 2 * np.sum(gamma[1:])) / n_obs\n",
        "\n",
        "    # If variance is negative or zero (numerical artifact), test is invalid.\n",
        "    if var_d_mean <= 0:\n",
        "        warnings.warn(\"HAC variance of loss differential is non-positive. Test is invalid.\")\n",
        "        return {'dm_statistic': np.nan, 'p_value': np.nan, 'interpretation': 'Invalid test'}\n",
        "\n",
        "    # --- Compute the Diebold-Mariano Statistic ---\n",
        "    # Equation: DM = d_mean / sqrt(Var(d_mean))\n",
        "    dm_stat_raw = d_mean / np.sqrt(var_d_mean)\n",
        "\n",
        "    # --- Apply Harvey, Leybourne, and Newbold (1997) Small-Sample Correction ---\n",
        "    # This correction is crucial for small test sets.\n",
        "    # Equation: DM* = sqrt([N+1-2h+h(h-1)/N] / N) * DM\n",
        "    correction_factor = np.sqrt(\n",
        "        (n_obs + 1 - 2 * forecast_horizon + forecast_horizon * (forecast_horizon - 1) / n_obs) / n_obs\n",
        "    )\n",
        "    dm_stat_corrected = correction_factor * dm_stat_raw\n",
        "\n",
        "    # --- Calculate the p-value ---\n",
        "    # The corrected statistic is compared to a t-distribution with N-1 degrees of freedom.\n",
        "    # We compute a two-sided p-value.\n",
        "    p_value = 2 * t.sf(np.abs(dm_stat_corrected), df=n_obs - 1)\n",
        "\n",
        "    # --- Provide Interpretation ---\n",
        "    if p_value < 0.01:\n",
        "        interpretation = \"Reject H0 at 1% level. Predictive accuracies are significantly different.\"\n",
        "    elif p_value < 0.05:\n",
        "        interpretation = \"Reject H0 at 5% level. Predictive accuracies are significantly different.\"\n",
        "    elif p_value < 0.10:\n",
        "        interpretation = \"Reject H0 at 10% level. Predictive accuracies are significantly different.\"\n",
        "    else:\n",
        "        interpretation = \"Fail to reject H0. No significant difference in predictive accuracy.\"\n",
        "\n",
        "    # Add detail about which model is better.\n",
        "    if d_mean < 0: # Loss of model 1 is less than model 2\n",
        "        interpretation += \" (Model 1 is preferred)\"\n",
        "    elif d_mean > 0: # Loss of model 2 is less than model 1\n",
        "        interpretation += \" (Model 2 is preferred)\"\n",
        "\n",
        "\n",
        "    results = {\n",
        "        'dm_statistic': dm_stat_corrected,\n",
        "        'p_value': p_value,\n",
        "        'interpretation': interpretation\n",
        "    }\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "rN80C0JMg0nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 15: Benchmark Model Setup\n",
        "\n",
        "# =============================================================================\n",
        "# Data Preparation Helper\n",
        "# =============================================================================\n",
        "\n",
        "def _prepare_benchmark_data(\n",
        "    X_tensor: np.ndarray,\n",
        "    y_vector: np.ndarray,\n",
        "    training_size: int,\n",
        "    forecast_horizon: int\n",
        ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, pd.Series, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Prepares aligned and vectorized data splits for benchmark models.\n",
        "\n",
        "    This helper function is a crucial preparatory step for ensuring a fair\n",
        "    comparison across all models. It takes the full predictor tensor and\n",
        "    target vector and performs two key operations:\n",
        "    1.  It splits the data into training and testing sets according to the\n",
        "        specified training size and forecast horizon, ensuring perfect\n",
        "        temporal alignment between predictors (X) and the target (y).\n",
        "    2.  It vectorizes the 3D predictor tensor (T, p, q) into a 2D matrix\n",
        "        (T, p*q), which is the required input format for standard linear\n",
        "        models like OLS and Lasso.\n",
        "\n",
        "    Args:\n",
        "        X_tensor (np.ndarray):\n",
        "            The full (T, p, q) tensor of prepared predictor data.\n",
        "        y_vector (np.ndarray):\n",
        "            The full (T,) vector of the prepared target variable.\n",
        "        training_size (int):\n",
        "            The number of observations from the start of the sample to be\n",
        "            used for training (T_train).\n",
        "        forecast_horizon (int):\n",
        "            The forecast horizon, h.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray, np.ndarray, pd.Series, np.ndarray]:\n",
        "            A tuple containing all necessary data splits:\n",
        "            - X_train_flat (np.ndarray): The (T_train-h, p*q) vectorized\n",
        "              training predictors.\n",
        "            - y_train_target (np.ndarray): The (T_train-h,) aligned training\n",
        "              target vector.\n",
        "            - X_test_flat (np.ndarray): The (T_test, p*q) vectorized test\n",
        "              predictors.\n",
        "            - y_test_true (pd.Series): The ground-truth target values for the\n",
        "              test period, as a pandas Series to preserve the index for\n",
        "              evaluation.\n",
        "            - y_train_full_for_ar (np.ndarray): The full training portion of the\n",
        "              target series (first `training_size` observations), required for\n",
        "              fitting the AR model.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Define Slicing Indices for Train/Test Split\n",
        "    # =========================================================================\n",
        "    # The last predictor used for training is at index `training_size - forecast_horizon - 1`.\n",
        "    predictor_train_end_idx = training_size - forecast_horizon\n",
        "\n",
        "    # The target for the first training predictor (at t=0) is at index `forecast_horizon`.\n",
        "    target_train_start_idx = forecast_horizon\n",
        "\n",
        "    # The target for the last training predictor is at index `training_size - 1`.\n",
        "    target_train_end_idx = training_size\n",
        "\n",
        "    # The first predictor for testing is at index `predictor_train_end_idx`.\n",
        "    predictor_test_start_idx = predictor_train_end_idx\n",
        "\n",
        "    # The last predictor we can use for an h-step ahead forecast is at T-h-1.\n",
        "    predictor_test_end_idx = X_tensor.shape[0] - forecast_horizon\n",
        "\n",
        "    # The first true target value for the test set corresponds to the first test predictor.\n",
        "    target_test_start_idx = target_train_end_idx\n",
        "\n",
        "    # =========================================================================\n",
        "    # Perform Data Slicing\n",
        "    # =========================================================================\n",
        "    # Slice the predictor tensor into training and testing sets.\n",
        "    X_train_tensor = X_tensor[0:predictor_train_end_idx]\n",
        "    X_test_tensor = X_tensor[predictor_test_start_idx:predictor_test_end_idx]\n",
        "\n",
        "    # Slice the target vector into aligned training and testing sets.\n",
        "    y_train_target = y_vector[target_train_start_idx:target_train_end_idx]\n",
        "    y_test_true_raw = y_vector[target_test_start_idx:]\n",
        "\n",
        "    # The AR model needs the full history of y in the training period to fit.\n",
        "    y_train_full_for_ar = y_vector[:training_size]\n",
        "\n",
        "    # Create a pandas Series for the true test values to preserve the time index\n",
        "    # for evaluation alignment. A dummy integer index is used here, assuming\n",
        "    # the final evaluation will use a proper DatetimeIndex.\n",
        "    test_index = pd.RangeIndex(\n",
        "        start=target_test_start_idx,\n",
        "        stop=target_test_start_idx + len(y_test_true_raw),\n",
        "        step=1\n",
        "    )\n",
        "    y_test_true = pd.Series(y_test_true_raw, index=test_index)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Vectorize Predictor Tensors\n",
        "    # =========================================================================\n",
        "    # Get the dimensions for reshaping.\n",
        "    T_train, p, q = X_train_tensor.shape\n",
        "    T_test = X_test_tensor.shape[0]\n",
        "\n",
        "    # Reshape the 3D training tensor into a 2D matrix.\n",
        "    X_train_flat = X_train_tensor.reshape(T_train, p * q)\n",
        "\n",
        "    # Reshape the 3D testing tensor into a 2D matrix.\n",
        "    X_test_flat = X_test_tensor.reshape(T_test, p * q)\n",
        "\n",
        "    # Return all the prepared data structures.\n",
        "    return X_train_flat, y_train_target, X_test_flat, y_test_true, y_train_full_for_ar\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Benchmark Model Implementations\n",
        "# =============================================================================\n",
        "\n",
        "def run_ar_benchmark(\n",
        "    y_train: pd.Series,\n",
        "    n_test: int,\n",
        "    forecast_horizon: int\n",
        ") -> pd.Series:\n",
        "    \"\"\"\n",
        "    Trains an AR(1) model and generates out-of-sample forecasts.\n",
        "\n",
        "    Args:\n",
        "        y_train (pd.Series): The training series for the target variable.\n",
        "        n_test (int): The number of out-of-sample forecasts to generate.\n",
        "        forecast_horizon (int): The forecast horizon, h.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: A Series containing the out-of-sample forecasts.\n",
        "    \"\"\"\n",
        "    # Fit the AR(1) model. `lags=1` specifies the order.\n",
        "    # `old_names=False` is a modern statsmodels convention.\n",
        "    model = AutoReg(y_train, lags=1, trend='c').fit()\n",
        "\n",
        "    # Generate out-of-sample forecasts.\n",
        "    # The forecast starts at the end of the training data.\n",
        "    start_pred = len(y_train)\n",
        "    end_pred = start_pred + n_test - 1\n",
        "\n",
        "    # Note: For h>1, a more complex iterative forecast would be needed.\n",
        "    # For h=1, this direct forecast is appropriate.\n",
        "    forecasts = model.predict(start=start_pred, end=end_pred, dynamic=False)\n",
        "\n",
        "    return forecasts\n",
        "\n",
        "def run_vectorized_ols_benchmark(\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    X_test: np.ndarray\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Trains a high-dimensional vectorized OLS model using the pseudoinverse.\n",
        "\n",
        "    Args:\n",
        "        X_train (np.ndarray): The (T_train, p*q) vectorized training predictors.\n",
        "        y_train (np.ndarray): The (T_train,) training target vector.\n",
        "        X_test (np.ndarray): The (T_test, p*q) vectorized test predictors.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A vector of out-of-sample forecasts.\n",
        "    \"\"\"\n",
        "    # In the high-dimensional case (n_features > n_samples), OLS is underdetermined.\n",
        "    # We use `scipy.linalg.lstsq` which finds the minimum L2-norm solution.\n",
        "    # This is equivalent to using the Moore-Penrose pseudoinverse.\n",
        "    beta, _, _, _ = scipy.linalg.lstsq(X_train, y_train)\n",
        "\n",
        "    # Generate forecasts using the estimated coefficients.\n",
        "    # Equation: y_hat = X_test @ beta\n",
        "    forecasts = X_test @ beta\n",
        "\n",
        "    return forecasts\n",
        "\n",
        "def run_vectorized_lasso_benchmark(\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    X_test: np.ndarray,\n",
        "    cv_folds: int,\n",
        "    random_seed: int\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Trains a Lasso regression model with cross-validation to select lambda.\n",
        "\n",
        "    Args:\n",
        "        X_train (np.ndarray): The (T_train, p*q) vectorized training predictors.\n",
        "        y_train (np.ndarray): The (T_train,) training target vector.\n",
        "        X_test (np.ndarray): The (T_test, p*q) vectorized test predictors.\n",
        "        cv_folds (int): The number of folds for cross-validation.\n",
        "        random_seed (int): Seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A vector of out-of-sample forecasts.\n",
        "    \"\"\"\n",
        "    # It is best practice to scale data before fitting regularized models.\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Use LassoCV to automatically find the best alpha (lambda) via cross-validation.\n",
        "    # `cv=cv_folds` sets the number of folds.\n",
        "    # `random_state` ensures the fold splits are reproducible.\n",
        "    lasso_cv = LassoCV(cv=cv_folds, random_state=random_seed, max_iter=10000)\n",
        "    lasso_cv.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Generate forecasts using the fitted model on the scaled test data.\n",
        "    forecasts = lasso_cv.predict(X_test_scaled)\n",
        "\n",
        "    return forecasts\n",
        "\n",
        "# =============================================================================\n",
        "# Main Orchestrator Function\n",
        "# =============================================================================\n",
        "\n",
        "def run_all_benchmarks(\n",
        "    X_tensor: np.ndarray,\n",
        "    y_vector: np.ndarray,\n",
        "    training_size: int,\n",
        "    forecast_horizon: int,\n",
        "    cv_folds: int,\n",
        "    random_seed: int\n",
        ") -> Dict[str, pd.Series]:\n",
        "    \"\"\"\n",
        "    Orchestrates the training and forecasting for all benchmark models.\n",
        "\n",
        "    This function ensures that all benchmark models are trained and evaluated\n",
        "    on the exact same data splits for a fair and rigorous comparison.\n",
        "\n",
        "    Args:\n",
        "        X_tensor, y_vector: The full prepared datasets.\n",
        "        training_size, forecast_horizon: Parameters for the train-test split.\n",
        "        cv_folds, random_seed: Parameters for the Lasso model.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, pd.Series]: A dictionary where keys are model names and\n",
        "                               values are the corresponding forecast Series.\n",
        "    \"\"\"\n",
        "    # Prepare the data splits for all models.\n",
        "    X_train_flat, y_train, X_test_flat, y_test_true, y_train_full = _prepare_benchmark_data(\n",
        "        X_tensor, y_vector, training_size, forecast_horizon\n",
        "    )\n",
        "\n",
        "    # The index for the forecasts should align with the true test values.\n",
        "    forecast_index = y_test_true.index\n",
        "\n",
        "    # --- Run AR(1) Benchmark ---\n",
        "    ar_forecasts_raw = run_ar_benchmark(\n",
        "        y_train=pd.Series(y_train_full), # AR model needs the original series format\n",
        "        n_test=len(y_test_true),\n",
        "        forecast_horizon=forecast_horizon\n",
        "    )\n",
        "    ar_forecasts = pd.Series(ar_forecasts_raw.values, index=forecast_index)\n",
        "\n",
        "    # --- Run Vectorized OLS Benchmark ---\n",
        "    ols_forecasts_raw = run_vectorized_ols_benchmark(X_train_flat, y_train, X_test_flat)\n",
        "    ols_forecasts = pd.Series(ols_forecasts_raw, index=forecast_index)\n",
        "\n",
        "    # --- Run Vectorized Lasso Benchmark ---\n",
        "    lasso_forecasts_raw = run_vectorized_lasso_benchmark(\n",
        "        X_train_flat, y_train, X_test_flat, cv_folds, random_seed\n",
        "    )\n",
        "    lasso_forecasts = pd.Series(lasso_forecasts_raw, index=forecast_index)\n",
        "\n",
        "    # Compile all forecasts into a single dictionary.\n",
        "    all_forecasts = {\n",
        "        'AR(1)': ar_forecasts,\n",
        "        'Vectorized_OLS': ols_forecasts,\n",
        "        'Vectorized_Lasso': lasso_forecasts,\n",
        "    }\n",
        "\n",
        "    return all_forecasts\n"
      ],
      "metadata": {
        "id": "9P8tTHpOhnVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 16: Data Generating Process Setup\n",
        "\n",
        "# =============================================================================\n",
        "# Factor Tensor Generator\n",
        "# =============================================================================\n",
        "\n",
        "def generate_factor_tensor(\n",
        "    T: int,\n",
        "    k: int,\n",
        "    r: int,\n",
        "    method: str,\n",
        "    rng: np.random.Generator\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generates the (T, k, r) latent factor tensor F_t using specified DGPs.\n",
        "\n",
        "    This function creates the time-series of latent factor matrices which drive\n",
        "    the dynamics of the observed data in the simulation. It supports two\n",
        "    distinct data generating processes as described in the paper.\n",
        "\n",
        "    Args:\n",
        "        T (int): The number of time periods.\n",
        "        k (int): The number of row factors.\n",
        "        r (int): The number of column factors.\n",
        "        method (str): The generation method. Must be one of:\n",
        "                      'matrix_normal': F_t ~ i.i.d. Matrix Normal(0, I, I).\n",
        "                      'mar1': F_t follows a stationary Matrix Autoregressive\n",
        "                              model of order 1.\n",
        "        rng (np.random.Generator): A configured numpy random number generator\n",
        "                                   for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The generated (T, k, r) latent factor tensor.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If an unsupported method is specified.\n",
        "    \"\"\"\n",
        "    # Validate the selected generation method.\n",
        "    if method not in ['matrix_normal', 'mar1']:\n",
        "        raise ValueError(f\"Unknown factor generation method: '{method}'\")\n",
        "\n",
        "    # --- DGP 1: i.i.d. Matrix Normal Factors ---\n",
        "    if method == 'matrix_normal':\n",
        "        # F_t ~ MN(0, I_k, I_r) is equivalent to generating each element of the\n",
        "        # tensor from an independent standard normal distribution.\n",
        "        return rng.standard_normal(size=(T, k, r))\n",
        "\n",
        "    # --- DGP 2: Matrix Autoregressive (MAR(1)) Factors ---\n",
        "    if method == 'mar1':\n",
        "        # The model is F_t = Φ1 * F_{t-1} * Φ2' + E_t.\n",
        "        # For stationarity, the paper specifies diagonal autoregressive matrices\n",
        "        # with coefficients drawn from a Uniform(-1, 1) distribution.\n",
        "\n",
        "        # Generate the diagonal elements for the k x k matrix Φ1.\n",
        "        phi1_diag = rng.uniform(-1, 1, size=k)\n",
        "\n",
        "        # Generate the diagonal elements for the r x r matrix Φ2.\n",
        "        phi2_diag = rng.uniform(-1, 1, size=r)\n",
        "\n",
        "        # Initialize the tensor to store the factor time series.\n",
        "        F_tensor = np.zeros((T, k, r))\n",
        "\n",
        "        # Iteratively generate the MAR(1) process, starting from F_0 = 0.\n",
        "        for t in range(1, T):\n",
        "            # Generate the (k, r) matrix of i.i.d. standard normal innovations for time t.\n",
        "            innovations = rng.standard_normal(size=(k, r))\n",
        "\n",
        "            # Apply the right-multiplication by Φ2' efficiently using broadcasting.\n",
        "            # This is equivalent to F_tensor[t-1] @ np.diag(phi2_diag).\n",
        "            term1 = F_tensor[t - 1] * phi2_diag[np.newaxis, :]\n",
        "\n",
        "            # Apply the left-multiplication by Φ1 and add the innovation.\n",
        "            # This is equivalent to np.diag(phi1_diag) @ term1 + innovations.\n",
        "            F_tensor[t] = phi1_diag[:, np.newaxis] * term1 + innovations\n",
        "\n",
        "        return F_tensor\n",
        "\n",
        "    # This line is unreachable due to the initial validation but included for safety.\n",
        "    return np.array([])\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Loading Matrix Generator\n",
        "# =============================================================================\n",
        "\n",
        "def generate_loading_matrices(\n",
        "    p: int,\n",
        "    q: int,\n",
        "    k: int,\n",
        "    r: int,\n",
        "    rng: np.random.Generator\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Generates the (p, k) row loading matrix R and (q, r) column loading matrix C.\n",
        "\n",
        "    As specified in the simulation setup, the entries of these matrices are\n",
        "    drawn from a simple Uniform(-1, 1) distribution. Note that for the DGP,\n",
        "    these matrices are not required to be orthogonal.\n",
        "\n",
        "    Args:\n",
        "        p (int): The number of rows in the observed data (e.g., countries).\n",
        "        q (int): The number of columns in the observed data (e.g., indicators).\n",
        "        k (int): The number of row factors.\n",
        "        r (int): The number of column factors.\n",
        "        rng (np.random.Generator): A configured numpy random number generator.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray]: A tuple containing (R, C).\n",
        "    \"\"\"\n",
        "    # Generate the (p, k) row loading matrix R with entries from U(-1, 1).\n",
        "    R = rng.uniform(-1, 1, size=(p, k))\n",
        "\n",
        "    # Generate the (q, r) column loading matrix C with entries from U(-1, 1).\n",
        "    C = rng.uniform(-1, 1, size=(q, r))\n",
        "\n",
        "    return R, C\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Target Vector Generator\n",
        "# =============================================================================\n",
        "\n",
        "def generate_target_vectors(\n",
        "    k: int,\n",
        "    r: int,\n",
        "    rng: np.random.Generator\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Generates the (k,) alpha and (r,) beta target loading vectors.\n",
        "\n",
        "    These vectors link the latent factors to the scalar target variable.\n",
        "    The generation follows the paper's specification: sampling from a standard\n",
        "    normal distribution, with an L2 normalization constraint on alpha for\n",
        "    model identification.\n",
        "\n",
        "    Args:\n",
        "        k (int): The number of row factors.\n",
        "        r (int): The number of column factors.\n",
        "        rng (np.random.Generator): A configured numpy random number generator.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray]: A tuple containing (alpha, beta).\n",
        "    \"\"\"\n",
        "    # Sample the initial alpha vector from an i.i.d. standard normal distribution.\n",
        "    alpha_raw = rng.standard_normal(size=k)\n",
        "\n",
        "    # Enforce the identification constraint ||alpha||_2 = 1 by normalizing.\n",
        "    # A safeguard is added for the astronomically unlikely event of a zero vector.\n",
        "    norm_alpha = np.linalg.norm(alpha_raw)\n",
        "    alpha = alpha_raw / (norm_alpha if norm_alpha > 1e-12 else 1.0)\n",
        "\n",
        "    # Sample the beta vector from an i.i.d. standard normal distribution.\n",
        "    beta = rng.standard_normal(size=r)\n",
        "\n",
        "    return alpha, beta\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Noise Tensor Generator\n",
        "# =============================================================================\n",
        "\n",
        "def generate_noise_tensor(\n",
        "    T: int,\n",
        "    p: int,\n",
        "    q: int,\n",
        "    method: str,\n",
        "    rng: np.random.Generator\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generates the (T, p, q) idiosyncratic noise tensor E_t using specified DGPs.\n",
        "\n",
        "    This function creates the noise component of the observed data. It supports\n",
        "    three distinct DGPs from the paper, allowing for simulations with\n",
        "    uncorrelated, time-correlated, or spatially-correlated noise structures.\n",
        "\n",
        "    Args:\n",
        "        T (int): The number of time periods.\n",
        "        p (int): The number of rows in the observed data.\n",
        "        q (int): The number of columns in the observed data.\n",
        "        method (str): The generation method. Must be one of:\n",
        "                      'uncorrelated', 'time_correlated_mar1', 'spatial_correlated'.\n",
        "        rng (np.random.Generator): A configured numpy random number generator.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The generated (T, p, q) noise tensor.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If an unsupported method is specified.\n",
        "    \"\"\"\n",
        "    # Validate the selected generation method.\n",
        "    if method not in ['uncorrelated', 'time_correlated_mar1', 'spatial_correlated']:\n",
        "        raise ValueError(f\"Unknown noise generation method: '{method}'\")\n",
        "\n",
        "    # --- DGP 1: Uncorrelated Noise ---\n",
        "    if method == 'uncorrelated':\n",
        "        # E_t ~ MN(0, I_p, I_q), equivalent to i.i.d. N(0,1) entries.\n",
        "        return rng.standard_normal(size=(T, p, q))\n",
        "\n",
        "    # --- DGP 2: Time-Correlated MAR(1) Noise ---\n",
        "    if method == 'time_correlated_mar1':\n",
        "        # The model is E_t = Ψ1 * E_{t-1} * Ψ2' + U_t.\n",
        "        # This follows the same logic as the MAR(1) factor generation.\n",
        "        psi1_diag = rng.uniform(-1, 1, size=p)\n",
        "        psi2_diag = rng.uniform(-1, 1, size=q)\n",
        "        E_tensor = np.zeros((T, p, q))\n",
        "        for t in range(1, T):\n",
        "            innovations = rng.standard_normal(size=(p, q))\n",
        "            term1 = E_tensor[t - 1] * psi2_diag[np.newaxis, :]\n",
        "            E_tensor[t] = psi1_diag[:, np.newaxis] * term1 + innovations\n",
        "        return E_tensor\n",
        "\n",
        "    # --- DGP 3: Spatially-Correlated Noise ---\n",
        "    if method == 'spatial_correlated':\n",
        "        # The model is E_t ~ MN(0, Σ_R, Σ_C).\n",
        "\n",
        "        # Construct the row covariance matrix Σ_R with 1s on the diagonal\n",
        "        # and 1/p on the off-diagonals.\n",
        "        sigma_R = np.full((p, p), 1.0 / p)\n",
        "        np.fill_diagonal(sigma_R, 1.0)\n",
        "\n",
        "        # Construct the column covariance matrix Σ_C with 1s on the diagonal\n",
        "        # and 1/q on the off-diagonals.\n",
        "        sigma_C = np.full((q, q), 1.0 / q)\n",
        "        np.fill_diagonal(sigma_C, 1.0)\n",
        "\n",
        "        # To sample from this distribution, we use the Cholesky decomposition.\n",
        "        # If E_t = L_R * Z_t * L_C', where Z_t has i.i.d. N(0,1) entries, then\n",
        "        # E_t will have the desired covariance structure.\n",
        "        L_R = scipy.linalg.cholesky(sigma_R, lower=True)\n",
        "        L_C = scipy.linalg.cholesky(sigma_C, lower=True)\n",
        "\n",
        "        # Generate the tensor of i.i.d. standard normal innovations.\n",
        "        Z = rng.standard_normal(size=(T, p, q))\n",
        "\n",
        "        # Apply the Cholesky factors using a vectorized einsum operation.\n",
        "        # 'ip,tpj,qj->tiq' performs L_R @ Z_t @ L_C.T for each t.\n",
        "        E_tensor = np.einsum('ip,tpj,qj->tiq', L_R, Z, L_C)\n",
        "\n",
        "        return E_tensor\n",
        "\n",
        "    # This line is unreachable due to the initial validation.\n",
        "    return np.array([])\n",
        "\n",
        "# =============================================================================\n",
        "# Main Orchestrator Function\n",
        "# =============================================================================\n",
        "\n",
        "def generate_synthetic_data(\n",
        "    p: int, q: int, T: int, k: int, r: int,\n",
        "    factor_method: str, noise_method: str,\n",
        "    forecast_horizon: int, random_seed: int\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Generates a complete synthetic dataset based on the factor model structure.\n",
        "\n",
        "    This function orchestrates the entire data generating process (DGP) by\n",
        "    calling specialized helpers to create each component of the model, and then\n",
        "    assembling them into the final predictor tensor (X_tensor) and target\n",
        "    vector (y_vector).\n",
        "\n",
        "    Args:\n",
        "        p, q, T, k, r (int): Model dimensions.\n",
        "        factor_method (str): Method for generating factors ('matrix_normal', 'mar1').\n",
        "        noise_method (str): Method for generating noise ('uncorrelated',\n",
        "                            'time_correlated_mar1', 'spatial_correlated').\n",
        "        forecast_horizon (int): The forecast horizon, h.\n",
        "        random_seed (int): Seed for the random number generator for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing the full synthetic dataset and\n",
        "                        its ground-truth components.\n",
        "    \"\"\"\n",
        "    # Initialize a reproducible random number generator.\n",
        "    rng = np.random.default_rng(random_seed)\n",
        "\n",
        "    # --- Step 16.1: Generate Latent Factors ---\n",
        "    F_tensor = generate_factor_tensor(T, k, r, factor_method, rng)\n",
        "\n",
        "    # --- Step 16.2: Generate Loadings and Target Vectors ---\n",
        "    R, C = generate_loading_matrices(p, q, k, r, rng)\n",
        "    alpha, beta = generate_target_vectors(k, r, rng)\n",
        "\n",
        "    # --- Step 16.3: Generate Noise ---\n",
        "    E_tensor = generate_noise_tensor(T, p, q, noise_method, rng)\n",
        "    e_scalar_noise = rng.standard_normal(size=T)\n",
        "\n",
        "    # --- Assemble the final dataset ---\n",
        "    # Equation: X_t = R @ F_t @ C' + E_t\n",
        "    # 'pk,tkr,qr->tpq': vectorized computation for all t\n",
        "    signal = np.einsum('pk,tkr,qr->tpq', R, F_tensor, C)\n",
        "    X_tensor = signal + E_tensor\n",
        "\n",
        "    # Equation: y_{t+h} = α' @ F_t @ β + e_{t+h}\n",
        "    # We generate y_t from F_{t-h}\n",
        "    y_signal = np.einsum('k,tkr,r->t', alpha, F_tensor, beta)\n",
        "    # Align noise by shifting: y_t uses noise e_t\n",
        "    y_vector = np.roll(y_signal, shift=-forecast_horizon) + e_scalar_noise\n",
        "    # Set the first h values of y to NaN as they depend on future F\n",
        "    y_vector[-forecast_horizon:] = np.nan\n",
        "\n",
        "    return {\n",
        "        'X_tensor': X_tensor,\n",
        "        'y_vector': y_vector,\n",
        "        'ground_truth': {\n",
        "            'F_tensor': F_tensor, 'R': R, 'C': C, 'E_tensor': E_tensor,\n",
        "            'alpha': alpha, 'beta': beta, 'e_scalar_noise': e_scalar_noise\n",
        "        }\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0OTRyT8wig1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 17: Monte Carlo Loop Implementation\n",
        "\n",
        "# =============================================================================\n",
        "# Error Metric Computation (Helper)\n",
        "# =============================================================================\n",
        "\n",
        "def _compute_simulation_error_metrics(\n",
        "    true_params: Dict[str, np.ndarray],\n",
        "    est_params: Dict[str, np.ndarray],\n",
        "    p: int,\n",
        "    q: int,\n",
        "    T: int\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Computes estimation errors, accounting for rotational ambiguity.\n",
        "\n",
        "    This function calculates the error between true and estimated parameters\n",
        "    after finding the optimal rotation matrices H_R and H_C that best align\n",
        "    the estimated factor space with the true one. This is essential because\n",
        "    the factor model is only identified up to an invertible linear\n",
        "    transformation (rotation).\n",
        "\n",
        "    Args:\n",
        "        true_params (Dict[str, np.ndarray]):\n",
        "            A dictionary containing the ground-truth components of the DGP,\n",
        "            including R, C, F_tensor, alpha, and beta.\n",
        "        est_params (Dict[str, np.ndarray]):\n",
        "            A dictionary containing the estimated components from the pipeline,\n",
        "            including R_hat, C_hat, F_hat_tensor, alpha_hat, and beta_hat.\n",
        "        p (int): The number of rows in the original data matrix.\n",
        "        q (int): The number of columns in the original data matrix.\n",
        "        T (int): The number of time periods in the aligned data.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, float]:\n",
        "            A dictionary containing the computed scalar error metrics:\n",
        "            'factor_matrix_error' and 'loading_vector_error'.\n",
        "    \"\"\"\n",
        "    # Unpack the ground-truth parameters from the input dictionary.\n",
        "    R, C, F, alpha, beta = (true_params['R'], true_params['C'],\n",
        "                            true_params['F_tensor'], true_params['alpha'],\n",
        "                            true_params['beta'])\n",
        "\n",
        "    # Unpack the estimated parameters from the input dictionary.\n",
        "    R_hat, C_hat, F_hat, alpha_hat, beta_hat = (est_params['R_hat'], est_params['C_hat'],\n",
        "                                                est_params['F_hat_tensor'], est_params['alpha_hat'],\n",
        "                                                est_params['beta_hat'])\n",
        "\n",
        "    # --- Define Rotation Matrices H_R and H_C via Procrustes Analysis ---\n",
        "    # To compare estimated and true spaces, we find the orthogonal matrices\n",
        "    # H_R and H_C that minimize the distance between R and R_hat @ H_R, etc.\n",
        "    # This is solved via the SVD of the cross-product matrix.\n",
        "    # Let M = R.T @ R_hat. The optimal rotation is H_R = U @ V.T where SVD(M) = U S V.T.\n",
        "    U_r, _, Vt_r = np.linalg.svd(R.T @ R_hat, full_matrices=False)\n",
        "    H_R = U_r @ Vt_r\n",
        "\n",
        "    # Perform the same procedure for the column loading space.\n",
        "    U_c, _, Vt_c = np.linalg.svd(C.T @ C_hat, full_matrices=False)\n",
        "    H_C = U_c @ Vt_c\n",
        "\n",
        "    # --- Compute Factor Matrix Error ---\n",
        "    # We compare the estimated factors F_hat to the true factors F after\n",
        "    # applying the inverse rotations to align them in the same space.\n",
        "    # The metric is the average Frobenius norm of the difference per time step.\n",
        "    F_rotated = np.einsum('kr,trl,lc->tkc', H_R.T, F, H_C)\n",
        "    factor_error_per_t = [np.linalg.norm(F_hat[t] - F_rotated[t], 'fro') for t in range(T)]\n",
        "    factor_matrix_error = np.mean(factor_error_per_t)\n",
        "\n",
        "    # --- Compute Loading Vector Error ---\n",
        "    # Equation: log(||β_hat ⊗ α_hat - (H_C'β) ⊗ (H_R'α)||_F^2)\n",
        "    # This metric compares the Kronecker product of the estimated vectors\n",
        "    # to the Kronecker product of the rotated true vectors.\n",
        "\n",
        "    # Rotate the true alpha and beta vectors into the estimated space.\n",
        "    true_vec_rotated = np.kron(H_C.T @ beta, H_R.T @ alpha)\n",
        "\n",
        "    # Compute the Kronecker product of the estimated vectors.\n",
        "    est_vec = np.kron(beta_hat, alpha_hat)\n",
        "\n",
        "    # Calculate the squared Frobenius norm of the difference.\n",
        "    loading_vector_error_raw = np.linalg.norm(est_vec - true_vec_rotated)**2\n",
        "\n",
        "    # Take the natural logarithm as specified for the final error metric.\n",
        "    loading_vector_error = np.log(loading_vector_error_raw)\n",
        "\n",
        "    # Return the computed scalar error metrics.\n",
        "    return {\n",
        "        'factor_matrix_error': factor_matrix_error,\n",
        "        'loading_vector_error': loading_vector_error\n",
        "    }\n",
        "\n",
        "# =============================================================================\n",
        "# Single Replication Worker (Helper)\n",
        "# =============================================================================\n",
        "\n",
        "def _run_single_replication(\n",
        "    config: Dict[str, Any],\n",
        "    replication_seed: int\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Executes a single, complete Monte Carlo replication for a given configuration.\n",
        "\n",
        "    This function acts as a self-contained worker for the parallel simulation.\n",
        "    It generates a synthetic dataset, runs the entire estimation pipeline,\n",
        "    computes the relevant error metrics against the ground truth, and returns\n",
        "    a structured record of the results, now including the estimated parameters.\n",
        "\n",
        "    Args:\n",
        "        config (Dict[str, Any]):\n",
        "            A dictionary specifying the parameters for this simulation run.\n",
        "        replication_seed (int):\n",
        "            The random seed for this specific replication, ensuring that each\n",
        "            run is statistically independent yet reproducible.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]:\n",
        "            A flat dictionary containing the original configuration, computed\n",
        "            error metrics, a status flag, and the estimated parameter vectors.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Unpack the dimensions from the configuration dictionary.\n",
        "        p, q, T, k, r = config['p'], config['q'], config['T'], config['k'], config['r']\n",
        "\n",
        "        # Step 1: Generate a complete synthetic dataset using the specified DGP.\n",
        "        data = generate_synthetic_data(\n",
        "            p, q, T, k, r,\n",
        "            factor_method=config['factor_method'],\n",
        "            noise_method=config['noise_method'],\n",
        "            forecast_horizon=1,\n",
        "            random_seed=replication_seed\n",
        "        )\n",
        "        X_tensor, y_vector = data['X_tensor'], data['y_vector']\n",
        "\n",
        "        # Align the data by removing any leading NaNs from y_vector.\n",
        "        valid_idx = ~np.isnan(y_vector)\n",
        "        X_tensor, y_vector = X_tensor[valid_idx], y_vector[valid_idx]\n",
        "\n",
        "        # Step 2: Run the full α-PCA estimation pipeline on the generated data.\n",
        "        apca_results = run_apca_pipeline(X_tensor, alpha=config['alpha'])\n",
        "\n",
        "        # Step 3: Estimate the forecasting parameters using Iterative Least Squares.\n",
        "        lse_setup = setup_lse_training_data(\n",
        "            apca_results['F_hat_tensor'], y_vector,\n",
        "            training_size=len(y_vector),\n",
        "            forecast_horizon=1,\n",
        "            random_seed=replication_seed\n",
        "        )\n",
        "        lse_results = estimate_lse_parameters(\n",
        "            lse_setup['F_train'], lse_setup['y_train_target'],\n",
        "            lse_setup['alpha_init'], lse_setup['beta_init'],\n",
        "            max_iterations=200, convergence_tolerance=1e-8\n",
        "        )\n",
        "\n",
        "        # Step 4: Compute the error metrics by comparing estimates to the ground truth.\n",
        "        true_params = data['ground_truth']\n",
        "        est_params = {**apca_results, **lse_results}\n",
        "\n",
        "        errors = _compute_simulation_error_metrics(\n",
        "            true_params, est_params, p, q, len(y_vector)\n",
        "        )\n",
        "\n",
        "        # We store the full vectors to be flexible for any downstream analysis.\n",
        "        estimated_params_output = {\n",
        "            'alpha_hat': est_params['alpha_hat'],\n",
        "            'beta_hat': est_params['beta_hat']\n",
        "        }\n",
        "\n",
        "        # Combine all results into a single flat dictionary for easy aggregation.\n",
        "        final_results = {\n",
        "            **config,\n",
        "            **errors,\n",
        "            'estimated_params': estimated_params_output,\n",
        "            'status': 'success'\n",
        "        }\n",
        "        return final_results\n",
        "\n",
        "    except Exception as e:\n",
        "        # If any step fails, return a failure record with consistent keys.\n",
        "        return {\n",
        "            **config,\n",
        "            'factor_matrix_error': np.nan,\n",
        "            'loading_vector_error': np.nan,\n",
        "            'estimated_params': None,\n",
        "            'status': f'error: {e}'\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# Main Simulation Orchestrator\n",
        "# =============================================================================\n",
        "\n",
        "def run_monte_carlo_simulation(\n",
        "    study_manifest: Dict[str, Any],\n",
        "    n_jobs: int = -1\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Orchestrates the full Monte Carlo simulation study specified in the manifest.\n",
        "\n",
        "    This function builds a grid of all experimental configurations, manages the\n",
        "    parallel execution of all replications for each configuration, and\n",
        "    aggregates the results into a single, analysis-ready pandas DataFrame.\n",
        "    This amended version now collects not just error metrics but also the\n",
        "    estimated parameters from each run.\n",
        "\n",
        "    Args:\n",
        "        study_manifest (Dict[str, Any]):\n",
        "            The master dictionary defining all parameters for the simulation study.\n",
        "        n_jobs (int):\n",
        "            The number of CPU cores to use for parallel execution. -1 means\n",
        "            using all available cores. Defaults to -1.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame:\n",
        "            A DataFrame where each row corresponds to a single replication run.\n",
        "            It contains columns for the configuration parameters, the resulting\n",
        "            error metrics, and the estimated parameter vectors.\n",
        "    \"\"\"\n",
        "    # Extract the simulation-specific parameters from the main manifest.\n",
        "    sim_params = study_manifest['simulation_study']['parameters']\n",
        "\n",
        "    # --- Build the grid of all unique experimental configurations ---\n",
        "    param_grid = []\n",
        "    # This example focuses on the setup for Table 2 from the paper.\n",
        "    for p_q_tuple in sim_params['observation_dimensions_grid_pq']['value']:\n",
        "        p, q = p_q_tuple\n",
        "        for T in sim_params['time_horizon_config']['for_table_2']['values']:\n",
        "            dgp_methods = product(['matrix_normal', 'mar1'],\n",
        "                                  ['uncorrelated', 'time_correlated_mar1', 'spatial_correlated'])\n",
        "            for factor_method, noise_method in dgp_methods:\n",
        "                config = {\n",
        "                    'p': p, 'q': q, 'T': T,\n",
        "                    'k': sim_params['latent_factor_dimensions_kr']['value'][0],\n",
        "                    'r': sim_params['latent_factor_dimensions_kr']['value'][1],\n",
        "                    'factor_method': factor_method,\n",
        "                    'noise_method': noise_method,\n",
        "                    'alpha': sim_params['alpha_pca_parameter_alpha']['value']\n",
        "                }\n",
        "                param_grid.append(config)\n",
        "\n",
        "    # --- Create the full list of tasks to be executed ---\n",
        "    n_reps = sim_params['monte_carlo_replications']['value']\n",
        "    tasks = [\n",
        "        (config, rep_idx) for config in param_grid for rep_idx in range(n_reps)\n",
        "    ]\n",
        "\n",
        "    # --- Run all replications in parallel using joblib ---\n",
        "    print(f\"Starting Monte Carlo simulation with {len(tasks)} total replications...\")\n",
        "    results_list = Parallel(n_jobs=n_jobs)(\n",
        "        delayed(_run_single_replication)(config, seed)\n",
        "        for config, seed in tqdm(tasks, desc=\"MC Replications\")\n",
        "    )\n",
        "\n",
        "    # --- Aggregate the list of result dictionaries into a DataFrame ---\n",
        "    # Pandas will now correctly handle the 'estimated_params' column,\n",
        "    # where each entry is a dictionary.\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "\n",
        "    # --- Unpack parameter estimates for easier access ---\n",
        "    # This post-processing step creates new columns for individual parameter\n",
        "    # estimates, which is what the diagnostic plotting function needs.\n",
        "    if 'estimated_params' in results_df.columns:\n",
        "        # Unpack the first element of alpha_hat\n",
        "        results_df['alpha_hat_0'] = results_df['estimated_params'].apply(\n",
        "            lambda x: x['alpha_hat'][0] if isinstance(x, dict) and 'alpha_hat' in x and len(x['alpha_hat']) > 0 else np.nan\n",
        "        )\n",
        "        # Unpack the first element of beta_hat\n",
        "        results_df['beta_hat_0'] = results_df['estimated_params'].apply(\n",
        "            lambda x: x['beta_hat'][0] if isinstance(x, dict) and 'beta_hat' in x and len(x['beta_hat']) > 0 else np.nan\n",
        "        )\n",
        "\n",
        "    print(\"Monte Carlo simulation complete.\")\n",
        "    return results_df\n",
        "\n"
      ],
      "metadata": {
        "id": "jMzHB-FNlg0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 18: Main Orchestrator Function Creation\n",
        "\n",
        "# =============================================================================\n",
        "# Helper Function for a Single Model Run\n",
        "# =============================================================================\n",
        "\n",
        "def _train_and_predict_single_model(\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    X_test: np.ndarray,\n",
        "    test_index: pd.DatetimeIndex,\n",
        "    alpha: float,\n",
        "    k: int,\n",
        "    r: int,\n",
        "    h: int,\n",
        "    lse_config: Dict[str, Any],\n",
        "    random_seed: int\n",
        ") -> pd.Series:\n",
        "    \"\"\"\n",
        "    Trains a single α-PCA-LSE model configuration and returns its forecasts.\n",
        "\n",
        "    This helper function encapsulates the core modeling pipeline for a single\n",
        "    set of hyperparameters (alpha, k, r). It runs the α-PCA pipeline on the\n",
        "    training data to get factor loadings, estimates the LSE forecasting\n",
        "    parameters, and then generates out-of-sample forecasts on the test data.\n",
        "\n",
        "    Args:\n",
        "        X_train (np.ndarray): The (T_train, p, q) training predictor tensor.\n",
        "        y_train (np.ndarray): The (T_train,) training target vector.\n",
        "        X_test (np.ndarray): The (T_test, p, q) testing predictor tensor.\n",
        "        test_index (pd.DatetimeIndex): The DatetimeIndex for the test period.\n",
        "        alpha (float): The α-PCA hyperparameter.\n",
        "        k (int): The fixed number of row factors.\n",
        "        r (int): The fixed number of column factors.\n",
        "        h (int): The forecast horizon.\n",
        "        lse_config (Dict[str, Any]): Configuration for the LSE algorithm\n",
        "                                     (max_iterations, tolerance).\n",
        "        random_seed (int): Seed for reproducible LSE initialization.\n",
        "\n",
        "    Returns:\n",
        "        pd.Series: A pandas Series of out-of-sample forecasts, indexed by the\n",
        "                   forecast target date.\n",
        "    \"\"\"\n",
        "    # Execute the α-PCA pipeline on the training data with fixed dimensions (k, r)\n",
        "    # to obtain the estimated loading matrices R_hat and C_hat.\n",
        "    apca_results = run_apca_pipeline(X_train, alpha, fixed_kr=(k, r))\n",
        "    R_hat, C_hat = apca_results['R_hat'], apca_results['C_hat']\n",
        "    F_train_factors = apca_results['F_hat_tensor']\n",
        "\n",
        "    # Prepare the aligned training data and initial parameters for LSE estimation.\n",
        "    lse_setup = setup_lse_training_data(\n",
        "        F_train_factors, y_train, len(y_train), h, random_seed\n",
        "    )\n",
        "\n",
        "    # Estimate the forecasting parameters alpha_hat and beta_hat using the LSE algorithm.\n",
        "    lse_results = estimate_lse_parameters(\n",
        "        lse_setup['F_train'], lse_setup['y_train_target'],\n",
        "        lse_setup['alpha_init'], lse_setup['beta_init'],\n",
        "        lse_config['max_iterations'], lse_config['convergence_tolerance']\n",
        "    )\n",
        "    alpha_hat, beta_hat = lse_results['alpha_hat'], lse_results['beta_hat']\n",
        "\n",
        "    # Generate the final out-of-sample forecasts using the test data and trained parameters.\n",
        "    forecasts = generate_out_of_sample_forecasts(\n",
        "        X_test, test_index, R_hat, C_hat, alpha_hat, beta_hat, h\n",
        "    )\n",
        "\n",
        "    # Return the forecast series.\n",
        "    return forecasts\n",
        "\n",
        "# =============================================================================\n",
        "# Grid Search Helper Function\n",
        "# =============================================================================\n",
        "\n",
        "def _run_grid_search(\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    X_test: np.ndarray,\n",
        "    y_test: np.ndarray,\n",
        "    test_index: pd.DatetimeIndex,\n",
        "    param_grid: List[Tuple[float, Tuple[int, int]]],\n",
        "    h: int,\n",
        "    lse_config: Dict[str, Any],\n",
        "    random_seed: int\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Executes the α-PCA-LSE model evaluation over a grid of hyperparameters.\n",
        "\n",
        "    This function iterates through each specified combination of (alpha, k, r),\n",
        "    trains the model, generates forecasts, evaluates the performance (MSFE),\n",
        "    and collects the results.\n",
        "\n",
        "    Args:\n",
        "        X_train, y_train (np.ndarray): The training data tensors.\n",
        "        X_test, y_test (np.ndarray): The testing data tensors.\n",
        "        test_index (pd.DatetimeIndex): The DatetimeIndex for the test period.\n",
        "        param_grid (List[Tuple[float, Tuple[int, int]]]): A list of all\n",
        "            (alpha, (k, r)) configurations to test.\n",
        "        h (int): The forecast horizon.\n",
        "        lse_config (Dict[str, Any]): Configuration for the LSE algorithm.\n",
        "        random_seed (int): Seed for reproducible LSE initialization.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame summarizing the MSFE for each hyperparameter\n",
        "                      configuration, indexed by (alpha, k, r).\n",
        "    \"\"\"\n",
        "    # Initialize a list to store the results from each run in the grid.\n",
        "    results_list = []\n",
        "\n",
        "    # Iterate through each hyperparameter configuration with a progress bar.\n",
        "    for alpha, (k, r) in tqdm(param_grid, desc=\"Grid Search\"):\n",
        "        try:\n",
        "            # Train the model and generate forecasts for the current configuration.\n",
        "            forecasts = _train_and_predict_single_model(\n",
        "                X_train, y_train, X_test, test_index,\n",
        "                alpha, k, r, h, lse_config, random_seed\n",
        "            )\n",
        "\n",
        "            # Prepare the true target series for evaluation, aligning its index with the forecasts.\n",
        "            y_test_true = pd.Series(y_test, index=test_index.shift(h))\n",
        "\n",
        "            # Compute performance metrics for the forecasts.\n",
        "            perf = compute_performance_metrics(y_test_true, forecasts)\n",
        "\n",
        "            # Append the configuration and its resulting MSFE to the results list.\n",
        "            results_list.append({'alpha': alpha, 'k': k, 'r': r, 'MSFE': perf['metrics']['MSFE']})\n",
        "\n",
        "        except Exception as e:\n",
        "            # If a run fails for any reason, record it as NaN to avoid crashing the entire study.\n",
        "            results_list.append({'alpha': alpha, 'k': k, 'r': r, 'MSFE': np.nan, 'error': str(e)})\n",
        "\n",
        "    # Convert the list of results into a multi-indexed DataFrame for easy analysis.\n",
        "    return pd.DataFrame(results_list).set_index(['alpha', 'k', 'r'])\n",
        "\n",
        "# =============================================================================\n",
        "# Main Orchestrator Function (Definitive Version)\n",
        "# =============================================================================\n",
        "\n",
        "def run_empirical_study_orchestrator(\n",
        "    country_data: Dict[str, pd.DataFrame],\n",
        "    y_series: pd.Series,\n",
        "    study_manifest: Dict[str, Any]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Orchestrates the complete, methodologically sound empirical study.\n",
        "\n",
        "    This master function serves as the main entry point for replicating the\n",
        "    paper's empirical analysis. It executes the entire pipeline in a strict,\n",
        "    leak-free sequence:\n",
        "    1.  Validates all inputs.\n",
        "    2.  Prepares stationary, centralized data with a correct train-test split.\n",
        "    3.  Runs a grid search to evaluate the main α-PCA-LSE model.\n",
        "    4.  Performs the supervised screening procedure and re-evaluates the model.\n",
        "    5.  Trains and evaluates all benchmark models on identical data splits.\n",
        "    6.  Conducts statistical significance tests between the best model and benchmarks.\n",
        "    7.  Aggregates all results into a final, structured output.\n",
        "\n",
        "    Args:\n",
        "        country_data (Dict[str, pd.DataFrame]): Raw country predictor data.\n",
        "        y_series (pd.Series): Raw target variable series.\n",
        "        study_manifest (Dict[str, Any]): The master configuration dictionary.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing all results of the study.\n",
        "    \"\"\"\n",
        "    # --- Step 1: Input Validation ---\n",
        "    print(\"Step 1: Validating inputs...\")\n",
        "    # Call the validator to ensure data and manifest integrity.\n",
        "    is_valid, report = validate_input_data(country_data, y_series, study_manifest)\n",
        "    # Abort if validation fails, providing a detailed report.\n",
        "    if not is_valid:\n",
        "        raise ValueError(f\"Input validation failed: {report}\")\n",
        "    print(\"Validation successful.\")\n",
        "\n",
        "    # Extract the empirical study parameters for convenience.\n",
        "    emp_params = study_manifest['empirical_study']['parameters']\n",
        "\n",
        "    # --- Step 2: Leak-Free Data Preparation and Splitting ---\n",
        "    print(\"\\nStep 2: Preparing leak-free forecasting data...\")\n",
        "    # Call the corrected data preparation function which handles transformations,\n",
        "    # centralization, and splitting without data leakage.\n",
        "    prep_results = prepare_forecasting_data(\n",
        "        country_data, y_series, study_manifest,\n",
        "        training_size=emp_params['train_test_split_config']['training_size']\n",
        "    )\n",
        "    # Unpack the prepared data tensors and metadata.\n",
        "    X_train_unscreened, y_train = prep_results['X_train'], prep_results['y_train']\n",
        "    X_test_unscreened, y_test = prep_results['X_test'], prep_results['y_test']\n",
        "    final_index, split_idx = prep_results['final_index'], prep_results['split_idx']\n",
        "    test_index = final_index[split_idx:]\n",
        "    print(\"Data preparation complete.\")\n",
        "\n",
        "    # --- Step 3: Unscreened Model Evaluation ---\n",
        "    print(\"\\nStep 3: Evaluating α-PCA-LSE model on unscreened data...\")\n",
        "    # Create the grid of hyperparameters (alpha, k, r) to be tested.\n",
        "    param_grid = list(product(emp_params['alpha_grid']['value'], emp_params['factor_dimensions_grid']['value']))\n",
        "    # Run the grid search on the unscreened data.\n",
        "    unscreened_results_df = _run_grid_search(\n",
        "        X_train_unscreened, y_train, X_test_unscreened, y_test, test_index,\n",
        "        param_grid, emp_params['forecast_horizon_h']['value'],\n",
        "        emp_params['iterative_lse_config'], random_seed=42\n",
        "    )\n",
        "    print(\"Unscreened model evaluation complete.\")\n",
        "\n",
        "    # --- Step 4: Supervised Screening Workflow ---\n",
        "    print(\"\\nStep 4: Performing supervised screening analysis...\")\n",
        "    # Get the original dimension names for indexing.\n",
        "    country_names = sorted(study_manifest['empirical_study']['data_inputs']['predictor_matrices_X_all']['row_index_countries'])\n",
        "    indicator_names = sorted(study_manifest['empirical_study']['data_inputs']['predictor_matrices_X_all']['column_index_indicators'])\n",
        "\n",
        "    # a. Compute correlation scores using ONLY the training data to prevent leakage.\n",
        "    corr_scores = compute_supervised_correlation_scores(\n",
        "        X_train_unscreened, y_train, country_names, indicator_names\n",
        "    )\n",
        "\n",
        "    # b. Filter both train and test sets using the rules derived from training data.\n",
        "    screen_params = study_manifest['screening_validation']['empirical_parameters']\n",
        "    # Concatenate train and test to apply filtering, then split back.\n",
        "    full_unscreened_tensor = np.concatenate([X_train_unscreened, X_test_unscreened], axis=0)\n",
        "    screening_results = perform_supervised_screening(\n",
        "        full_unscreened_tensor, country_names, indicator_names,\n",
        "        corr_scores['row_avg_correlations'], corr_scores['col_avg_correlations'],\n",
        "        screen_params['screening_thresholds']['row_threshold'],\n",
        "        screen_params['screening_thresholds']['column_threshold']\n",
        "    )\n",
        "    X_screened_full = screening_results['X_tilde_tensor']\n",
        "    X_train_screened = X_screened_full[:X_train_unscreened.shape[0]]\n",
        "    X_test_screened = X_screened_full[X_train_unscreened.shape[0]:]\n",
        "\n",
        "    # c. Run the grid search again on the newly created screened data.\n",
        "    print(\"Evaluating α-PCA-LSE model on screened data...\")\n",
        "    screened_results_df = _run_grid_search(\n",
        "        X_train_screened, y_train, X_test_screened, y_test, test_index,\n",
        "        param_grid, emp_params['forecast_horizon_h']['value'],\n",
        "        emp_params['iterative_lse_config'], random_seed=42\n",
        "    )\n",
        "    print(\"Screened model evaluation complete.\")\n",
        "\n",
        "    # --- Step 5: Benchmark Evaluation ---\n",
        "    print(\"\\nStep 5: Evaluating benchmark models...\")\n",
        "    # Run all benchmark models on the same, leak-free data splits.\n",
        "    benchmark_forecasts = run_all_benchmarks(\n",
        "        np.concatenate([X_train_unscreened, X_test_unscreened], axis=0),\n",
        "        np.concatenate([y_train, y_test]),\n",
        "        training_size=len(y_train),\n",
        "        forecast_horizon=emp_params['forecast_horizon_h']['value'],\n",
        "        cv_folds=emp_params['cross_validation_folds']['value'],\n",
        "        random_seed=42\n",
        "    )\n",
        "\n",
        "    # Compute performance metrics for each benchmark.\n",
        "    benchmark_results = {}\n",
        "    y_test_true = pd.Series(y_test, index=test_index.shift(emp_params['forecast_horizon_h']['value']))\n",
        "    for name, preds in benchmark_forecasts.items():\n",
        "        aligned_preds = preds.reindex(y_test_true.index)\n",
        "        perf = compute_performance_metrics(y_test_true, aligned_preds)\n",
        "        benchmark_results[name] = perf['metrics']\n",
        "    print(\"Benchmark evaluation complete.\")\n",
        "\n",
        "    # --- Step 6: Final Analysis and Significance Testing ---\n",
        "    print(\"\\nStep 6: Performing final analysis and significance tests...\")\n",
        "    # Find the best performing configuration from the unscreened results.\n",
        "    best_unscreened_config = unscreened_results_df['MSFE'].idxmin()\n",
        "    # Find the best performing configuration from the screened results.\n",
        "    best_screened_config = screened_results_df['MSFE'].idxmin()\n",
        "\n",
        "    # Determine the overall best model by comparing the best of both categories.\n",
        "    if unscreened_results_df.loc[best_unscreened_config, 'MSFE'] <= screened_results_df.loc[best_screened_config, 'MSFE']:\n",
        "        best_model_type = 'Unscreened'\n",
        "        best_alpha, best_k, best_r = best_unscreened_config\n",
        "        print(f\"Best model is Unscreened with config: alpha={best_alpha}, k={best_k}, r={best_r}\")\n",
        "        # Rerun the single best model to get its forecast series for comparison.\n",
        "        best_model_forecasts = _train_and_predict_single_model(\n",
        "            X_train_unscreened, y_train, X_test_unscreened, test_index,\n",
        "            best_alpha, best_k, best_r, emp_params['forecast_horizon_h']['value'],\n",
        "            emp_params['iterative_lse_config'], random_seed=42\n",
        "        )\n",
        "    else:\n",
        "        best_model_type = 'Screened'\n",
        "        best_alpha, best_k, best_r = best_screened_config\n",
        "        print(f\"Best model is Screened with config: alpha={best_alpha}, k={best_k}, r={best_r}\")\n",
        "        # Rerun the single best model to get its forecast series for comparison.\n",
        "        best_model_forecasts = _train_and_predict_single_model(\n",
        "            X_train_screened, y_train, X_test_screened, test_index,\n",
        "            best_alpha, best_k, best_r, emp_params['forecast_horizon_h']['value'],\n",
        "            emp_params['iterative_lse_config'], random_seed=42\n",
        "        )\n",
        "\n",
        "    # Perform Diebold-Mariano tests comparing the best model to all benchmarks.\n",
        "    significance_tests = {}\n",
        "    for name, benchmark_preds in benchmark_forecasts.items():\n",
        "        aligned_preds = benchmark_preds.reindex(y_test_true.index)\n",
        "        dm_test = perform_diebold_mariano_test(\n",
        "            y_test_true, best_model_forecasts, aligned_preds,\n",
        "            forecast_horizon=emp_params['forecast_horizon_h']['value']\n",
        "        )\n",
        "        significance_tests[f'Best_vs_{name}'] = dm_test\n",
        "    print(\"Significance testing complete.\")\n",
        "\n",
        "    # --- Final Output Compilation ---\n",
        "    # Aggregate all results into a single, comprehensive dictionary.\n",
        "    final_output = {\n",
        "        \"unscreened_results\": unscreened_results_df,\n",
        "        \"screened_results\": screened_results_df,\n",
        "        \"benchmark_results\": pd.DataFrame(benchmark_results),\n",
        "        \"best_model_info\": {\"type\": best_model_type, \"config\": (best_alpha, best_k, best_r)},\n",
        "        \"significance_tests\": pd.DataFrame(significance_tests).T,\n",
        "        \"data_preparation_log\": prep_results['prep_log']\n",
        "    }\n",
        "\n",
        "    print(\"\\nEmpirical study orchestration complete.\")\n",
        "    return final_output\n"
      ],
      "metadata": {
        "id": "dQEGChg7oLJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 19: Robustness Analysis Implementation\n",
        "\n",
        "def run_parameter_sensitivity_analysis(\n",
        "    country_data: Dict[str, pd.DataFrame],\n",
        "    y_series: pd.Series,\n",
        "    base_study_manifest: Dict[str, Any]\n",
        ") -> Dict[str, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Performs a systematic sensitivity analysis on key model hyperparameters.\n",
        "\n",
        "    This function repeatedly runs the entire empirical study orchestrator while\n",
        "    systematically varying one key hyperparameter at a time, mapping out the\n",
        "    model's performance landscape. It analyzes sensitivity to:\n",
        "    1. The α-PCA parameter `alpha`.\n",
        "    2. The fixed factor dimensions `(k, r)`.\n",
        "    3. The supervised screening thresholds.\n",
        "\n",
        "    Args:\n",
        "        country_data (Dict[str, pd.DataFrame]): Raw country predictor data.\n",
        "        y_series (pd.Series): Raw target variable series.\n",
        "        base_study_manifest (Dict[str, Any]): The baseline master configuration\n",
        "            dictionary. This will be modified for each sensitivity run.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, pd.DataFrame]: A dictionary containing DataFrames of results\n",
        "            for each sensitivity analysis performed.\n",
        "    \"\"\"\n",
        "    # Initialize a dictionary to store the results of each analysis.\n",
        "    sensitivity_results = {}\n",
        "\n",
        "    # =========================================================================\n",
        "    # 1. Sensitivity to α-PCA Parameter `alpha`\n",
        "    # =========================================================================\n",
        "    print(\"--- Starting Sensitivity Analysis for alpha ---\")\n",
        "    # Define the extended grid for alpha as specified.\n",
        "    alpha_sensitivity_grid = np.arange(-2.0, 3.1, 0.1)\n",
        "    alpha_results = []\n",
        "\n",
        "    # Iterate over the alpha grid with a progress bar.\n",
        "    for alpha in tqdm(alpha_sensitivity_grid, desc=\"Alpha Sensitivity\"):\n",
        "        # Create a deep copy of the manifest to avoid side-effects.\n",
        "        run_manifest = copy.deepcopy(base_study_manifest)\n",
        "        # Override the alpha_grid for this specific run.\n",
        "        run_manifest['empirical_study']['parameters']['alpha_grid']['value'] = [alpha]\n",
        "\n",
        "        try:\n",
        "            # Run the full study with this single alpha value.\n",
        "            study_results = run_empirical_study_orchestrator(\n",
        "                country_data, y_series, run_manifest\n",
        "            )\n",
        "            # Find the best MSFE achieved with this alpha across all (k,r) combos.\n",
        "            best_unscreened_msfe = study_results['unscreened_results']['MSFE'].min()\n",
        "            best_screened_msfe = study_results['screened_results']['MSFE'].min()\n",
        "            # Store the results for this alpha value.\n",
        "            alpha_results.append({\n",
        "                'alpha': alpha,\n",
        "                'best_unscreened_msfe': best_unscreened_msfe,\n",
        "                'best_screened_msfe': best_screened_msfe\n",
        "            })\n",
        "        except Exception as e:\n",
        "            # If a run fails, log it and continue.\n",
        "            alpha_results.append({'alpha': alpha, 'best_unscreened_msfe': np.nan, 'best_screened_msfe': np.nan})\n",
        "\n",
        "    # Store the aggregated results for the alpha analysis.\n",
        "    sensitivity_results['alpha_sensitivity'] = pd.DataFrame(alpha_results).set_index('alpha')\n",
        "    print(\"--- Alpha sensitivity analysis complete ---\\n\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # 2. Sensitivity to Factor Dimensions (k, r)\n",
        "    # =========================================================================\n",
        "    print(\"--- Starting Sensitivity Analysis for Factor Dimensions (k, r) ---\")\n",
        "    # Define the extended grid for (k, r).\n",
        "    k_range = range(1, 9)  # k <= 8\n",
        "    r_range = range(1, 7)  # r <= 6\n",
        "    kr_sensitivity_grid = list(product(k_range, r_range))\n",
        "    kr_results = []\n",
        "\n",
        "    # Iterate over the (k, r) grid.\n",
        "    for k, r in tqdm(kr_sensitivity_grid, desc=\"k, r Sensitivity\"):\n",
        "        run_manifest = copy.deepcopy(base_study_manifest)\n",
        "        # Override the factor dimensions grid for this run.\n",
        "        run_manifest['empirical_study']['parameters']['factor_dimensions_grid']['value'] = [(k, r)]\n",
        "\n",
        "        try:\n",
        "            study_results = run_empirical_study_orchestrator(\n",
        "                country_data, y_series, run_manifest\n",
        "            )\n",
        "            # Find the best MSFE achieved with this (k,r) across all alphas.\n",
        "            best_unscreened_msfe = study_results['unscreened_results']['MSFE'].min()\n",
        "            best_screened_msfe = study_results['screened_results']['MSFE'].min()\n",
        "            kr_results.append({\n",
        "                'k': k, 'r': r,\n",
        "                'best_unscreened_msfe': best_unscreened_msfe,\n",
        "                'best_screened_msfe': best_screened_msfe\n",
        "            })\n",
        "        except Exception as e:\n",
        "            kr_results.append({'k': k, 'r': r, 'best_unscreened_msfe': np.nan, 'best_screened_msfe': np.nan})\n",
        "\n",
        "    # Store the aggregated results for the k, r analysis.\n",
        "    sensitivity_results['kr_sensitivity'] = pd.DataFrame(kr_results).set_index(['k', 'r'])\n",
        "    print(\"--- Factor dimension sensitivity analysis complete ---\\n\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # 3. Sensitivity to Screening Thresholds\n",
        "    # =========================================================================\n",
        "    print(\"--- Starting Sensitivity Analysis for Screening Thresholds ---\")\n",
        "    # Define the extended grid for the screening threshold.\n",
        "    threshold_sensitivity_grid = np.arange(0.01, 0.31, 0.01)\n",
        "    threshold_results = []\n",
        "\n",
        "    # Iterate over the threshold grid.\n",
        "    for threshold in tqdm(threshold_sensitivity_grid, desc=\"Threshold Sensitivity\"):\n",
        "        run_manifest = copy.deepcopy(base_study_manifest)\n",
        "        # Override both row and column thresholds for this run.\n",
        "        run_manifest['screening_validation']['empirical_parameters']['screening_thresholds'] = {\n",
        "            'row_threshold': threshold,\n",
        "            'column_threshold': threshold\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            study_results = run_empirical_study_orchestrator(\n",
        "                country_data, y_series, run_manifest\n",
        "            )\n",
        "            # For this analysis, we only care about the screened result.\n",
        "            best_screened_msfe = study_results['screened_results']['MSFE'].min()\n",
        "            threshold_results.append({\n",
        "                'threshold': threshold,\n",
        "                'best_screened_msfe': best_screened_msfe\n",
        "            })\n",
        "        except Exception as e:\n",
        "            # A common error here is that a high threshold removes all data.\n",
        "            threshold_results.append({'threshold': threshold, 'best_screened_msfe': np.nan})\n",
        "\n",
        "    # Store the aggregated results for the threshold analysis.\n",
        "    sensitivity_results['threshold_sensitivity'] = pd.DataFrame(threshold_results).set_index('threshold')\n",
        "    print(\"--- Screening threshold sensitivity analysis complete ---\\n\")\n",
        "\n",
        "    return sensitivity_results\n",
        "\n",
        "\n",
        "def run_forward_chaining_cv(\n",
        "    country_data: Dict[str, pd.DataFrame],\n",
        "    y_series: pd.Series,\n",
        "    study_manifest: Dict[str, Any],\n",
        "    model_config: Dict[str, Any],\n",
        "    n_splits: int\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Evaluates a single model configuration using forward-chaining cross-validation.\n",
        "\n",
        "    This function provides a robust estimate of a model's out-of-sample\n",
        "    performance by simulating a real-world forecasting scenario. It uses an\n",
        "    expanding window approach: the model is repeatedly trained on a growing\n",
        "    set of historical data and tested on the next unseen data point.\n",
        "\n",
        "    Args:\n",
        "        country_data (Dict[str, pd.DataFrame]): Raw country predictor data.\n",
        "        y_series (pd.Series): Raw target variable series.\n",
        "        study_manifest (Dict[str, Any]): The master configuration dictionary.\n",
        "        model_config (Dict[str, Any]): A dictionary specifying the single model\n",
        "            configuration to evaluate, e.g., {'alpha': -0.5, 'k': 6, 'r': 5}.\n",
        "        n_splits (int): The number of splits (folds) for the cross-validation.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary containing the CV results:\n",
        "            - 'oos_forecasts' (pd.Series): A series of all out-of-sample\n",
        "              forecasts generated across all folds.\n",
        "            - 'oos_true_values' (pd.Series): The corresponding true values.\n",
        "            - 'cv_msfe' (float): The overall Mean Squared Forecast Error\n",
        "              calculated from the out-of-sample predictions.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Initialization\n",
        "    # =========================================================================\n",
        "    # Extract key parameters from the configuration.\n",
        "    alpha = model_config['alpha']\n",
        "    k, r = model_config['k'], model_config['r']\n",
        "    h = study_manifest['empirical_study']['parameters']['forecast_horizon_h']['value']\n",
        "    lse_config = study_manifest['empirical_study']['parameters']['iterative_lse_config']\n",
        "\n",
        "    # Use scikit-learn's TimeSeriesSplit to generate the indices for each fold.\n",
        "    # This object correctly creates expanding training sets.\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "    # Lists to store the out-of-sample results from each fold.\n",
        "    all_oos_forecasts = []\n",
        "    all_oos_true_values = []\n",
        "    all_oos_indices = []\n",
        "\n",
        "    print(f\"Starting forward-chaining CV for config: {model_config}...\")\n",
        "    # =========================================================================\n",
        "    # Cross-Validation Loop\n",
        "    # =========================================================================\n",
        "    # Iterate through each split generated by TimeSeriesSplit.\n",
        "    for fold, (train_indices, test_indices) in tqdm(\n",
        "        enumerate(tscv.split(y_series)), total=n_splits, desc=\"CV Folds\"\n",
        "    ):\n",
        "        # The test set for each fold in forecasting is typically just one step.\n",
        "        # We take the first index of the test set as our forecast point.\n",
        "        if len(test_indices) == 0: continue\n",
        "\n",
        "        # Define the training size for this specific fold.\n",
        "        # `train_indices[-1] + 1` gives the length of the current training set.\n",
        "        current_training_size = train_indices[-1] + 1\n",
        "\n",
        "        try:\n",
        "            # --- Step 1: Leak-Free Data Prep FOR THIS FOLD ---\n",
        "            # This is the most critical step. All data preparation is done\n",
        "            # inside the loop, using only the current fold's training data\n",
        "            # to learn transformation parameters.\n",
        "            prep_results = prepare_forecasting_data(\n",
        "                country_data, y_series, study_manifest,\n",
        "                training_size=current_training_size\n",
        "            )\n",
        "            # We only need the training data for this fold to fit the model.\n",
        "            X_train, y_train = prep_results['X_train'], prep_results['y_train']\n",
        "\n",
        "            # The test set is the single next observation. We need to find its\n",
        "            # corresponding position in the *aligned* data.\n",
        "            original_test_start_idx = test_indices[0]\n",
        "            final_index = prep_results['final_index']\n",
        "\n",
        "            # Find where the original test index falls in the new aligned index.\n",
        "            try:\n",
        "                aligned_test_idx_pos = final_index.get_loc(y_series.index[original_test_start_idx])\n",
        "            except KeyError:\n",
        "                # This can happen if the test point was dropped during alignment.\n",
        "                continue\n",
        "\n",
        "            # The test predictor is the single time slice at this position.\n",
        "            X_test_single = prep_results['X_train'][aligned_test_idx_pos:aligned_test_idx_pos+1]\n",
        "\n",
        "            # The true value is the corresponding y value.\n",
        "            y_test_single_true = prep_results['y_train'][aligned_test_idx_pos]\n",
        "\n",
        "            if X_test_single.shape[0] == 0: continue\n",
        "\n",
        "            # --- Step 2: Train Model and Predict ---\n",
        "            # Use the single-model helper to train on this fold's training\n",
        "            # data and predict on the single test point.\n",
        "            forecast = _train_and_predict_single_model(\n",
        "                X_train, y_train, X_test_single,\n",
        "                pd.DatetimeIndex([final_index[aligned_test_idx_pos]]),\n",
        "                alpha, k, r, h, lse_config, random_seed=fold\n",
        "            )\n",
        "\n",
        "            # Store the single forecast value, the true value, and the target index.\n",
        "            all_oos_forecasts.append(forecast.iloc[0])\n",
        "            all_oos_true_values.append(y_test_single_true)\n",
        "            all_oos_indices.append(forecast.index[0])\n",
        "\n",
        "        except Exception as e:\n",
        "            # If a fold fails, log it and continue.\n",
        "            print(f\"Warning: Fold {fold} failed with error: {e}\")\n",
        "            continue\n",
        "\n",
        "    # =========================================================================\n",
        "    # Aggregate and Evaluate Results\n",
        "    # =========================================================================\n",
        "    if not all_oos_forecasts:\n",
        "        raise RuntimeError(\"Cross-validation failed to produce any forecasts.\")\n",
        "\n",
        "    # Create pandas Series from the collected out-of-sample results.\n",
        "    oos_forecasts_series = pd.Series(all_oos_forecasts, index=all_oos_indices)\n",
        "    oos_true_values_series = pd.Series(all_oos_true_values, index=all_oos_indices)\n",
        "\n",
        "    # Compute the overall MSFE on the collected out-of-sample predictions.\n",
        "    final_metrics = compute_performance_metrics(oos_true_values_series, oos_forecasts_series)\n",
        "\n",
        "    return {\n",
        "        'oos_forecasts': oos_forecasts_series,\n",
        "        'oos_true_values': oos_true_values_series,\n",
        "        'cv_msfe': final_metrics['metrics']['MSFE']\n",
        "    }\n",
        "\n",
        "def run_stability_assessment(\n",
        "    country_data: Dict[str, pd.DataFrame],\n",
        "    y_series: pd.Series,\n",
        "    base_study_manifest: Dict[str, Any],\n",
        "    subsample_fractions: List[float],\n",
        "    n_runs_per_fraction: int = 5\n",
        ") -> Dict[float, List[Dict[str, Any]]]:\n",
        "    \"\"\"\n",
        "    Assesses model stability by running the empirical study on data subsamples.\n",
        "\n",
        "    This function investigates the robustness of the study's conclusions by\n",
        "    repeatedly running the entire `run_empirical_study_orchestrator` on\n",
        "    different contiguous subsamples of the original time series data. High\n",
        "    variance in the key results (e.g., best model MSFE, selected parameters)\n",
        "    across different subsamples would indicate that the model is not stable.\n",
        "\n",
        "    Args:\n",
        "        country_data (Dict[str, pd.DataFrame]): Raw country predictor data.\n",
        "        y_series (pd.Series): Raw target variable series.\n",
        "        base_study_manifest (Dict[str, Any]): The baseline master configuration\n",
        "            dictionary.\n",
        "        subsample_fractions (List[float]): A list of fractions (e.g., [0.75, 0.85, 0.95])\n",
        "            to define the size of the data subsamples.\n",
        "        n_runs_per_fraction (int): The number of random contiguous blocks to\n",
        "            draw for each fraction to get a better sense of variability.\n",
        "\n",
        "    Returns:\n",
        "        Dict[float, List[Dict[str, Any]]]:\n",
        "            A dictionary where keys are the subsample fractions and values are\n",
        "            lists of the full result dictionaries from each run of the\n",
        "            orchestrator on a subsample of that size.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Initialization\n",
        "    # =========================================================================\n",
        "    # Initialize a dictionary to store the results for each fraction.\n",
        "    stability_results = {fraction: [] for fraction in subsample_fractions}\n",
        "    # Get the total number of observations in the original dataset.\n",
        "    total_obs = len(y_series)\n",
        "    # Initialize a random number generator for selecting subsamples.\n",
        "    rng = np.random.default_rng(seed=123)\n",
        "\n",
        "    print(\"--- Starting Stability Assessment via Subsampling ---\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Subsampling Loop\n",
        "    # =========================================================================\n",
        "    # Iterate over each specified subsample fraction.\n",
        "    for fraction in subsample_fractions:\n",
        "        print(f\"\\n--- Analyzing subsample fraction: {fraction*100:.0f}% ---\")\n",
        "        # Calculate the length of the contiguous block for this fraction.\n",
        "        subsample_len = math.floor(fraction * total_obs)\n",
        "\n",
        "        # Check if the subsample is long enough to perform a meaningful train/test split.\n",
        "        min_train_size = base_study_manifest['empirical_study']['parameters']['train_test_split_config']['training_size']\n",
        "        if subsample_len < min_train_size + 10: # Ensure at least 10 test points\n",
        "            print(f\"Skipping fraction {fraction} as subsample length ({subsample_len}) is too short.\")\n",
        "            continue\n",
        "\n",
        "        # Perform multiple runs for each fraction to average out randomness.\n",
        "        for run_num in range(n_runs_per_fraction):\n",
        "            print(f\"  --- Running subsample run {run_num + 1}/{n_runs_per_fraction} ---\")\n",
        "\n",
        "            # --- Step 1: Create the Subsample ---\n",
        "            # Randomly select a starting point for the contiguous block.\n",
        "            max_start_idx = total_obs - subsample_len\n",
        "            start_idx = rng.integers(0, max_start_idx + 1)\n",
        "            end_idx = start_idx + subsample_len\n",
        "\n",
        "            # Slice the raw data to create the subsample for this run.\n",
        "            y_subsample = y_series.iloc[start_idx:end_idx]\n",
        "            country_data_subsample = {\n",
        "                country: df.iloc[start_idx:end_idx] for country, df in country_data.items()\n",
        "            }\n",
        "\n",
        "            # --- Step 2: Modify the Manifest for the Subsample ---\n",
        "            # Create a deep copy of the manifest to avoid side-effects.\n",
        "            run_manifest = copy.deepcopy(base_study_manifest)\n",
        "\n",
        "            # Adjust the train/test split to be proportional to the new, shorter dataset.\n",
        "            # Here we use a fixed 80/20 split for simplicity, but other rules could be applied.\n",
        "            new_training_size = math.floor(0.8 * subsample_len)\n",
        "            run_manifest['empirical_study']['parameters']['train_test_split_config']['training_size'] = new_training_size\n",
        "\n",
        "            try:\n",
        "                # --- Step 3: Run the Full Orchestrator on the Subsample ---\n",
        "                # This is the core of the assessment. We run the entire, rigorous\n",
        "                # study on this smaller slice of the original data.\n",
        "                study_results = run_empirical_study_orchestrator(\n",
        "                    country_data_subsample,\n",
        "                    y_subsample,\n",
        "                    run_manifest\n",
        "                )\n",
        "\n",
        "                # Append the full, detailed results dictionary to the list for this fraction.\n",
        "                stability_results[fraction].append(study_results)\n",
        "\n",
        "                # Print a summary of the run's outcome.\n",
        "                best_msfe = study_results['unscreened_results']['MSFE'].min()\n",
        "                print(f\"  Run {run_num + 1} complete. Best unscreened MSFE: {best_msfe:.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                # If a full run fails on a subsample, log it and continue.\n",
        "                print(f\"  Run {run_num + 1} failed with error: {e}\")\n",
        "                stability_results[fraction].append({'error': str(e)})\n",
        "\n",
        "    print(\"\\n--- Stability Assessment complete ---\")\n",
        "    return stability_results\n",
        "\n",
        "def run_full_robustness_analysis(\n",
        "    country_data: Dict[str, pd.DataFrame],\n",
        "    y_series: pd.Series,\n",
        "    study_manifest: Dict[str, Any],\n",
        "    do_sensitivity_analysis: bool = True,\n",
        "    do_cross_validation: bool = True,\n",
        "    do_stability_assessment: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Orchestrates a comprehensive suite of robustness analyses for the model.\n",
        "\n",
        "    This master function serves as the main entry point for stress-testing the\n",
        "    empirical findings. It systematically executes three distinct types of\n",
        "    robustness checks by calling their dedicated orchestrators:\n",
        "    1.  Parameter Sensitivity: Evaluates model performance across extended\n",
        "        hyperparameter grids.\n",
        "    2.  Cross-Validation: Assesses the out-of-sample performance of the best\n",
        "        model configuration using a rigorous forward-chaining CV framework.\n",
        "    3.  Stability Assessment: Investigates the model's sensitivity to the\n",
        "        specific data sample used for training.\n",
        "\n",
        "    Args:\n",
        "        country_data (Dict[str, pd.DataFrame]): Raw country predictor data.\n",
        "        y_series (pd.Series): Raw target variable series.\n",
        "        study_manifest (Dict[str, Any]): The master configuration dictionary.\n",
        "        do_sensitivity_analysis (bool): Flag to enable/disable parameter\n",
        "                                        sensitivity analysis.\n",
        "        do_cross_validation (bool): Flag to enable/disable cross-validation.\n",
        "        do_stability_assessment (bool): Flag to enable/disable stability assessment.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A nested dictionary containing the detailed results\n",
        "                        from each of the executed robustness analyses.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Initialization\n",
        "    # =========================================================================\n",
        "    # Initialize a dictionary to store all robustness results.\n",
        "    full_robustness_results = {}\n",
        "    print(\"=== Starting Full Robustness Analysis Workflow ===\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 19.1: Parameter Sensitivity Analysis\n",
        "    # =========================================================================\n",
        "    if do_sensitivity_analysis:\n",
        "        # This block executes the systematic variation of alpha, (k, r), and\n",
        "        # screening thresholds by repeatedly calling the main study orchestrator.\n",
        "        print(\"\\n[ROBUSTNESS CHECK 1/3] Launching Parameter Sensitivity Analysis...\")\n",
        "\n",
        "        # Call the dedicated function for sensitivity analysis.\n",
        "        sensitivity_results = run_parameter_sensitivity_analysis(\n",
        "            country_data, y_series, study_manifest\n",
        "        )\n",
        "\n",
        "        # Store the results in the main output dictionary.\n",
        "        full_robustness_results['parameter_sensitivity'] = sensitivity_results\n",
        "        print(\"[ROBUSTNESS CHECK 1/3] Parameter Sensitivity Analysis complete.\")\n",
        "    else:\n",
        "        print(\"\\n[ROBUSTNESS CHECK 1/3] Skipping Parameter Sensitivity Analysis.\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 19.2: Cross-Validation Framework\n",
        "    # =========================================================================\n",
        "    if do_cross_validation:\n",
        "        print(\"\\n[ROBUSTNESS CHECK 2/3] Launching Forward-Chaining Cross-Validation...\")\n",
        "\n",
        "        # To perform CV, we first need to identify the \"best\" model configuration\n",
        "        # from a standard run. We use the manifest's default grid for this.\n",
        "        print(\"  - Identifying best model configuration from baseline study...\")\n",
        "        baseline_results = run_empirical_study_orchestrator(\n",
        "            country_data, y_series, study_manifest\n",
        "        )\n",
        "        best_config_info = baseline_results['best_model_info']\n",
        "        best_config_dict = {\n",
        "            'alpha': best_config_info['config'][0],\n",
        "            'k': best_config_info['config'][1],\n",
        "            'r': best_config_info['config'][2]\n",
        "        }\n",
        "        print(f\"  - Best configuration identified: {best_config_dict}\")\n",
        "\n",
        "        # Now, run the forward-chaining CV for this single best configuration.\n",
        "        # The number of splits is taken from the manifest.\n",
        "        n_splits = study_manifest['empirical_study']['parameters']['cross_validation_folds']['value']\n",
        "        cv_results = run_forward_chaining_cv(\n",
        "            country_data, y_series, study_manifest,\n",
        "            model_config=best_config_dict,\n",
        "            n_splits=n_splits\n",
        "        )\n",
        "\n",
        "        # Store the detailed CV results.\n",
        "        full_robustness_results['cross_validation'] = cv_results\n",
        "        print(f\"[ROBUSTNESS CHECK 2/3] Cross-Validation complete. CV MSFE: {cv_results['cv_msfe']:.4f}\")\n",
        "    else:\n",
        "        print(\"\\n[ROBUSTNESS CHECK 2/3] Skipping Cross-Validation.\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 19.3: Stability Assessment\n",
        "    # =========================================================================\n",
        "    if do_stability_assessment:\n",
        "        print(\"\\n[ROBUSTNESS CHECK 3/3] Launching Stability Assessment via Subsampling...\")\n",
        "\n",
        "        # Define the subsample fractions to test.\n",
        "        # These could also be moved into the study_manifest for more control.\n",
        "        subsample_fractions = [0.75, 0.85, 0.95]\n",
        "\n",
        "        # Call the dedicated function for stability assessment.\n",
        "        stability_results = run_stability_assessment(\n",
        "            country_data, y_series, study_manifest,\n",
        "            subsample_fractions=subsample_fractions,\n",
        "            n_runs_per_fraction=5 # Run 5 random blocks per fraction\n",
        "        )\n",
        "\n",
        "        # Store the detailed stability results.\n",
        "        full_robustness_results['stability_assessment'] = stability_results\n",
        "        print(\"[ROBUSTNESS CHECK 3/3] Stability Assessment complete.\")\n",
        "    else:\n",
        "        print(\"\\n[ROBUSTNESS CHECK 3/3] Skipping Stability Assessment.\")\n",
        "\n",
        "    print(\"\\n=== Full Robustness Analysis Workflow Finished ===\")\n",
        "    return full_robustness_results\n"
      ],
      "metadata": {
        "id": "oD6mycuj6j3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 20: Results Compilation and Output Generation\n",
        "\n",
        "def format_table_4(\n",
        "    unscreened_results_df: pd.DataFrame,\n",
        "    benchmark_results_df: pd.DataFrame\n",
        ") -> Any:\n",
        "    \"\"\"\n",
        "    Formats the empirical study results into a publication-quality table (Table 4).\n",
        "\n",
        "    This function takes the raw results from the unscreened empirical analysis\n",
        "    and the benchmark model evaluation and transforms them into a styled\n",
        "    pandas DataFrame that precisely replicates the structure and formatting of\n",
        "    Table 4 from the paper.\n",
        "\n",
        "    Args:\n",
        "        unscreened_results_df (pd.DataFrame):\n",
        "            A DataFrame with a multi-index of (alpha, k, r) and a column 'MSFE'\n",
        "            containing the performance of the main model.\n",
        "        benchmark_results_df (pd.DataFrame):\n",
        "            A DataFrame with benchmark model names as the index and a column\n",
        "            'MSFE' with their performance.\n",
        "\n",
        "    Returns:\n",
        "        pandas.io.formats.style.Styler:\n",
        "            A styled DataFrame object. This can be rendered in a Jupyter\n",
        "            notebook, or exported to HTML or LaTeX using .to_html() or .to_latex().\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    if not isinstance(unscreened_results_df, pd.DataFrame) or \\\n",
        "       not isinstance(benchmark_results_df, pd.DataFrame):\n",
        "        raise TypeError(\"Inputs must be pandas DataFrames.\")\n",
        "    if 'MSFE' not in unscreened_results_df.columns or \\\n",
        "       'MSFE' not in benchmark_results_df.columns:\n",
        "        raise ValueError(\"Input DataFrames must contain an 'MSFE' column.\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Panel A: α-PCA-LSE Results\n",
        "    # =========================================================================\n",
        "    # --- Reshape the Data ---\n",
        "    # We need to pivot the results DataFrame so that 'alpha' values are the index,\n",
        "    # and '(k, r)' tuples are the columns.\n",
        "    # The `unstack` method is perfect for this multi-level transformation.\n",
        "    panel_a_df = unscreened_results_df['MSFE'].unstack(level=['k', 'r'])\n",
        "\n",
        "    # Ensure the columns are in the same order as the paper's table.\n",
        "    # This requires knowing the column order from the manifest.\n",
        "    # For this example, we assume the manifest provides the order.\n",
        "    # If not, we sort them.\n",
        "    panel_a_df = panel_a_df.reindex(\n",
        "        sorted(panel_a_df.columns, key=lambda x: (x[0], x[1]), reverse=True), axis=1\n",
        "    )\n",
        "\n",
        "    # --- Apply Styling ---\n",
        "    # Use the pandas Styler object for professional formatting.\n",
        "    # Set the caption for the table.\n",
        "    styler_a = panel_a_df.style.set_caption(\"<b>Panel A: α-PCA-LSE</b>\")\n",
        "\n",
        "    # Format all MSFE values to three decimal places.\n",
        "    styler_a.format(\"{:.3f}\")\n",
        "\n",
        "    # Define a function to highlight the minimum value in the table.\n",
        "    def highlight_min(s):\n",
        "        # Check if the series is numeric before finding the min.\n",
        "        is_min = s == s.min()\n",
        "        return ['font-weight: bold' if v else '' for v in is_min]\n",
        "\n",
        "    # Apply the highlighting function to the entire DataFrame.\n",
        "    # `axis=None` applies it to the whole table.\n",
        "    styler_a.apply(highlight_min, axis=None)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Panel B: Benchmarks\n",
        "    # =========================================================================\n",
        "    # --- Reshape and Style ---\n",
        "    # The benchmark data is already in a simple format. We just need to style it.\n",
        "    # Transpose the DataFrame for a horizontal layout as in the paper.\n",
        "    panel_b_df = benchmark_results_df.T\n",
        "\n",
        "    # Apply styling.\n",
        "    styler_b = panel_b_df.style.set_caption(\"<b>Panel B: Benchmarks</b>\")\n",
        "\n",
        "    # Format all values to three decimal places.\n",
        "    styler_b.format(\"{:.3f}\")\n",
        "\n",
        "    # In a real environment, you would display these styler objects.\n",
        "    # For a function, we can return them in a dictionary.\n",
        "    # In a Jupyter Notebook, simply having `styler_a` or `styler_b` as the\n",
        "    # last line of a cell would render the styled table.\n",
        "\n",
        "    print(\"--- Table 4: MSFE with original observations ---\")\n",
        "    # For console output, we can print the styled HTML.\n",
        "    # In a real application, you would save or display this.\n",
        "    # display(styler_a) # Use this in a Jupyter Notebook\n",
        "    # display(styler_b) # Use this in a Jupyter Notebook\n",
        "\n",
        "    return {\n",
        "        \"Panel A\": styler_a,\n",
        "        \"Panel B\": styler_b\n",
        "    }\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Reusable Helper for Creating Styled Panels\n",
        "# =============================================================================\n",
        "\n",
        "def _create_results_panel(\n",
        "    results_df: pd.DataFrame,\n",
        "    panel_title: str\n",
        ") -> Any:\n",
        "    \"\"\"\n",
        "    Internal helper to create a styled results panel for α-PCA-LSE models.\n",
        "    \"\"\"\n",
        "    # --- Reshape the Data ---\n",
        "    # Pivot the DataFrame to have 'alpha' as index and '(k, r)' as columns.\n",
        "    panel_df = results_df['MSFE'].unstack(level=['k', 'r'])\n",
        "\n",
        "    # Sort columns to match the paper's typical descending order.\n",
        "    panel_df = panel_df.reindex(\n",
        "        sorted(panel_df.columns, key=lambda x: (x[0], x[1]), reverse=True), axis=1\n",
        "    )\n",
        "\n",
        "    # --- Apply Styling ---\n",
        "    # Create the Styler object with a caption.\n",
        "    styler = panel_df.style.set_caption(f\"<b>{panel_title}</b>\")\n",
        "\n",
        "    # Format all numeric values to three decimal places.\n",
        "    styler.format(\"{:.3f}\", na_rep=\"-\")\n",
        "\n",
        "    # Define a function to find and highlight the minimum value in the table.\n",
        "    def highlight_min(s: pd.Series) -> List[str]:\n",
        "        # Find the minimum value, ignoring NaNs.\n",
        "        min_val = s.min()\n",
        "        # Return a style string for the minimum value, otherwise an empty string.\n",
        "        return ['font-weight: bold' if v == min_val else '' for v in s]\n",
        "\n",
        "    # Apply the highlighting function across the entire DataFrame (axis=None).\n",
        "    styler.apply(highlight_min, axis=None)\n",
        "\n",
        "    return styler\n",
        "\n",
        "# =============================================================================\n",
        "# Main Function for Table 5\n",
        "# =============================================================================\n",
        "\n",
        "def format_table_5(\n",
        "    screened_results_df: pd.DataFrame,\n",
        "    benchmark_results_screened_df: pd.DataFrame\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Formats the screened empirical results into a publication-quality table (Table 5).\n",
        "\n",
        "    This function takes the results from the empirical analysis performed on\n",
        "    the supervised-screened data and formats them to precisely replicate the\n",
        "    structure of Table 5 from the paper. It uses a shared helper function\n",
        "    for consistent styling with Table 4.\n",
        "\n",
        "    Args:\n",
        "        screened_results_df (pd.DataFrame):\n",
        "            A DataFrame with a multi-index of (alpha, k, r) and a column 'MSFE'\n",
        "            containing the performance of the main model on screened data.\n",
        "        benchmark_results_screened_df (pd.DataFrame):\n",
        "            A DataFrame with benchmark model names as the index and a column\n",
        "            'MSFE' from their evaluation on screened data.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]:\n",
        "            A dictionary containing the styled Styler objects for Panel A and Panel B.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    if not isinstance(screened_results_df, pd.DataFrame) or \\\n",
        "       not isinstance(benchmark_results_screened_df, pd.DataFrame):\n",
        "        raise TypeError(\"Inputs must be pandas DataFrames.\")\n",
        "    if 'MSFE' not in screened_results_df.columns or \\\n",
        "       'MSFE' not in benchmark_results_screened_df.columns:\n",
        "        raise ValueError(\"Input DataFrames must contain an 'MSFE' column.\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Panel A: α-PCA-LSE on Screened Data\n",
        "    # =========================================================================\n",
        "    # Use the reusable helper to create the styled Panel A.\n",
        "    styler_a = _create_results_panel(\n",
        "        screened_results_df,\n",
        "        \"Panel A: α-PCA-LSE with Supervised Screening\"\n",
        "    )\n",
        "\n",
        "    # =========================================================================\n",
        "    # Panel B: Benchmarks on Screened Data\n",
        "    # =========================================================================\n",
        "    # Transpose the benchmark results for the correct layout.\n",
        "    panel_b_df = benchmark_results_screened_df.T\n",
        "\n",
        "    # Create the Styler object for Panel B.\n",
        "    styler_b = panel_b_df.style.set_caption(\"<b>Panel B: Benchmarks with Supervised Screening</b>\")\n",
        "\n",
        "    # Format the numeric values to three decimal places.\n",
        "    styler_b.format(\"{:.3f}\")\n",
        "\n",
        "    # --- Display Logic (for interactive use) ---\n",
        "    print(\"--- Table 5: MSFE with supervised screening refinement ---\")\n",
        "    # In a Jupyter Notebook, the styler objects would be displayed directly.\n",
        "    # For a script, one might save them to HTML or LaTeX.\n",
        "    # display(styler_a)\n",
        "    # display(styler_b)\n",
        "\n",
        "    # Return the Styler objects for programmatic use.\n",
        "    return {\n",
        "        \"Panel A\": styler_a,\n",
        "        \"Panel B\": styler_b\n",
        "    }\n",
        "\n",
        "def format_simulation_tables(\n",
        "    simulation_results_df: pd.DataFrame\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Formats the Monte Carlo simulation results into publication-quality tables.\n",
        "\n",
        "    This function takes the raw, long-format DataFrame from the simulation\n",
        "    orchestrator and generates two styled tables that replicate the structure\n",
        "    and content of Table 1 (Factor Matrix Estimation Loss) and Table 2\n",
        "    (Loading Vector Estimation Loss) from the paper.\n",
        "\n",
        "    Args:\n",
        "        simulation_results_df (pd.DataFrame):\n",
        "            The DataFrame containing the results of all Monte Carlo replications.\n",
        "            Each row represents one run.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]:\n",
        "            A dictionary containing the styled Styler objects for Table 1 and Table 2.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation\n",
        "    # =========================================================================\n",
        "    if not isinstance(simulation_results_df, pd.DataFrame):\n",
        "        raise TypeError(\"Input must be a pandas DataFrame.\")\n",
        "    required_cols = {'p', 'q', 'T', 'factor_method', 'noise_method',\n",
        "                     'factor_matrix_error', 'loading_vector_error'}\n",
        "    if not required_cols.issubset(simulation_results_df.columns):\n",
        "        raise ValueError(f\"Input DataFrame is missing required columns. \"\n",
        "                         f\"Needed: {required_cols}\")\n",
        "\n",
        "    # --- Helper function for formatting mean and std ---\n",
        "    def format_mean_std(x):\n",
        "        # Custom formatter to combine mean and std into \"mean (std)\" string.\n",
        "        mean_val = x['mean']\n",
        "        std_val = x['std']\n",
        "        if pd.isna(mean_val) or pd.isna(std_val):\n",
        "            return \"-\"\n",
        "        return f\"{mean_val:.3f} ({std_val:.3f})\"\n",
        "\n",
        "    # =========================================================================\n",
        "    # Table 1: Factor Matrix Estimation Loss (factor_matrix_error)\n",
        "    # =========================================================================\n",
        "    print(\"--- Formatting Table 1: Factor Matrix Estimation Loss ---\")\n",
        "\n",
        "    # Step 1: Group by configuration and aggregate mean and std.\n",
        "    # We also count successful runs to ensure statistics are reliable.\n",
        "    agg_table1 = simulation_results_df.groupby(\n",
        "        ['factor_method', 'noise_method', 'p', 'q', 'T']\n",
        "    ).agg(\n",
        "        mean=('factor_matrix_error', 'mean'),\n",
        "        std=('factor_matrix_error', 'std'),\n",
        "        count=('factor_matrix_error', 'count')\n",
        "    ).reset_index()\n",
        "\n",
        "    # Step 2: Apply the custom string formatter.\n",
        "    agg_table1['display_val'] = agg_table1[['mean', 'std']].apply(format_mean_std, axis=1)\n",
        "\n",
        "    # Step 3: Pivot the table to match the paper's layout.\n",
        "    # Index: (p, q), Columns: (factor_method, noise_method, T)\n",
        "    table1_pivot = agg_table1.pivot_table(\n",
        "        index=['p', 'q'],\n",
        "        columns=['factor_method', 'noise_method', 'T'],\n",
        "        values='display_val',\n",
        "        aggfunc='first' # Use 'first' since values are already unique strings\n",
        "    ).fillna(\"-\")\n",
        "\n",
        "    # Reorder columns for better readability if needed\n",
        "    table1_pivot = table1_pivot.sort_index(axis=1)\n",
        "\n",
        "    # Step 4: Apply styling.\n",
        "    styler_t1 = table1_pivot.style.set_caption(\n",
        "        \"<b>Table 1: Means and Standard Deviations of Factor Matrix Estimation Loss</b>\"\n",
        "    ).set_table_styles([{'selector': 'th', 'props': [('text-align', 'center')]}])\n",
        "\n",
        "    # =========================================================================\n",
        "    # Table 2: Loading Vector Estimation Loss (loading_vector_error)\n",
        "    # =========================================================================\n",
        "    print(\"--- Formatting Table 2: Loading Vector Estimation Loss ---\")\n",
        "\n",
        "    # Step 1: Aggregate mean and std for the loading vector error.\n",
        "    agg_table2 = simulation_results_df.groupby(\n",
        "        ['factor_method', 'noise_method', 'p', 'q', 'T']\n",
        "    ).agg(\n",
        "        mean=('loading_vector_error', 'mean'),\n",
        "        std=('loading_vector_error', 'std')\n",
        "    ).reset_index()\n",
        "\n",
        "    # Step 2: Apply the custom string formatter.\n",
        "    agg_table2['display_val'] = agg_table2[['mean', 'std']].apply(format_mean_std, axis=1)\n",
        "\n",
        "    # Step 3: Pivot the table.\n",
        "    # Index: (p, q), Columns: (factor_method, noise_method, T)\n",
        "    table2_pivot = agg_table2.pivot_table(\n",
        "        index=['p', 'q'],\n",
        "        columns=['factor_method', 'noise_method', 'T'],\n",
        "        values='display_val',\n",
        "        aggfunc='first'\n",
        "    ).fillna(\"-\")\n",
        "\n",
        "    # Reorder columns\n",
        "    table2_pivot = table2_pivot.sort_index(axis=1)\n",
        "\n",
        "    # Step 4: Apply styling.\n",
        "    styler_t2 = table2_pivot.style.set_caption(\n",
        "        \"<b>Table 2: Means and Standard Deviations of Loading Vector Estimation Loss</b>\"\n",
        "    ).set_table_styles([{'selector': 'th', 'props': [('text-align', 'center')]}])\n",
        "\n",
        "    return {\n",
        "        \"Table 1\": styler_t1,\n",
        "        \"Table 2\": styler_t2\n",
        "    }\n",
        "\n",
        "def generate_normality_diagnostics(\n",
        "    simulation_results_df: pd.DataFrame,\n",
        "    config_to_plot: Dict[str, Any],\n",
        "    parameter_name: str = 'alpha_hat_0'\n",
        ") -> Any:\n",
        "    \"\"\"\n",
        "    Generates diagnostic plots (Q-Q plot, histogram) to assess normality.\n",
        "\n",
        "    This function takes the detailed results from a Monte Carlo simulation,\n",
        "    filters them for a specific experimental configuration, and produces a\n",
        "    two-panel figure to visually inspect the asymptotic normality of a\n",
        "    specified parameter estimate, as discussed in Section 5.3 of the paper.\n",
        "\n",
        "    Args:\n",
        "        simulation_results_df (pd.DataFrame):\n",
        "            The DataFrame containing the results of all Monte Carlo replications.\n",
        "            This DataFrame must contain columns for the estimated parameters\n",
        "            (e.g., 'alpha_hat_0', 'beta_hat_0').\n",
        "        config_to_plot (Dict[str, Any]):\n",
        "            A dictionary specifying the exact experimental configuration to\n",
        "            visualize (e.g., {'p': 10, 'q': 10, 'T': 400, ...}).\n",
        "        parameter_name (str):\n",
        "            The name of the column in the DataFrame containing the parameter\n",
        "            estimates to be analyzed.\n",
        "\n",
        "    Returns:\n",
        "        matplotlib.figure.Figure:\n",
        "            The matplotlib Figure object containing the diagnostic plots. This\n",
        "            can be displayed, modified, or saved.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the specified configuration is not found or the\n",
        "                    parameter column does not exist.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Input Validation and Data Filtering\n",
        "    # =========================================================================\n",
        "    if parameter_name not in simulation_results_df.columns:\n",
        "        raise ValueError(f\"Parameter '{parameter_name}' not found in simulation results.\")\n",
        "\n",
        "    # Create a boolean mask to filter the DataFrame for the specific configuration.\n",
        "    mask = pd.Series(True, index=simulation_results_df.index)\n",
        "    for key, value in config_to_plot.items():\n",
        "        if key in simulation_results_df.columns:\n",
        "            mask &= (simulation_results_df[key] == value)\n",
        "        else:\n",
        "            raise ValueError(f\"Configuration key '{key}' not found in DataFrame columns.\")\n",
        "\n",
        "    # Apply the filter to get the data for the specific experiment.\n",
        "    filtered_data = simulation_results_df[mask][parameter_name].dropna()\n",
        "\n",
        "    if filtered_data.empty:\n",
        "        raise ValueError(f\"No data found for the specified configuration: {config_to_plot}\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Plotting Setup\n",
        "    # =========================================================================\n",
        "    # Create a figure with two subplots side-by-side.\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    fig.suptitle(f\"Normality Diagnostics for '{parameter_name}'\\n\"\n",
        "                 f\"Config: {config_to_plot}\", fontsize=16)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Panel 1: Q-Q Plot\n",
        "    # =========================================================================\n",
        "    # Generate the Q-Q plot using scipy's probplot.\n",
        "    # This plots the sample quantiles against the theoretical normal quantiles.\n",
        "    # 'r' specifies that the reference line should be plotted.\n",
        "    (osm, osr), (slope, intercept, r) = scipy.stats.probplot(\n",
        "        filtered_data, dist=\"norm\", plot=axes[0]\n",
        "    )\n",
        "\n",
        "    # Customize the Q-Q plot.\n",
        "    axes[0].set_title(\"Q-Q Plot against Normal Distribution\", fontsize=12)\n",
        "    axes[0].set_xlabel(\"Theoretical Quantiles\")\n",
        "    axes[0].set_ylabel(\"Sample Quantiles\")\n",
        "    axes[0].grid(True, linestyle='--', alpha=0.6)\n",
        "    # Add R-squared value to the plot for a quantitative measure of fit.\n",
        "    axes[0].text(0.05, 0.95, f'$R^2 = {r**2:.3f}$',\n",
        "                 transform=axes[0].transAxes, verticalalignment='top')\n",
        "\n",
        "    # =========================================================================\n",
        "    # Panel 2: Histogram with Normal PDF Overlay\n",
        "    # =========================================================================\n",
        "    # Calculate the sample mean and standard deviation.\n",
        "    mu = filtered_data.mean()\n",
        "    sigma = filtered_data.std()\n",
        "\n",
        "    # Plot the histogram of the empirical data.\n",
        "    # `density=True` normalizes the histogram to form a probability density.\n",
        "    count, bins, ignored = axes[1].hist(filtered_data, bins=30, density=True,\n",
        "                                        alpha=0.7, label='Empirical Distribution')\n",
        "\n",
        "    # Calculate the PDF of the theoretical normal distribution for the overlay.\n",
        "    x_range = np.linspace(bins[0], bins[-1], 100)\n",
        "    pdf = scipy.stats.norm.pdf(x_range, mu, sigma)\n",
        "\n",
        "    # Plot the theoretical PDF as a line.\n",
        "    axes[1].plot(x_range, pdf, 'r-', linewidth=2, label='Normal PDF Overlay')\n",
        "\n",
        "    # Customize the histogram plot.\n",
        "    axes[1].set_title(\"Histogram with Normal PDF Overlay\", fontsize=12)\n",
        "    axes[1].set_xlabel(f\"Value of {parameter_name}\")\n",
        "    axes[1].set_ylabel(\"Density\")\n",
        "    axes[1].grid(True, linestyle='--', alpha=0.6)\n",
        "    axes[1].legend()\n",
        "    # Add sample statistics to the plot.\n",
        "    axes[1].text(0.05, 0.95, f'Mean: {mu:.3f}\\nStd: {sigma:.3f}',\n",
        "                 transform=axes[1].transAxes, verticalalignment='top')\n",
        "\n",
        "    # Adjust layout and display the plot.\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "\n",
        "    return fig\n",
        "\n",
        "def generate_reproducibility_report(\n",
        "    study_results: Dict[str, Any],\n",
        "    study_manifest: Dict[str, Any]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Generates a comprehensive reproducibility report for a study run.\n",
        "\n",
        "    This function creates a structured dictionary containing all metadata\n",
        "    necessary to document and reproduce the results of an empirical study.\n",
        "    It captures the computational environment, a full log of the parameters\n",
        "    used, and a high-level summary of the key findings.\n",
        "\n",
        "    Args:\n",
        "        study_results (Dict[str, Any]):\n",
        "            The final output dictionary from the `run_empirical_study_orchestrator`.\n",
        "        study_manifest (Dict[str, Any]):\n",
        "            The master configuration dictionary that was used for the run.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]:\n",
        "            A nested dictionary containing the complete reproducibility package.\n",
        "            This dictionary is designed to be easily serialized to JSON or YAML.\n",
        "    \"\"\"\n",
        "    # =========================================================================\n",
        "    # Step 1: Document Computational Environment\n",
        "    # =========================================================================\n",
        "    # Capture versions of the OS, Python, and key libraries to ensure that\n",
        "    # the computational environment can be replicated.\n",
        "    environment_spec = {\n",
        "        'timestamp_utc': datetime.datetime.utcnow().isoformat(),\n",
        "        'python_version': sys.version,\n",
        "        'platform_info': {\n",
        "            'system': platform.system(),\n",
        "            'release': platform.release(),\n",
        "            'version': platform.version(),\n",
        "            'machine': platform.machine(),\n",
        "            'processor': platform.processor(),\n",
        "        },\n",
        "        'library_versions': {\n",
        "            'numpy': np.__version__,\n",
        "            'pandas': pd.__version__,\n",
        "            'scipy': scipy.__version__,\n",
        "            'statsmodels': statsmodels.__version__,\n",
        "            'scikit-learn': sklearn.__version__,\n",
        "            'joblib': joblib.__version__,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 2: Create Parameter Log and Record Random Seeds\n",
        "    # =========================================================================\n",
        "    # The study_manifest itself serves as the complete parameter log.\n",
        "    # We perform a deep copy to ensure it's a snapshot at the time of the run.\n",
        "    parameter_log = copy.deepcopy(study_manifest)\n",
        "\n",
        "    # While random seeds are part of the orchestrator logic, explicitly\n",
        "    # recording the master seed here is good practice. We assume a seed\n",
        "    # was used, e.g., 42, in the orchestrator calls.\n",
        "    # A more advanced system would pass the seed through the manifest.\n",
        "    reproducibility_info = {\n",
        "        'master_random_seed_used': 42 # As used in the orchestrator\n",
        "    }\n",
        "\n",
        "    # =========================================================================\n",
        "    # Step 3: Generate Comprehensive Results Summary\n",
        "    # =========================================================================\n",
        "    # Extract the key, top-line findings from the detailed results objects.\n",
        "    try:\n",
        "        # Information about the best performing model configuration.\n",
        "        best_model_info = study_results.get('best_model_info', {})\n",
        "\n",
        "        # Extract the MSFE for the best model.\n",
        "        if best_model_info.get('type') == 'Unscreened':\n",
        "            best_msfe = study_results['unscreened_results'].loc[best_model_info['config']]['MSFE']\n",
        "        elif best_model_info.get('type') == 'Screened':\n",
        "            best_msfe = study_results['screened_results'].loc[best_model_info['config']]['MSFE']\n",
        "        else:\n",
        "            best_msfe = None\n",
        "\n",
        "        # Summary of benchmark performance.\n",
        "        benchmark_summary = study_results.get('benchmark_results', pd.DataFrame()).to_dict()\n",
        "\n",
        "        # Summary of significance tests.\n",
        "        significance_summary = study_results.get('significance_tests', pd.DataFrame()).to_dict('index')\n",
        "\n",
        "        results_summary = {\n",
        "            'best_model_type': best_model_info.get('type'),\n",
        "            'best_model_config': str(best_model_info.get('config')),\n",
        "            'best_model_msfe': best_msfe,\n",
        "            'benchmark_performance': benchmark_summary,\n",
        "            'significance_test_p_values': {\n",
        "                test: result.get('p_value') for test, result in significance_summary.items()\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        results_summary = {'error': f\"Failed to generate summary: {e}\"}\n",
        "\n",
        "    # =========================================================================\n",
        "    # Final Assembly\n",
        "    # =========================================================================\n",
        "    # Combine all components into the final report.\n",
        "    full_report = {\n",
        "        'reproducibility_report': {\n",
        "            'generation_info': environment_spec,\n",
        "            'reproducibility_settings': reproducibility_info,\n",
        "            'parameters_used': parameter_log,\n",
        "            'results_summary': results_summary,\n",
        "            'full_results': {\n",
        "                # For full detail, we can serialize the DataFrames.\n",
        "                # Note: Styler objects cannot be easily serialized.\n",
        "                'unscreened_results_df': study_results['unscreened_results'].reset_index().to_dict('records'),\n",
        "                'screened_results_df': study_results['screened_results'].reset_index().to_dict('records'),\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return full_report\n"
      ],
      "metadata": {
        "id": "1h73Rou8DZYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Master Orchestrator\n",
        "\n",
        "def run_complete_study(\n",
        "    country_data: Dict[str, pd.DataFrame],\n",
        "    y_series: pd.Series,\n",
        "    study_manifest: Dict[str, Any],\n",
        "    run_empirical_study: bool = True,\n",
        "    run_simulation_study: bool = True,\n",
        "    generate_reports: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Executes the entire research pipeline from data to final report.\n",
        "\n",
        "    This master orchestrator is the main entry point for the entire project.\n",
        "    It sequentially runs the core empirical study, the comprehensive simulation\n",
        "    study, and generates all publication-quality tables and reproducibility\n",
        "    documentation. Each major stage can be enabled or disabled via flags.\n",
        "\n",
        "    Args:\n",
        "        country_data (Dict[str, pd.DataFrame]): Raw country predictor data.\n",
        "        y_series (pd.Series): Raw target variable series.\n",
        "        study_manifest (Dict[str, Any]): The master configuration dictionary.\n",
        "        run_empirical_study (bool): If True, runs the main empirical study.\n",
        "        run_simulation_study (bool): If True, runs the Monte Carlo simulations.\n",
        "        generate_reports (bool): If True, generates final tables and reports.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A comprehensive dictionary containing all results and\n",
        "                        artifacts generated during the study.\n",
        "    \"\"\"\n",
        "    # Initialize the master dictionary to hold all outputs.\n",
        "    master_results = {}\n",
        "    print(\"=\"*80)\n",
        "    print(\"=== LAUNCHING COMPLETE RESEARCH STUDY PIPELINE ===\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # =========================================================================\n",
        "    # 1. Core Empirical Study\n",
        "    # =========================================================================\n",
        "    if run_empirical_study:\n",
        "        print(\"\\n[PHASE 1/3] Starting Core Empirical Study...\")\n",
        "        # Execute the dedicated orchestrator for the empirical analysis.\n",
        "        # This function now correctly handles all sub-steps internally.\n",
        "        empirical_results = run_empirical_study_orchestrator(\n",
        "            country_data, y_series, study_manifest\n",
        "        )\n",
        "        # Store the complete, detailed results.\n",
        "        master_results['empirical_study'] = empirical_results\n",
        "        print(\"[PHASE 1/3] Core Empirical Study complete.\")\n",
        "    else:\n",
        "        print(\"\\n[PHASE 1/3] Skipping Core Empirical Study.\")\n",
        "        master_results['empirical_study'] = None\n",
        "\n",
        "    # =========================================================================\n",
        "    # 2. Monte Carlo Simulation Study\n",
        "    # =========================================================================\n",
        "    if run_simulation_study:\n",
        "        print(\"\\n[PHASE 2/3] Starting Monte Carlo Simulation Study...\")\n",
        "        # Execute the orchestrator for the Monte Carlo simulations.\n",
        "        # This now returns a DataFrame that includes estimated parameters.\n",
        "        simulation_results_df = run_monte_carlo_simulation(study_manifest)\n",
        "        # Store the raw, detailed simulation results DataFrame.\n",
        "        master_results['simulation_study'] = {\n",
        "            'raw_results_df': simulation_results_df\n",
        "        }\n",
        "        print(\"[PHASE 2/3] Monte Carlo Simulation Study complete.\")\n",
        "    else:\n",
        "        print(\"\\n[PHASE 2/3] Skipping Monte Carlo Simulation Study.\")\n",
        "        master_results['simulation_study'] = None\n",
        "\n",
        "    # =========================================================================\n",
        "    # 3. Results Compilation and Reporting\n",
        "    # =========================================================================\n",
        "    if generate_reports:\n",
        "        print(\"\\n[PHASE 3/3] Generating Final Reports and Tables...\")\n",
        "        # Initialize a sub-dictionary for all generated reports.\n",
        "        reports = {}\n",
        "\n",
        "        # --- Generate Empirical Study Tables (4 & 5) ---\n",
        "        if master_results.get('empirical_study'):\n",
        "            emp_res = master_results['empirical_study']\n",
        "\n",
        "            # Generate Table 4 using the unscreened model and UNSCREENED benchmark results.\n",
        "            reports['Table 4'] = format_table_4(\n",
        "                emp_res['unscreened_results'],\n",
        "                emp_res['benchmark_results_unscreened'].T\n",
        "            )\n",
        "\n",
        "            # Generate Table 5 using the screened model and SCREENED benchmark results.\n",
        "            reports['Table 5'] = format_table_5(\n",
        "                emp_res['screened_results'],\n",
        "                emp_res['benchmark_results_screened'].T\n",
        "            )\n",
        "            print(\"  - Empirical tables (4, 5) generated.\")\n",
        "\n",
        "        # --- Generate Simulation Study Tables (1 & 2) and Plots ---\n",
        "        if master_results.get('simulation_study'):\n",
        "            sim_res_df = master_results['simulation_study']['raw_results_df']\n",
        "\n",
        "            # Generate Tables 1 and 2 from the raw simulation DataFrame.\n",
        "            reports['Simulation Tables 1 & 2'] = format_simulation_tables(sim_res_df)\n",
        "            print(\"  - Simulation tables (1, 2) generated.\")\n",
        "\n",
        "            # Generate diagnostic normality plots for a specific configuration.\n",
        "            config_for_plots = study_manifest.get('simulation_study', {}).get('parameters', {}).get('config_for_normality_plots')\n",
        "            if config_for_plots and not sim_res_df.empty:\n",
        "                try:\n",
        "                    # Generate plots for the first element of alpha_hat.\n",
        "                    reports['normality_plot_alpha'] = generate_normality_diagnostics(\n",
        "                        sim_res_df, config_for_plots, parameter_name='alpha_hat_0'\n",
        "                    )\n",
        "                    # Generate plots for the first element of beta_hat.\n",
        "                    reports['normality_plot_beta'] = generate_normality_diagnostics(\n",
        "                        sim_res_df, config_for_plots, parameter_name='beta_hat_0'\n",
        "                    )\n",
        "                    print(\"  - Normality diagnostic plots generated.\")\n",
        "                except ValueError as e:\n",
        "                    print(f\"  - Could not generate normality plots: {e}\")\n",
        "            else:\n",
        "                print(\"  - Skipping normality plots (no data or config).\")\n",
        "\n",
        "        # --- Generate Final Reproducibility Report ---\n",
        "        reports['reproducibility_report'] = generate_reproducibility_report(\n",
        "            master_results.get('empirical_study', {}),\n",
        "            study_manifest\n",
        "        )\n",
        "        print(\"  - Reproducibility report generated.\")\n",
        "\n",
        "        # Store all generated reports.\n",
        "        master_results['reports'] = reports\n",
        "        print(\"[PHASE 3/3] Report generation complete.\")\n",
        "    else:\n",
        "        print(\"\\n[PHASE 3/3] Skipping Report Generation.\")\n",
        "        master_results['reports'] = None\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"=== COMPLETE RESEARCH STUDY PIPELINE FINISHED ===\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return master_results\n"
      ],
      "metadata": {
        "id": "hocx6_YQHFxM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}